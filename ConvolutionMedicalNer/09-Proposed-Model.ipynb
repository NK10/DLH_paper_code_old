{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "# import glove nitin commented as its not used\n",
    "# from glove import Corpus\n",
    "\n",
    "import collections\n",
    "import gc \n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, merge, Activation, Concatenate, LSTM, GRU\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n",
    "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D, merge\n",
    "\n",
    "# from keras.optimizers import Adam # nitin commented as Adam has been shifted to optimizer_v1 module.\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "#from keras.backend.tensorflow_backend import set_session, clear_session, get_session # nitin commented as tensorflow_backend not used anymore\n",
    "from keras.backend import set_session, clear_session, get_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nitin added as without it the read_pickel below was giving the error as in notebook 5 when its writing\n",
    "#pickel do a lazy execution and write the function as well\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_ner = \"new\"\n",
    "\n",
    "x_train_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_train.pkl\")\n",
    "x_dev_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_dev.pkl\")\n",
    "x_test_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_test.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(\"data/\"+type_of_ner+\"_y_train.pkl\")\n",
    "y_dev = pd.read_pickle(\"data/\"+type_of_ner+\"_y_dev.pkl\")\n",
    "y_test = pd.read_pickle(\"data/\"+type_of_ner+\"_y_test.pkl\")\n",
    "\n",
    "\n",
    "ner_word2vec = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_word2vec_limited_dict.pkl\")\n",
    "ner_fasttext = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_fasttext_limited_dict.pkl\")\n",
    "ner_concat = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_combined_limited_dict.pkl\")\n",
    "\n",
    "train_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_train_ids.pkl\")\n",
    "dev_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_dev_ids.pkl\")\n",
    "test_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_test_ids.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15219, 24, 104),\n",
       " (2164, 24, 104),\n",
       " (4348, 24, 104),\n",
       " (15219, 4),\n",
       " (2164, 4),\n",
       " (4348, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lstm.shape,x_dev_lstm.shape,x_test_lstm.shape ,y_train.shape,y_dev.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_cnn(model, test_data):\n",
    "    probs = model.predict(test_data)\n",
    "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
    "    return probs, y_pred\n",
    "\n",
    "def save_scores_cnn(predictions, probs, ground_truth, \n",
    "                          \n",
    "                          embed_name, problem_type, iteration, hidden_unit_size,\n",
    "                          \n",
    "                          sequence_name, type_of_ner):\n",
    "    \n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    result_dict = {}    \n",
    "    result_dict['auc'] = auc\n",
    "    result_dict['auprc'] = auprc\n",
    "    result_dict['acc'] = acc\n",
    "    result_dict['F1'] = F1\n",
    "\n",
    "    result_path = \"results/cnn/\"\n",
    "    file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n",
    "    file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-cnn-.p\"\n",
    "    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
    "\n",
    "    print(auc, auprc, acc, F1)\n",
    "    \n",
    "def print_scores_cnn(predictions, probs, ground_truth, model_name, problem_type, iteration, hidden_unit_size):\n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    print (\"AUC: \", auc, \"AUPRC: \", auprc, \"F1: \", F1)\n",
    "    \n",
    "def get_subvector_data(size, embed_name, data):\n",
    "    if embed_name == \"concat\":\n",
    "        vector_size = 200\n",
    "    else:\n",
    "        vector_size = 100\n",
    "\n",
    "    x_data = {}\n",
    "    for k, v in data.items():\n",
    "        number_of_additional_vector = len(v) - size\n",
    "        vector = []\n",
    "        for i in v:\n",
    "            vector.append(i)\n",
    "        if number_of_additional_vector < 0: \n",
    "            number_of_additional_vector = np.abs(number_of_additional_vector)\n",
    "\n",
    "            temp = vector[:size]\n",
    "            for i in range(0, number_of_additional_vector):\n",
    "                temp.append(np.zeros(vector_size))\n",
    "            x_data[k] = np.asarray(temp)\n",
    "        else:\n",
    "            x_data[k] = np.asarray(vector[:size])\n",
    "\n",
    "    return x_data\n",
    "\n",
    "\n",
    "def proposedmodel(layer_name, number_of_unit, embedding_name, ner_limit, num_filter):\n",
    "    if embedding_name == \"concat\":\n",
    "        input_dimension = 200\n",
    "    else:\n",
    "        input_dimension = 100\n",
    "\n",
    "    sequence_input = Input(shape=(24,104))\n",
    "\n",
    "    input_img = Input(shape=(ner_limit, input_dimension), name = \"cnn_input\")\n",
    "\n",
    "    convs = []\n",
    "    filter_sizes = [2,3,4]\n",
    "\n",
    "\n",
    "    #logits_regularizer = tf.compat.v1.estimator.layers.l2_regularizer(scale=0.01)\n",
    "    # removed tf.compat.v1.estimator.layers.xavier_initializer() with glorot_normal\n",
    "    \n",
    "    text_conv1d = Conv1D(filters=num_filter, kernel_size=3, \n",
    "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu', \n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal() )(input_img)\n",
    "    \n",
    "    text_conv1d = Conv1D(filters=num_filter*2, kernel_size=3, \n",
    "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal())(text_conv1d)   \n",
    "    \n",
    "    text_conv1d = Conv1D(filters=num_filter*3, kernel_size=3, \n",
    "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal())(text_conv1d)   \n",
    "\n",
    "    \n",
    "    #concat_conv = keras.layers.Concatenate()([text_conv1d, text_conv1d_2, text_conv1d_3])\n",
    "    text_embeddings = GlobalMaxPooling1D()(text_conv1d)\n",
    "    #text_embeddings = Dense(128, activation=\"relu\")(text_embeddings)\n",
    "    \n",
    "    if layer_name == \"GRU\":\n",
    "        x = GRU(number_of_unit)(sequence_input)\n",
    "    elif layer_name == \"LSTM\":\n",
    "        x = LSTM(number_of_unit)(sequence_input)\n",
    "\n",
    "    concatenated = keras.layers.Concatenate(axis =1)([x, text_embeddings])# nitin uncommented\n",
    "    #concatenated = merge([x, text_embeddings], mode='concat', concat_axis=1)# nitin commented\n",
    "\n",
    "    concatenated = Dense(512, activation='relu')(concatenated)\n",
    "    concatenated = Dropout(0.2)(concatenated)\n",
    "    #concatenated = Dense(256, activation='relu')(concatenated)\n",
    "    #concatenated = Dense(512, activation='relu')(concatenated)\n",
    "    \n",
    "    #concatenated = Dense(512, activation='relu')(concatenated)\n",
    "    \n",
    "    #logits_regularizer = tf.contrib.layers.l2_regularizer(scale=0.01) nitin commented as its deprecated\n",
    "    logits_regularizer = tf.keras.regularizers.L2(0.01)\n",
    "    \n",
    "    preds = Dense(1, activation='sigmoid',use_bias=False,\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal(), \n",
    "                  kernel_regularizer=logits_regularizer)(concatenated)\n",
    "    \n",
    "    \n",
    "    #opt = Adam(lr=1e-4, decay = 0.01)\n",
    "    \n",
    "    opt = Adam(lr=1e-3, decay = 0.01)\n",
    "    \n",
    "    #opt = Adam(lr=0.001)\n",
    "\n",
    "    model = Model(inputs=[sequence_input, input_img], outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_f = {\"a\": [1,2,3], \"b\": [1,2,3], \"c\": [1,2,3], \"d\": [1,2,3]}\n",
    "\n",
    "#data = list(dict.items())\n",
    "data = collections.OrderedDict(sorted(dict_f.items()))\n",
    "print(sorted(dict_f.items()))\n",
    "an_array = np.asarray(data.values())\n",
    "\n",
    "print(data)\n",
    "print('an_array',an_array)\n",
    "print(type(data))\n",
    "\n",
    "\n",
    "\n",
    "for a in data.items():\n",
    "    print(a[1])\n",
    "\n",
    "t1[0]\n",
    "\n",
    "i =0\n",
    "t = []\n",
    "for kk,v in x_train_dict_sorted.items():\n",
    "    i+=1\n",
    "    #print(kk, v.shape,i+1)\n",
    "    t.append(v)\n",
    "a  = np.array(t)\n",
    "    \n",
    "\n",
    "a.shape\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding:  word2vec\n",
      "=============================\n",
      "(15219, 64, 100)\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2879 - acc: 0.9004\n",
      "Epoch 00001: val_loss improved from inf to 0.24888, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 30s 92ms/step - loss: 0.2879 - acc: 0.9004 - val_loss: 0.2489 - val_acc: 0.9145 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2363 - acc: 0.9164\n",
      "Epoch 00002: val_loss improved from 0.24888 to 0.23846, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 21s 88ms/step - loss: 0.2363 - acc: 0.9164 - val_loss: 0.2385 - val_acc: 0.9159 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2209 - acc: 0.9207\n",
      "Epoch 00003: val_loss did not improve from 0.23846\n",
      "238/238 [==============================] - 20s 86ms/step - loss: 0.2209 - acc: 0.9207 - val_loss: 0.2395 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2116 - acc: 0.9248\n",
      "Epoch 00004: val_loss did not improve from 0.23846\n",
      "238/238 [==============================] - 21s 87ms/step - loss: 0.2116 - acc: 0.9248 - val_loss: 0.2425 - val_acc: 0.9159 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1998 - acc: 0.9270\n",
      "Epoch 00005: val_loss did not improve from 0.23846\n",
      "238/238 [==============================] - 20s 86ms/step - loss: 0.1998 - acc: 0.9270 - val_loss: 0.2394 - val_acc: 0.9140 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1973 - acc: 0.9292\n",
      "Epoch 00006: val_loss did not improve from 0.23846\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1973 - acc: 0.9292 - val_loss: 0.2399 - val_acc: 0.9127 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1958 - acc: 0.9300\n",
      "Epoch 00007: val_loss did not improve from 0.23846\n",
      "238/238 [==============================] - 21s 86ms/step - loss: 0.1958 - acc: 0.9300 - val_loss: 0.2398 - val_acc: 0.9131 - lr: 4.0000e-05\n",
      "AUC:  0.8824230108379593 AUPRC:  0.5849820932858496 F1:  0.47659574468085103\n",
      "0.875645982024848 0.5740869507022067 0.9158233670653174 0.4171974522292993\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2133 - acc: 0.9332\n",
      "Epoch 00001: val_loss improved from inf to 0.17972, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 27s 87ms/step - loss: 0.2133 - acc: 0.9332 - val_loss: 0.1797 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1712 - acc: 0.9427\n",
      "Epoch 00002: val_loss improved from 0.17972 to 0.17002, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1712 - acc: 0.9427 - val_loss: 0.1700 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1568 - acc: 0.9477\n",
      "Epoch 00003: val_loss improved from 0.17002 to 0.16775, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1568 - acc: 0.9477 - val_loss: 0.1677 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1456 - acc: 0.9506\n",
      "Epoch 00004: val_loss did not improve from 0.16775\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1456 - acc: 0.9506 - val_loss: 0.1679 - val_acc: 0.9422 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1363 - acc: 0.9528\n",
      "Epoch 00005: val_loss did not improve from 0.16775\n",
      "238/238 [==============================] - 18s 77ms/step - loss: 0.1363 - acc: 0.9528 - val_loss: 0.1711 - val_acc: 0.9422 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1260 - acc: 0.9568\n",
      "Epoch 00006: val_loss did not improve from 0.16775\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1260 - acc: 0.9568 - val_loss: 0.1701 - val_acc: 0.9427 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1241 - acc: 0.9570\n",
      "Epoch 00007: val_loss did not improve from 0.16775\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1241 - acc: 0.9570 - val_loss: 0.1705 - val_acc: 0.9432 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1226 - acc: 0.9573\n",
      "Epoch 00008: val_loss did not improve from 0.16775\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1226 - acc: 0.9573 - val_loss: 0.1706 - val_acc: 0.9432 - lr: 4.0000e-05\n",
      "AUC:  0.887998033615806 AUPRC:  0.5179590146128387 F1:  0.45188284518828453\n",
      "0.8872871701234452 0.5217252280291164 0.9411223551057958 0.4285714285714286\n",
      "Iteration number:  2\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2907 - acc: 0.9010\n",
      "Epoch 00001: val_loss improved from inf to 0.24378, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 27s 89ms/step - loss: 0.2907 - acc: 0.9010 - val_loss: 0.2438 - val_acc: 0.9122 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2377 - acc: 0.9162\n",
      "Epoch 00002: val_loss improved from 0.24378 to 0.24266, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.2377 - acc: 0.9162 - val_loss: 0.2427 - val_acc: 0.9145 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2227 - acc: 0.9209\n",
      "Epoch 00003: val_loss improved from 0.24266 to 0.23541, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.2227 - acc: 0.9209 - val_loss: 0.2354 - val_acc: 0.9168 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2122 - acc: 0.9242\n",
      "Epoch 00004: val_loss did not improve from 0.23541\n",
      "238/238 [==============================] - 20s 83ms/step - loss: 0.2122 - acc: 0.9242 - val_loss: 0.2383 - val_acc: 0.9131 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2041 - acc: 0.9271\n",
      "Epoch 00005: val_loss did not improve from 0.23541\n",
      "238/238 [==============================] - 19s 81ms/step - loss: 0.2041 - acc: 0.9271 - val_loss: 0.2364 - val_acc: 0.9159 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1936 - acc: 0.9310\n",
      "Epoch 00006: val_loss did not improve from 0.23541\n",
      "238/238 [==============================] - 20s 83ms/step - loss: 0.1936 - acc: 0.9310 - val_loss: 0.2364 - val_acc: 0.9140 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1926 - acc: 0.9305\n",
      "Epoch 00007: val_loss did not improve from 0.23541\n",
      "238/238 [==============================] - 20s 83ms/step - loss: 0.1926 - acc: 0.9305 - val_loss: 0.2366 - val_acc: 0.9150 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "237/238 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9313\n",
      "Epoch 00008: val_loss did not improve from 0.23541\n",
      "238/238 [==============================] - 19s 81ms/step - loss: 0.1906 - acc: 0.9313 - val_loss: 0.2366 - val_acc: 0.9150 - lr: 4.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8836307163626752 AUPRC:  0.5922632618159211 F1:  0.48137535816618904\n",
      "0.8824147501982554 0.5895581760838886 0.9169733210671573 0.46518518518518515\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2162 - acc: 0.9346\n",
      "Epoch 00001: val_loss improved from inf to 0.17858, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 27s 88ms/step - loss: 0.2162 - acc: 0.9346 - val_loss: 0.1786 - val_acc: 0.9427 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1743 - acc: 0.9430\n",
      "Epoch 00002: val_loss improved from 0.17858 to 0.17593, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1743 - acc: 0.9430 - val_loss: 0.1759 - val_acc: 0.9432 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1571 - acc: 0.9474\n",
      "Epoch 00003: val_loss did not improve from 0.17593\n",
      "238/238 [==============================] - 19s 80ms/step - loss: 0.1571 - acc: 0.9474 - val_loss: 0.1776 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1475 - acc: 0.9490\n",
      "Epoch 00004: val_loss improved from 0.17593 to 0.17455, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.1475 - acc: 0.9490 - val_loss: 0.1746 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1368 - acc: 0.9539\n",
      "Epoch 00005: val_loss did not improve from 0.17455\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.1368 - acc: 0.9539 - val_loss: 0.1764 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1303 - acc: 0.9555\n",
      "Epoch 00006: val_loss did not improve from 0.17455\n",
      "238/238 [==============================] - 18s 77ms/step - loss: 0.1303 - acc: 0.9555 - val_loss: 0.1788 - val_acc: 0.9395 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1203 - acc: 0.9596\n",
      "Epoch 00007: val_loss did not improve from 0.17455\n",
      "238/238 [==============================] - 18s 76ms/step - loss: 0.1203 - acc: 0.9596 - val_loss: 0.1794 - val_acc: 0.9376 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1179 - acc: 0.9600\n",
      "Epoch 00008: val_loss did not improve from 0.17455\n",
      "238/238 [==============================] - 20s 83ms/step - loss: 0.1179 - acc: 0.9600 - val_loss: 0.1803 - val_acc: 0.9372 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1159 - acc: 0.9611\n",
      "Epoch 00009: val_loss did not improve from 0.17455\n",
      "238/238 [==============================] - 19s 82ms/step - loss: 0.1159 - acc: 0.9611 - val_loss: 0.1803 - val_acc: 0.9372 - lr: 4.0000e-05\n",
      "AUC:  0.887914540318679 AUPRC:  0.5216954386309282 F1:  0.4605809128630705\n",
      "0.8883858482762926 0.5259507792825964 0.9413523459061638 0.44924406047516197\n",
      "Iteration number:  3\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2809 - acc: 0.9038\n",
      "Epoch 00001: val_loss improved from inf to 0.24726, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 23s 77ms/step - loss: 0.2809 - acc: 0.9038 - val_loss: 0.2473 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2348 - acc: 0.9173\n",
      "Epoch 00002: val_loss improved from 0.24726 to 0.23970, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 18s 77ms/step - loss: 0.2348 - acc: 0.9173 - val_loss: 0.2397 - val_acc: 0.9177 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2206 - acc: 0.9218\n",
      "Epoch 00003: val_loss improved from 0.23970 to 0.23900, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 19s 81ms/step - loss: 0.2206 - acc: 0.9218 - val_loss: 0.2390 - val_acc: 0.9154 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2105 - acc: 0.9246\n",
      "Epoch 00004: val_loss improved from 0.23900 to 0.23818, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 21s 87ms/step - loss: 0.2105 - acc: 0.9246 - val_loss: 0.2382 - val_acc: 0.9196 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2023 - acc: 0.9265\n",
      "Epoch 00005: val_loss did not improve from 0.23818\n",
      "238/238 [==============================] - 20s 86ms/step - loss: 0.2023 - acc: 0.9265 - val_loss: 0.2399 - val_acc: 0.9177 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1937 - acc: 0.9298\n",
      "Epoch 00006: val_loss did not improve from 0.23818\n",
      "238/238 [==============================] - 21s 87ms/step - loss: 0.1937 - acc: 0.9298 - val_loss: 0.2395 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1850 - acc: 0.9337\n",
      "Epoch 00007: val_loss did not improve from 0.23818\n",
      "238/238 [==============================] - 18s 75ms/step - loss: 0.1850 - acc: 0.9337 - val_loss: 0.2406 - val_acc: 0.9154 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1833 - acc: 0.9340\n",
      "Epoch 00008: val_loss did not improve from 0.23818\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 0.1833 - acc: 0.9340 - val_loss: 0.2411 - val_acc: 0.9164 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1819 - acc: 0.9342\n",
      "Epoch 00009: val_loss did not improve from 0.23818\n",
      "238/238 [==============================] - 19s 81ms/step - loss: 0.1819 - acc: 0.9342 - val_loss: 0.2413 - val_acc: 0.9164 - lr: 4.0000e-05\n",
      "AUC:  0.8832138294122831 AUPRC:  0.5897749913751842 F1:  0.48746518105849584\n",
      "0.8806954357212089 0.5875465931063144 0.9167433302667893 0.47838616714697413\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2126 - acc: 0.9353\n",
      "Epoch 00001: val_loss improved from inf to 0.17892, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 26s 87ms/step - loss: 0.2126 - acc: 0.9353 - val_loss: 0.1789 - val_acc: 0.9427 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1717 - acc: 0.9429\n",
      "Epoch 00002: val_loss improved from 0.17892 to 0.17053, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1717 - acc: 0.9429 - val_loss: 0.1705 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1567 - acc: 0.9472\n",
      "Epoch 00003: val_loss did not improve from 0.17053\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1567 - acc: 0.9472 - val_loss: 0.1712 - val_acc: 0.9432 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1465 - acc: 0.9489\n",
      "Epoch 00004: val_loss improved from 0.17053 to 0.16896, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 19s 81ms/step - loss: 0.1465 - acc: 0.9489 - val_loss: 0.1690 - val_acc: 0.9422 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1363 - acc: 0.9533\n",
      "Epoch 00005: val_loss did not improve from 0.16896\n",
      "238/238 [==============================] - 19s 82ms/step - loss: 0.1363 - acc: 0.9533 - val_loss: 0.1691 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1268 - acc: 0.9547\n",
      "Epoch 00006: val_loss did not improve from 0.16896\n",
      "238/238 [==============================] - 21s 86ms/step - loss: 0.1268 - acc: 0.9547 - val_loss: 0.1732 - val_acc: 0.9422 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1177 - acc: 0.9592\n",
      "Epoch 00007: val_loss did not improve from 0.16896\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1177 - acc: 0.9592 - val_loss: 0.1728 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1155 - acc: 0.9598\n",
      "Epoch 00008: val_loss did not improve from 0.16896\n",
      "238/238 [==============================] - 21s 87ms/step - loss: 0.1155 - acc: 0.9598 - val_loss: 0.1728 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1130 - acc: 0.9617\n",
      "Epoch 00009: val_loss did not improve from 0.16896\n",
      "238/238 [==============================] - 21s 86ms/step - loss: 0.1130 - acc: 0.9617 - val_loss: 0.1729 - val_acc: 0.9422 - lr: 4.0000e-05\n",
      "AUC:  0.8832872949732354 AUPRC:  0.5000981303486426 F1:  0.4310344827586206\n",
      "0.8872103094714172 0.5091462803905001 0.9413523459061638 0.44924406047516197\n",
      "Iteration number:  4\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2829 - acc: 0.9039\n",
      "Epoch 00001: val_loss improved from inf to 0.24821, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 29s 93ms/step - loss: 0.2829 - acc: 0.9039 - val_loss: 0.2482 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2358 - acc: 0.9179\n",
      "Epoch 00002: val_loss improved from 0.24821 to 0.24079, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 21s 86ms/step - loss: 0.2358 - acc: 0.9179 - val_loss: 0.2408 - val_acc: 0.9177 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2195 - acc: 0.9213\n",
      "Epoch 00003: val_loss improved from 0.24079 to 0.23879, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.2195 - acc: 0.9213 - val_loss: 0.2388 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2071 - acc: 0.9260\n",
      "Epoch 00004: val_loss did not improve from 0.23879\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.2071 - acc: 0.9260 - val_loss: 0.2406 - val_acc: 0.9127 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1984 - acc: 0.9281\n",
      "Epoch 00005: val_loss did not improve from 0.23879\n",
      "238/238 [==============================] - 20s 86ms/step - loss: 0.1984 - acc: 0.9281 - val_loss: 0.2443 - val_acc: 0.9104 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1871 - acc: 0.9327\n",
      "Epoch 00006: val_loss did not improve from 0.23879\n",
      "238/238 [==============================] - 18s 74ms/step - loss: 0.1871 - acc: 0.9327 - val_loss: 0.2426 - val_acc: 0.9140 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1851 - acc: 0.9325\n",
      "Epoch 00007: val_loss did not improve from 0.23879\n",
      "238/238 [==============================] - 18s 75ms/step - loss: 0.1851 - acc: 0.9325 - val_loss: 0.2427 - val_acc: 0.9140 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1831 - acc: 0.9331\n",
      "Epoch 00008: val_loss did not improve from 0.23879\n",
      "238/238 [==============================] - 19s 79ms/step - loss: 0.1831 - acc: 0.9331 - val_loss: 0.2426 - val_acc: 0.9136 - lr: 4.0000e-05\n",
      "AUC:  0.8843659132963257 AUPRC:  0.5838493300802904 F1:  0.5021037868162693\n",
      "0.8814647766323025 0.5801007835341132 0.9167433302667893 0.46920821114369504\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2100 - acc: 0.9354\n",
      "Epoch 00001: val_loss improved from inf to 0.18261, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 28s 97ms/step - loss: 0.2100 - acc: 0.9354 - val_loss: 0.1826 - val_acc: 0.9427 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1710 - acc: 0.9443\n",
      "Epoch 00002: val_loss improved from 0.18261 to 0.17099, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 21s 87ms/step - loss: 0.1710 - acc: 0.9443 - val_loss: 0.1710 - val_acc: 0.9409 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1555 - acc: 0.9476\n",
      "Epoch 00003: val_loss improved from 0.17099 to 0.17062, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 17s 73ms/step - loss: 0.1555 - acc: 0.9476 - val_loss: 0.1706 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1446 - acc: 0.9505\n",
      "Epoch 00004: val_loss did not improve from 0.17062\n",
      "238/238 [==============================] - 18s 74ms/step - loss: 0.1446 - acc: 0.9505 - val_loss: 0.1755 - val_acc: 0.9381 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1342 - acc: 0.9532\n",
      "Epoch 00005: val_loss did not improve from 0.17062\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 0.1342 - acc: 0.9532 - val_loss: 0.1792 - val_acc: 0.9367 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1238 - acc: 0.9558\n",
      "Epoch 00006: val_loss did not improve from 0.17062\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.1238 - acc: 0.9558 - val_loss: 0.1756 - val_acc: 0.9385 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1212 - acc: 0.9576\n",
      "Epoch 00007: val_loss did not improve from 0.17062\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1212 - acc: 0.9576 - val_loss: 0.1764 - val_acc: 0.9385 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1192 - acc: 0.9587\n",
      "Epoch 00008: val_loss did not improve from 0.17062\n",
      "238/238 [==============================] - 20s 86ms/step - loss: 0.1192 - acc: 0.9587 - val_loss: 0.1764 - val_acc: 0.9395 - lr: 4.0000e-05\n",
      "AUC:  0.8841089626543065 AUPRC:  0.5127875394908887 F1:  0.45283018867924524\n",
      "0.8849610624717137 0.5201471224473739 0.9415823367065317 0.40375586854460094\n",
      "Iteration number:  5\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2934 - acc: 0.9001\n",
      "Epoch 00001: val_loss improved from inf to 0.25174, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 25s 85ms/step - loss: 0.2934 - acc: 0.9001 - val_loss: 0.2517 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2391 - acc: 0.9163\n",
      "Epoch 00002: val_loss improved from 0.25174 to 0.23918, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 18s 74ms/step - loss: 0.2391 - acc: 0.9163 - val_loss: 0.2392 - val_acc: 0.9164 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2239 - acc: 0.9206\n",
      "Epoch 00003: val_loss did not improve from 0.23918\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.2239 - acc: 0.9206 - val_loss: 0.2395 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2136 - acc: 0.9252- ETA: 0s - loss: 0.2142 - acc: 0\n",
      "Epoch 00004: val_loss improved from 0.23918 to 0.23809, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 18s 78ms/step - loss: 0.2136 - acc: 0.9252 - val_loss: 0.2381 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2038 - acc: 0.9282\n",
      "Epoch 00005: val_loss did not improve from 0.23809\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.2038 - acc: 0.9282 - val_loss: 0.2397 - val_acc: 0.9131 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1947 - acc: 0.9303\n",
      "Epoch 00006: val_loss did not improve from 0.23809\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1947 - acc: 0.9303 - val_loss: 0.2394 - val_acc: 0.9127 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1857 - acc: 0.9339\n",
      "Epoch 00007: val_loss did not improve from 0.23809\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.1857 - acc: 0.9339 - val_loss: 0.2396 - val_acc: 0.9113 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1837 - acc: 0.9334- ETA: 1s - loss:\n",
      "Epoch 00008: val_loss did not improve from 0.23809\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.1837 - acc: 0.9334 - val_loss: 0.2399 - val_acc: 0.9122 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1820 - acc: 0.9347- ETA: 3s - loss: - ETA: 1s\n",
      "Epoch 00009: val_loss did not improve from 0.23809\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 0.1820 - acc: 0.9347 - val_loss: 0.2399 - val_acc: 0.9113 - lr: 4.0000e-05\n",
      "AUC:  0.8774547867653538 AUPRC:  0.579894189018618 F1:  0.48579545454545453\n",
      "0.879091219490704 0.5859396011298851 0.9158233670653174 0.45697329376854595\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2172 - acc: 0.9327\n",
      "Epoch 00001: val_loss improved from inf to 0.18088, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 28s 96ms/step - loss: 0.2172 - acc: 0.9327 - val_loss: 0.1809 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1730 - acc: 0.9444- ETA: 1s - loss: 0.1722\n",
      "Epoch 00002: val_loss improved from 0.18088 to 0.17289, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1730 - acc: 0.9444 - val_loss: 0.1729 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1600 - acc: 0.9473\n",
      "Epoch 00003: val_loss improved from 0.17289 to 0.17267, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 19s 80ms/step - loss: 0.1600 - acc: 0.9473 - val_loss: 0.1727 - val_acc: 0.9441 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1512 - acc: 0.9498\n",
      "Epoch 00004: val_loss improved from 0.17267 to 0.16941, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 0.1512 - acc: 0.9498 - val_loss: 0.1694 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1422 - acc: 0.9521\n",
      "Epoch 00005: val_loss did not improve from 0.16941\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 0.1422 - acc: 0.9521 - val_loss: 0.1704 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1369 - acc: 0.9537\n",
      "Epoch 00006: val_loss did not improve from 0.16941\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 0.1369 - acc: 0.9537 - val_loss: 0.1725 - val_acc: 0.9427 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1284 - acc: 0.9567\n",
      "Epoch 00007: val_loss did not improve from 0.16941\n",
      "238/238 [==============================] - 20s 86ms/step - loss: 0.1284 - acc: 0.9567 - val_loss: 0.1723 - val_acc: 0.9427 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1259 - acc: 0.9581- ETA: 1s - los\n",
      "Epoch 00008: val_loss did not improve from 0.16941\n",
      "238/238 [==============================] - 22s 91ms/step - loss: 0.1259 - acc: 0.9581 - val_loss: 0.1726 - val_acc: 0.9422 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1245 - acc: 0.9574- ETA: 2s - \n",
      "Epoch 00009: val_loss did not improve from 0.16941\n",
      "238/238 [==============================] - 22s 91ms/step - loss: 0.1245 - acc: 0.9574 - val_loss: 0.1727 - val_acc: 0.9422 - lr: 4.0000e-05\n",
      "AUC:  0.8868821886168203 AUPRC:  0.5172935719140396 F1:  0.4553191489361702\n",
      "0.8886714421711379 0.522930614389476 0.9411223551057958 0.45299145299145294\n",
      "Iteration number:  6\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2797 - acc: 0.9049\n",
      "Epoch 00001: val_loss improved from inf to 0.25038, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 22s 75ms/step - loss: 0.2797 - acc: 0.9049 - val_loss: 0.2504 - val_acc: 0.9104 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2367 - acc: 0.9155- ETA: 2s \n",
      "Epoch 00002: val_loss improved from 0.25038 to 0.23671, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 20s 83ms/step - loss: 0.2367 - acc: 0.9155 - val_loss: 0.2367 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2196 - acc: 0.9209\n",
      "Epoch 00003: val_loss improved from 0.23671 to 0.23604, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 19s 79ms/step - loss: 0.2196 - acc: 0.9209 - val_loss: 0.2360 - val_acc: 0.9122 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2086 - acc: 0.9261\n",
      "Epoch 00004: val_loss did not improve from 0.23604\n",
      "238/238 [==============================] - 20s 83ms/step - loss: 0.2086 - acc: 0.9261 - val_loss: 0.2366 - val_acc: 0.9122 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1975 - acc: 0.9294\n",
      "Epoch 00005: val_loss did not improve from 0.23604\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1975 - acc: 0.9294 - val_loss: 0.2368 - val_acc: 0.9127 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1855 - acc: 0.9333\n",
      "Epoch 00006: val_loss did not improve from 0.23604\n",
      "238/238 [==============================] - 18s 76ms/step - loss: 0.1855 - acc: 0.9333 - val_loss: 0.2374 - val_acc: 0.9113 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1829 - acc: 0.9346\n",
      "Epoch 00007: val_loss did not improve from 0.23604\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 0.1829 - acc: 0.9346 - val_loss: 0.2380 - val_acc: 0.9104 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1802 - acc: 0.9350\n",
      "Epoch 00008: val_loss did not improve from 0.23604\n",
      "238/238 [==============================] - 17s 69ms/step - loss: 0.1802 - acc: 0.9350 - val_loss: 0.2381 - val_acc: 0.9099 - lr: 4.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8797889681910301 AUPRC:  0.5711206282953859 F1:  0.4779516358463727\n",
      "0.8784050356859636 0.5663711488970622 0.9121435142594296 0.4246987951807229\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2252 - acc: 0.9311\n",
      "Epoch 00001: val_loss improved from inf to 0.18048, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 27s 95ms/step - loss: 0.2252 - acc: 0.9311 - val_loss: 0.1805 - val_acc: 0.9399 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1760 - acc: 0.9435\n",
      "Epoch 00002: val_loss improved from 0.18048 to 0.17126, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.1760 - acc: 0.9435 - val_loss: 0.1713 - val_acc: 0.9459 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1639 - acc: 0.9467\n",
      "Epoch 00003: val_loss did not improve from 0.17126\n",
      "238/238 [==============================] - 19s 77ms/step - loss: 0.1639 - acc: 0.9467 - val_loss: 0.1724 - val_acc: 0.9441 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1542 - acc: 0.9496\n",
      "Epoch 00004: val_loss improved from 0.17126 to 0.16965, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 0.1542 - acc: 0.9496 - val_loss: 0.1696 - val_acc: 0.9450 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1475 - acc: 0.9508\n",
      "Epoch 00005: val_loss did not improve from 0.16965\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.1475 - acc: 0.9508 - val_loss: 0.1709 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1419 - acc: 0.9516\n",
      "Epoch 00006: val_loss did not improve from 0.16965\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 0.1419 - acc: 0.9516 - val_loss: 0.1716 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1351 - acc: 0.9538- ETA: 0s - loss: 0.1345 -\n",
      "Epoch 00007: val_loss did not improve from 0.16965\n",
      "238/238 [==============================] - 19s 79ms/step - loss: 0.1351 - acc: 0.9538 - val_loss: 0.1715 - val_acc: 0.9427 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1335 - acc: 0.9548\n",
      "Epoch 00008: val_loss did not improve from 0.16965\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1335 - acc: 0.9548 - val_loss: 0.1715 - val_acc: 0.9427 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1325 - acc: 0.9543\n",
      "Epoch 00009: val_loss did not improve from 0.16965\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1325 - acc: 0.9543 - val_loss: 0.1716 - val_acc: 0.9427 - lr: 4.0000e-05\n",
      "AUC:  0.8905769620924825 AUPRC:  0.5228119114579964 F1:  0.4502164502164501\n",
      "0.8896690700251261 0.5207308637649898 0.9418123275068997 0.4288939051918736\n",
      "Iteration number:  7\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2942 - acc: 0.9013\n",
      "Epoch 00001: val_loss improved from inf to 0.24357, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 23s 75ms/step - loss: 0.2942 - acc: 0.9013 - val_loss: 0.2436 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2393 - acc: 0.9170\n",
      "Epoch 00002: val_loss improved from 0.24357 to 0.24251, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.2393 - acc: 0.9170 - val_loss: 0.2425 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2234 - acc: 0.9213\n",
      "Epoch 00003: val_loss improved from 0.24251 to 0.23874, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.2234 - acc: 0.9213 - val_loss: 0.2387 - val_acc: 0.9145 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2120 - acc: 0.9262\n",
      "Epoch 00004: val_loss improved from 0.23874 to 0.23770, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 19s 80ms/step - loss: 0.2120 - acc: 0.9262 - val_loss: 0.2377 - val_acc: 0.9154 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2028 - acc: 0.9277\n",
      "Epoch 00005: val_loss did not improve from 0.23770\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.2028 - acc: 0.9277 - val_loss: 0.2407 - val_acc: 0.9145 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1961 - acc: 0.9300\n",
      "Epoch 00006: val_loss did not improve from 0.23770\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1961 - acc: 0.9300 - val_loss: 0.2415 - val_acc: 0.9154 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1858 - acc: 0.9335\n",
      "Epoch 00007: val_loss did not improve from 0.23770\n",
      "238/238 [==============================] - 18s 77ms/step - loss: 0.1858 - acc: 0.9335 - val_loss: 0.2421 - val_acc: 0.9154 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1846 - acc: 0.9349- ETA: 0s - loss: 0.1854 \n",
      "Epoch 00008: val_loss did not improve from 0.23770\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 0.1846 - acc: 0.9349 - val_loss: 0.2429 - val_acc: 0.9145 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1826 - acc: 0.9349\n",
      "Epoch 00009: val_loss did not improve from 0.23770\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 0.1826 - acc: 0.9349 - val_loss: 0.2430 - val_acc: 0.9150 - lr: 4.0000e-05\n",
      "AUC:  0.8832694510529563 AUPRC:  0.581197941540218 F1:  0.48760330578512395\n",
      "0.8823205789056305 0.5756166828453786 0.9128334866605335 0.4531024531024531\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2154 - acc: 0.9343\n",
      "Epoch 00001: val_loss improved from inf to 0.17662, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 26s 90ms/step - loss: 0.2154 - acc: 0.9343 - val_loss: 0.1766 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1733 - acc: 0.9437\n",
      "Epoch 00002: val_loss improved from 0.17662 to 0.17214, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 19s 79ms/step - loss: 0.1733 - acc: 0.9437 - val_loss: 0.1721 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1572 - acc: 0.9463\n",
      "Epoch 00003: val_loss improved from 0.17214 to 0.17152, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.1572 - acc: 0.9463 - val_loss: 0.1715 - val_acc: 0.9399 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1468 - acc: 0.9503\n",
      "Epoch 00004: val_loss improved from 0.17152 to 0.16894, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 0.1468 - acc: 0.9503 - val_loss: 0.1689 - val_acc: 0.9441 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1378 - acc: 0.9527\n",
      "Epoch 00005: val_loss did not improve from 0.16894\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 0.1378 - acc: 0.9527 - val_loss: 0.1694 - val_acc: 0.9427 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1284 - acc: 0.9559\n",
      "Epoch 00006: val_loss did not improve from 0.16894\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 0.1284 - acc: 0.9559 - val_loss: 0.1715 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1193 - acc: 0.9585\n",
      "Epoch 00007: val_loss did not improve from 0.16894\n",
      "238/238 [==============================] - 18s 77ms/step - loss: 0.1193 - acc: 0.9585 - val_loss: 0.1719 - val_acc: 0.9413 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1175 - acc: 0.9590\n",
      "Epoch 00008: val_loss did not improve from 0.16894\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1175 - acc: 0.9590 - val_loss: 0.1722 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1154 - acc: 0.9597\n",
      "Epoch 00009: val_loss did not improve from 0.16894\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 0.1154 - acc: 0.9597 - val_loss: 0.1721 - val_acc: 0.9422 - lr: 4.0000e-05\n",
      "AUC:  0.887078827036222 AUPRC:  0.516538947710229 F1:  0.4654088050314465\n",
      "0.8846668851537994 0.5171692431219347 0.9404323827046918 0.41269841269841273\n",
      "Iteration number:  8\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2865 - acc: 0.9020\n",
      "Epoch 00001: val_loss improved from inf to 0.24619, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 24s 81ms/step - loss: 0.2865 - acc: 0.9020 - val_loss: 0.2462 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2384 - acc: 0.9156\n",
      "Epoch 00002: val_loss improved from 0.24619 to 0.24065, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.2384 - acc: 0.9156 - val_loss: 0.2407 - val_acc: 0.9131 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2226 - acc: 0.9207\n",
      "Epoch 00003: val_loss did not improve from 0.24065\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 0.2226 - acc: 0.9207 - val_loss: 0.2416 - val_acc: 0.9094 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2128 - acc: 0.9233- ETA: 9s - - ETA: 7s - loss - ETA: 2\n",
      "Epoch 00004: val_loss did not improve from 0.24065\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.2128 - acc: 0.9233 - val_loss: 0.2419 - val_acc: 0.9117 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2015 - acc: 0.9275- ETA: 8s - loss: 0.202 - ETA: 7s - - ETA: 2s - loss: 0.2022 - acc: 0.927 - ETA: 2s -\n",
      "Epoch 00005: val_loss improved from 0.24065 to 0.23933, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 21s 87ms/step - loss: 0.2015 - acc: 0.9275 - val_loss: 0.2393 - val_acc: 0.9108 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1993 - acc: 0.9281\n",
      "Epoch 00006: val_loss did not improve from 0.23933\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1993 - acc: 0.9281 - val_loss: 0.2403 - val_acc: 0.9136 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1975 - acc: 0.9281\n",
      "Epoch 00007: val_loss did not improve from 0.23933\n",
      "238/238 [==============================] - 19s 79ms/step - loss: 0.1975 - acc: 0.9281 - val_loss: 0.2406 - val_acc: 0.9131 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1955 - acc: 0.9290\n",
      "Epoch 00008: val_loss did not improve from 0.23933\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.1955 - acc: 0.9290 - val_loss: 0.2405 - val_acc: 0.9131 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1963 - acc: 0.9283\n",
      "Epoch 00009: val_loss did not improve from 0.23933\n",
      "238/238 [==============================] - 17s 69ms/step - loss: 0.1963 - acc: 0.9283 - val_loss: 0.2405 - val_acc: 0.9131 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1951 - acc: 0.9294\n",
      "Epoch 00010: val_loss did not improve from 0.23933\n",
      "238/238 [==============================] - 18s 75ms/step - loss: 0.1951 - acc: 0.9294 - val_loss: 0.2405 - val_acc: 0.9131 - lr: 1.0000e-05\n",
      "AUC:  0.8825970349810557 AUPRC:  0.5862568110016494 F1:  0.48196248196248204\n",
      "0.8818822142920081 0.5852971516257697 0.9167433302667893 0.4660766961651917\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2142 - acc: 0.9323\n",
      "Epoch 00001: val_loss improved from inf to 0.18013, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 27s 84ms/step - loss: 0.2142 - acc: 0.9323 - val_loss: 0.1801 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1711 - acc: 0.9419\n",
      "Epoch 00002: val_loss improved from 0.18013 to 0.17290, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 18s 78ms/step - loss: 0.1711 - acc: 0.9419 - val_loss: 0.1729 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1572 - acc: 0.9468\n",
      "Epoch 00003: val_loss improved from 0.17290 to 0.17156, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 17s 73ms/step - loss: 0.1572 - acc: 0.9468 - val_loss: 0.1716 - val_acc: 0.9422 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1465 - acc: 0.9491\n",
      "Epoch 00004: val_loss did not improve from 0.17156\n",
      "238/238 [==============================] - 17s 69ms/step - loss: 0.1465 - acc: 0.9491 - val_loss: 0.1728 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1366 - acc: 0.9524\n",
      "Epoch 00005: val_loss did not improve from 0.17156\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 0.1366 - acc: 0.9524 - val_loss: 0.1754 - val_acc: 0.9390 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1280 - acc: 0.9553\n",
      "Epoch 00006: val_loss did not improve from 0.17156\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.1280 - acc: 0.9553 - val_loss: 0.1747 - val_acc: 0.9376 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1262 - acc: 0.9557\n",
      "Epoch 00007: val_loss did not improve from 0.17156\n",
      "238/238 [==============================] - 19s 80ms/step - loss: 0.1262 - acc: 0.9557 - val_loss: 0.1750 - val_acc: 0.9390 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1247 - acc: 0.9562- ETA: 0s - loss: 0.1247 - acc: 0.95\n",
      "Epoch 00008: val_loss did not improve from 0.17156\n",
      "238/238 [==============================] - 20s 83ms/step - loss: 0.1247 - acc: 0.9562 - val_loss: 0.1750 - val_acc: 0.9390 - lr: 4.0000e-05\n",
      "AUC:  0.8876207531563587 AUPRC:  0.5203561607936363 F1:  0.46764091858037576\n",
      "0.8844554208218237 0.5219337599050028 0.9413523459061638 0.41913439635535304\n",
      "Iteration number:  9\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2817 - acc: 0.9033- ETA: 0s - loss: 0.2814 - acc: 0.902 - ETA: 0s - loss: 0.2812 -\n",
      "Epoch 00001: val_loss improved from inf to 0.24407, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 24s 79ms/step - loss: 0.2817 - acc: 0.9033 - val_loss: 0.2441 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2371 - acc: 0.9166\n",
      "Epoch 00002: val_loss improved from 0.24407 to 0.23883, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 0.2371 - acc: 0.9166 - val_loss: 0.2388 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2198 - acc: 0.9207\n",
      "Epoch 00003: val_loss improved from 0.23883 to 0.23855, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 17s 69ms/step - loss: 0.2198 - acc: 0.9207 - val_loss: 0.2385 - val_acc: 0.9122 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2073 - acc: 0.9242\n",
      "Epoch 00004: val_loss improved from 0.23855 to 0.23720, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 18s 74ms/step - loss: 0.2073 - acc: 0.9242 - val_loss: 0.2372 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1950 - acc: 0.9296\n",
      "Epoch 00005: val_loss did not improve from 0.23720\n",
      "238/238 [==============================] - 19s 79ms/step - loss: 0.1950 - acc: 0.9296 - val_loss: 0.2386 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1851 - acc: 0.9339- ETA: 2s - \n",
      "Epoch 00006: val_loss did not improve from 0.23720\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.1851 - acc: 0.9339 - val_loss: 0.2419 - val_acc: 0.9094 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1738 - acc: 0.9377\n",
      "Epoch 00007: val_loss did not improve from 0.23720\n",
      "238/238 [==============================] - 19s 82ms/step - loss: 0.1738 - acc: 0.9377 - val_loss: 0.2413 - val_acc: 0.9136 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1717 - acc: 0.9393\n",
      "Epoch 00008: val_loss did not improve from 0.23720\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.1717 - acc: 0.9393 - val_loss: 0.2421 - val_acc: 0.9136 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1689 - acc: 0.9398\n",
      "Epoch 00009: val_loss did not improve from 0.23720\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 0.1689 - acc: 0.9398 - val_loss: 0.2421 - val_acc: 0.9131 - lr: 4.0000e-05\n",
      "AUC:  0.880836968014803 AUPRC:  0.5712171505879841 F1:  0.450070323488045\n",
      "0.8806210899638736 0.5735068495776692 0.9135234590616376 0.43373493975903615\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2175 - acc: 0.9338\n",
      "Epoch 00001: val_loss improved from inf to 0.18366, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 27s 91ms/step - loss: 0.2175 - acc: 0.9338 - val_loss: 0.1837 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1724 - acc: 0.9431- ETA: 1s - loss: \n",
      "Epoch 00002: val_loss improved from 0.18366 to 0.17355, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 19s 82ms/step - loss: 0.1724 - acc: 0.9431 - val_loss: 0.1736 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1582 - acc: 0.9474\n",
      "Epoch 00003: val_loss improved from 0.17355 to 0.17161, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 21s 86ms/step - loss: 0.1582 - acc: 0.9474 - val_loss: 0.1716 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1495 - acc: 0.9491\n",
      "Epoch 00004: val_loss did not improve from 0.17161\n",
      "238/238 [==============================] - 18s 76ms/step - loss: 0.1495 - acc: 0.9491 - val_loss: 0.1737 - val_acc: 0.9441 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1403 - acc: 0.9517\n",
      "Epoch 00005: val_loss did not improve from 0.17161\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.1403 - acc: 0.9517 - val_loss: 0.1751 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1317 - acc: 0.9557\n",
      "Epoch 00006: val_loss did not improve from 0.17161\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.1317 - acc: 0.9557 - val_loss: 0.1747 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.9558\n",
      "Epoch 00007: val_loss did not improve from 0.17161\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 0.1301 - acc: 0.9558 - val_loss: 0.1750 - val_acc: 0.9422 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1285 - acc: 0.9562\n",
      "Epoch 00008: val_loss did not improve from 0.17161\n",
      "238/238 [==============================] - 19s 81ms/step - loss: 0.1285 - acc: 0.9562 - val_loss: 0.1750 - val_acc: 0.9418 - lr: 4.0000e-05\n",
      "AUC:  0.8833114846200664 AUPRC:  0.5216065602745176 F1:  0.4560669456066946\n",
      "0.8852505579224996 0.5268588442189136 0.9413523459061638 0.45396145610278366\n",
      "Iteration number:  10\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2867 - acc: 0.9034\n",
      "Epoch 00001: val_loss improved from inf to 0.24883, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 26s 88ms/step - loss: 0.2867 - acc: 0.9034 - val_loss: 0.2488 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2349 - acc: 0.9169\n",
      "Epoch 00002: val_loss improved from 0.24883 to 0.23802, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 0.2349 - acc: 0.9169 - val_loss: 0.2380 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2202 - acc: 0.9202\n",
      "Epoch 00003: val_loss improved from 0.23802 to 0.23630, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.2202 - acc: 0.9202 - val_loss: 0.2363 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2102 - acc: 0.9244\n",
      "Epoch 00004: val_loss did not improve from 0.23630\n",
      "238/238 [==============================] - 17s 69ms/step - loss: 0.2102 - acc: 0.9244 - val_loss: 0.2415 - val_acc: 0.9085 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2006 - acc: 0.9273\n",
      "Epoch 00005: val_loss did not improve from 0.23630\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 0.2006 - acc: 0.9273 - val_loss: 0.2378 - val_acc: 0.9127 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1911 - acc: 0.9302\n",
      "Epoch 00006: val_loss did not improve from 0.23630\n",
      "238/238 [==============================] - 19s 79ms/step - loss: 0.1911 - acc: 0.9302 - val_loss: 0.2377 - val_acc: 0.9122 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1889 - acc: 0.9321\n",
      "Epoch 00007: val_loss did not improve from 0.23630\n",
      "238/238 [==============================] - 19s 81ms/step - loss: 0.1889 - acc: 0.9321 - val_loss: 0.2382 - val_acc: 0.9131 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1865 - acc: 0.9334\n",
      "Epoch 00008: val_loss did not improve from 0.23630\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.1865 - acc: 0.9334 - val_loss: 0.2383 - val_acc: 0.9127 - lr: 4.0000e-05\n",
      "AUC:  0.8818084192439863 AUPRC:  0.5812832602773015 F1:  0.4714285714285715\n",
      "0.8799651951713807 0.580570375135221 0.9160533578656854 0.45765230312035665\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2178 - acc: 0.9343\n",
      "Epoch 00001: val_loss improved from inf to 0.17982, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 25s 78ms/step - loss: 0.2178 - acc: 0.9343 - val_loss: 0.1798 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1735 - acc: 0.9434\n",
      "Epoch 00002: val_loss improved from 0.17982 to 0.17142, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 85ms/step - loss: 0.1735 - acc: 0.9434 - val_loss: 0.1714 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1596 - acc: 0.9463\n",
      "Epoch 00003: val_loss improved from 0.17142 to 0.16902, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 20s 84ms/step - loss: 0.1596 - acc: 0.9463 - val_loss: 0.1690 - val_acc: 0.9464 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1499 - acc: 0.9500\n",
      "Epoch 00004: val_loss improved from 0.16902 to 0.16796, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 19s 80ms/step - loss: 0.1499 - acc: 0.9500 - val_loss: 0.1680 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1420 - acc: 0.9517\n",
      "Epoch 00005: val_loss did not improve from 0.16796\n",
      "238/238 [==============================] - 20s 82ms/step - loss: 0.1420 - acc: 0.9517 - val_loss: 0.1685 - val_acc: 0.9441 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1349 - acc: 0.9533\n",
      "Epoch 00006: val_loss did not improve from 0.16796\n",
      "238/238 [==============================] - 18s 76ms/step - loss: 0.1349 - acc: 0.9533 - val_loss: 0.1713 - val_acc: 0.9432 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1269 - acc: 0.9570\n",
      "Epoch 00007: val_loss did not improve from 0.16796\n",
      "238/238 [==============================] - 17s 73ms/step - loss: 0.1269 - acc: 0.9570 - val_loss: 0.1703 - val_acc: 0.9422 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1256 - acc: 0.9572\n",
      "Epoch 00008: val_loss did not improve from 0.16796\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 0.1256 - acc: 0.9572 - val_loss: 0.1706 - val_acc: 0.9422 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1239 - acc: 0.9565\n",
      "Epoch 00009: val_loss did not improve from 0.16796\n",
      "238/238 [==============================] - 18s 75ms/step - loss: 0.1239 - acc: 0.9565 - val_loss: 0.1705 - val_acc: 0.9422 - lr: 4.0000e-05\n",
      "AUC:  0.8924450270767983 AUPRC:  0.5222522862353369 F1:  0.4641350210970464\n",
      "0.8909304430606926 0.5190632107215685 0.9420423183072677 0.4497816593886462\n",
      "Embedding:  fasttext\n",
      "=============================\n",
      "(15219, 64, 100)\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2991 - acc: 0.9000\n",
      "Epoch 00001: val_loss improved from inf to 0.24497, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 187s 762ms/step - loss: 0.2991 - acc: 0.9000 - val_loss: 0.2450 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2380 - acc: 0.9167\n",
      "Epoch 00002: val_loss improved from 0.24497 to 0.23997, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 118s 496ms/step - loss: 0.2380 - acc: 0.9167 - val_loss: 0.2400 - val_acc: 0.9187 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2218 - acc: 0.9219\n",
      "Epoch 00003: val_loss improved from 0.23997 to 0.23990, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 117s 493ms/step - loss: 0.2218 - acc: 0.9219 - val_loss: 0.2399 - val_acc: 0.9145 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2103 - acc: 0.9250\n",
      "Epoch 00004: val_loss improved from 0.23990 to 0.23612, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 114s 479ms/step - loss: 0.2103 - acc: 0.9250 - val_loss: 0.2361 - val_acc: 0.9168 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1987 - acc: 0.9296\n",
      "Epoch 00005: val_loss did not improve from 0.23612\n",
      "238/238 [==============================] - 107s 452ms/step - loss: 0.1987 - acc: 0.9296 - val_loss: 0.2400 - val_acc: 0.9108 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1909 - acc: 0.9319\n",
      "Epoch 00006: val_loss did not improve from 0.23612\n",
      "238/238 [==============================] - 111s 465ms/step - loss: 0.1909 - acc: 0.9319 - val_loss: 0.2377 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1803 - acc: 0.9361\n",
      "Epoch 00007: val_loss did not improve from 0.23612\n",
      "238/238 [==============================] - 93s 393ms/step - loss: 0.1803 - acc: 0.9361 - val_loss: 0.2390 - val_acc: 0.9131 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1776 - acc: 0.9377\n",
      "Epoch 00008: val_loss did not improve from 0.23612\n",
      "238/238 [==============================] - 103s 431ms/step - loss: 0.1776 - acc: 0.9377 - val_loss: 0.2400 - val_acc: 0.9113 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1750 - acc: 0.9376\n",
      "Epoch 00009: val_loss did not improve from 0.23612\n",
      "238/238 [==============================] - 106s 447ms/step - loss: 0.1750 - acc: 0.9376 - val_loss: 0.2400 - val_acc: 0.9122 - lr: 4.0000e-05\n",
      "AUC:  0.8763641069697772 AUPRC:  0.5701552492010675 F1:  0.4535211267605634\n",
      "0.8779672217816549 0.5711533836993039 0.9123735050597976 0.4355555555555556\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2297 - acc: 0.9309\n",
      "Epoch 00001: val_loss improved from inf to 0.18255, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 91s 360ms/step - loss: 0.2297 - acc: 0.9309 - val_loss: 0.1826 - val_acc: 0.9409 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1751 - acc: 0.9434\n",
      "Epoch 00002: val_loss improved from 0.18255 to 0.17501, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 77s 324ms/step - loss: 0.1751 - acc: 0.9434 - val_loss: 0.1750 - val_acc: 0.9427 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1608 - acc: 0.9467\n",
      "Epoch 00003: val_loss improved from 0.17501 to 0.17377, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 73s 307ms/step - loss: 0.1608 - acc: 0.9467 - val_loss: 0.1738 - val_acc: 0.9427 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1506 - acc: 0.9501\n",
      "Epoch 00004: val_loss improved from 0.17377 to 0.17362, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 74s 311ms/step - loss: 0.1506 - acc: 0.9501 - val_loss: 0.1736 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1402 - acc: 0.9523\n",
      "Epoch 00005: val_loss did not improve from 0.17362\n",
      "238/238 [==============================] - 79s 334ms/step - loss: 0.1402 - acc: 0.9523 - val_loss: 0.1745 - val_acc: 0.9450 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1320 - acc: 0.9550\n",
      "Epoch 00006: val_loss did not improve from 0.17362\n",
      "238/238 [==============================] - 79s 334ms/step - loss: 0.1320 - acc: 0.9550 - val_loss: 0.1760 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1221 - acc: 0.9584\n",
      "Epoch 00007: val_loss did not improve from 0.17362\n",
      "238/238 [==============================] - 77s 324ms/step - loss: 0.1221 - acc: 0.9584 - val_loss: 0.1767 - val_acc: 0.9432 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1210 - acc: 0.9590\n",
      "Epoch 00008: val_loss did not improve from 0.17362\n",
      "238/238 [==============================] - 92s 386ms/step - loss: 0.1210 - acc: 0.9590 - val_loss: 0.1774 - val_acc: 0.9422 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1194 - acc: 0.9587\n",
      "Epoch 00009: val_loss did not improve from 0.17362\n",
      "238/238 [==============================] - 73s 309ms/step - loss: 0.1194 - acc: 0.9587 - val_loss: 0.1775 - val_acc: 0.9427 - lr: 4.0000e-05\n",
      "AUC:  0.8839349532593598 AUPRC:  0.5205784844156663 F1:  0.45435244161358807\n",
      "0.8859871716840676 0.5259410578290667 0.9408923643054278 0.4473118279569892\n",
      "Iteration number:  2\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.3049 - acc: 0.9002\n",
      "Epoch 00001: val_loss improved from inf to 0.24422, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 69s 267ms/step - loss: 0.3049 - acc: 0.9002 - val_loss: 0.2442 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2391 - acc: 0.9175\n",
      "Epoch 00002: val_loss improved from 0.24422 to 0.24372, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 64s 269ms/step - loss: 0.2391 - acc: 0.9175 - val_loss: 0.2437 - val_acc: 0.9122 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2237 - acc: 0.9212\n",
      "Epoch 00003: val_loss improved from 0.24372 to 0.23905, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 58s 243ms/step - loss: 0.2237 - acc: 0.9212 - val_loss: 0.2390 - val_acc: 0.9127 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2124 - acc: 0.9242\n",
      "Epoch 00004: val_loss improved from 0.23905 to 0.23756, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 68s 285ms/step - loss: 0.2124 - acc: 0.9242 - val_loss: 0.2376 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2024 - acc: 0.9284\n",
      "Epoch 00005: val_loss did not improve from 0.23756\n",
      "238/238 [==============================] - 61s 258ms/step - loss: 0.2024 - acc: 0.9284 - val_loss: 0.2384 - val_acc: 0.9159 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1947 - acc: 0.9301\n",
      "Epoch 00006: val_loss did not improve from 0.23756\n",
      "238/238 [==============================] - 71s 298ms/step - loss: 0.1947 - acc: 0.9301 - val_loss: 0.2396 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1843 - acc: 0.9354\n",
      "Epoch 00007: val_loss did not improve from 0.23756\n",
      "238/238 [==============================] - 77s 326ms/step - loss: 0.1843 - acc: 0.9354 - val_loss: 0.2382 - val_acc: 0.9159 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1830 - acc: 0.9344\n",
      "Epoch 00008: val_loss did not improve from 0.23756\n",
      "238/238 [==============================] - 65s 270ms/step - loss: 0.1830 - acc: 0.9344 - val_loss: 0.2383 - val_acc: 0.9154 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1800 - acc: 0.9352\n",
      "Epoch 00009: val_loss did not improve from 0.23756\n",
      "238/238 [==============================] - 74s 312ms/step - loss: 0.1800 - acc: 0.9352 - val_loss: 0.2384 - val_acc: 0.9145 - lr: 4.0000e-05\n",
      "AUC:  0.880755463036391 AUPRC:  0.5813650749593096 F1:  0.4779516358463727\n",
      "0.8814278791082915 0.5858472775362433 0.9178932842686293 0.48484848484848486\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2311 - acc: 0.9325\n",
      "Epoch 00001: val_loss improved from inf to 0.18660, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 72s 275ms/step - loss: 0.2311 - acc: 0.9325 - val_loss: 0.1866 - val_acc: 0.9390 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1769 - acc: 0.9425\n",
      "Epoch 00002: val_loss improved from 0.18660 to 0.17433, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 54s 226ms/step - loss: 0.1769 - acc: 0.9425 - val_loss: 0.1743 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1617 - acc: 0.9472\n",
      "Epoch 00003: val_loss did not improve from 0.17433\n",
      "238/238 [==============================] - 59s 248ms/step - loss: 0.1617 - acc: 0.9472 - val_loss: 0.1752 - val_acc: 0.9409 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1515 - acc: 0.9490\n",
      "Epoch 00004: val_loss improved from 0.17433 to 0.17388, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 61s 255ms/step - loss: 0.1515 - acc: 0.9490 - val_loss: 0.1739 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1413 - acc: 0.9524\n",
      "Epoch 00005: val_loss did not improve from 0.17388\n",
      "238/238 [==============================] - 57s 240ms/step - loss: 0.1413 - acc: 0.9524 - val_loss: 0.1758 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1337 - acc: 0.9550\n",
      "Epoch 00006: val_loss did not improve from 0.17388\n",
      "238/238 [==============================] - 50s 212ms/step - loss: 0.1337 - acc: 0.9550 - val_loss: 0.1756 - val_acc: 0.9427 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1244 - acc: 0.9583\n",
      "Epoch 00007: val_loss did not improve from 0.17388\n",
      "238/238 [==============================] - 62s 262ms/step - loss: 0.1244 - acc: 0.9583 - val_loss: 0.1769 - val_acc: 0.9409 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1232 - acc: 0.9592\n",
      "Epoch 00008: val_loss did not improve from 0.17388\n",
      "238/238 [==============================] - 63s 263ms/step - loss: 0.1232 - acc: 0.9592 - val_loss: 0.1773 - val_acc: 0.9432 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1211 - acc: 0.9590\n",
      "Epoch 00009: val_loss did not improve from 0.17388\n",
      "238/238 [==============================] - 56s 236ms/step - loss: 0.1211 - acc: 0.9590 - val_loss: 0.1773 - val_acc: 0.9422 - lr: 4.0000e-05\n",
      "AUC:  0.8869836290712736 AUPRC:  0.5088273455727309 F1:  0.4344086021505376\n",
      "0.8860230659987203 0.5065196782228351 0.9392824287028518 0.41592920353982304\n",
      "Iteration number:  3\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2848 - acc: 0.9027\n",
      "Epoch 00001: val_loss improved from inf to 0.24764, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 61s 233ms/step - loss: 0.2848 - acc: 0.9027 - val_loss: 0.2476 - val_acc: 0.9131 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2385 - acc: 0.9158\n",
      "Epoch 00002: val_loss improved from 0.24764 to 0.24096, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 49s 205ms/step - loss: 0.2385 - acc: 0.9158 - val_loss: 0.2410 - val_acc: 0.9113 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2216 - acc: 0.9204\n",
      "Epoch 00003: val_loss improved from 0.24096 to 0.23857, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 48s 201ms/step - loss: 0.2216 - acc: 0.9204 - val_loss: 0.2386 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2085 - acc: 0.9244\n",
      "Epoch 00004: val_loss did not improve from 0.23857\n",
      "238/238 [==============================] - 50s 209ms/step - loss: 0.2085 - acc: 0.9244 - val_loss: 0.2414 - val_acc: 0.9113 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1977 - acc: 0.9286\n",
      "Epoch 00005: val_loss did not improve from 0.23857\n",
      "238/238 [==============================] - 48s 202ms/step - loss: 0.1977 - acc: 0.9286 - val_loss: 0.2436 - val_acc: 0.9094 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1853 - acc: 0.9321\n",
      "Epoch 00006: val_loss did not improve from 0.23857\n",
      "238/238 [==============================] - 49s 205ms/step - loss: 0.1853 - acc: 0.9321 - val_loss: 0.2398 - val_acc: 0.9127 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1831 - acc: 0.9331\n",
      "Epoch 00007: val_loss did not improve from 0.23857\n",
      "238/238 [==============================] - 67s 282ms/step - loss: 0.1831 - acc: 0.9331 - val_loss: 0.2402 - val_acc: 0.9122 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1806 - acc: 0.9343\n",
      "Epoch 00008: val_loss did not improve from 0.23857\n",
      "238/238 [==============================] - 48s 202ms/step - loss: 0.1806 - acc: 0.9343 - val_loss: 0.2403 - val_acc: 0.9122 - lr: 4.0000e-05\n",
      "AUC:  0.8795428011278527 AUPRC:  0.5750301010882666 F1:  0.46910112359550565\n",
      "0.8801436249889858 0.5782620761883738 0.9144434222631095 0.4294478527607362\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2304 - acc: 0.9305\n",
      "Epoch 00001: val_loss improved from inf to 0.18333, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 62s 237ms/step - loss: 0.2304 - acc: 0.9305 - val_loss: 0.1833 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1767 - acc: 0.9422\n",
      "Epoch 00002: val_loss improved from 0.18333 to 0.17713, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 44s 183ms/step - loss: 0.1767 - acc: 0.9422 - val_loss: 0.1771 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1623 - acc: 0.9441\n",
      "Epoch 00003: val_loss improved from 0.17713 to 0.17233, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 53s 223ms/step - loss: 0.1623 - acc: 0.9441 - val_loss: 0.1723 - val_acc: 0.9409 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1520 - acc: 0.9488\n",
      "Epoch 00004: val_loss did not improve from 0.17233\n",
      "238/238 [==============================] - 49s 207ms/step - loss: 0.1520 - acc: 0.9488 - val_loss: 0.1766 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1449 - acc: 0.9496\n",
      "Epoch 00005: val_loss did not improve from 0.17233\n",
      "238/238 [==============================] - 50s 209ms/step - loss: 0.1449 - acc: 0.9496 - val_loss: 0.1739 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1354 - acc: 0.9537\n",
      "Epoch 00006: val_loss did not improve from 0.17233\n",
      "238/238 [==============================] - 48s 202ms/step - loss: 0.1354 - acc: 0.9537 - val_loss: 0.1742 - val_acc: 0.9422 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1341 - acc: 0.9544\n",
      "Epoch 00007: val_loss did not improve from 0.17233\n",
      "238/238 [==============================] - 64s 270ms/step - loss: 0.1341 - acc: 0.9544 - val_loss: 0.1750 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1314 - acc: 0.9549\n",
      "Epoch 00008: val_loss did not improve from 0.17233\n",
      "238/238 [==============================] - 59s 247ms/step - loss: 0.1314 - acc: 0.9549 - val_loss: 0.1751 - val_acc: 0.9418 - lr: 4.0000e-05\n",
      "AUC:  0.8864834495997005 AUPRC:  0.5105025643395671 F1:  0.4434968017057569\n",
      "0.8858443747366451 0.5155673030203852 0.9399724011039559 0.41348314606741576\n",
      "Iteration number:  4\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.3067 - acc: 0.9003\n",
      "Epoch 00001: val_loss improved from inf to 0.24739, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 65s 246ms/step - loss: 0.3067 - acc: 0.9003 - val_loss: 0.2474 - val_acc: 0.9177 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2422 - acc: 0.9158\n",
      "Epoch 00002: val_loss improved from 0.24739 to 0.24174, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 52s 221ms/step - loss: 0.2422 - acc: 0.9158 - val_loss: 0.2417 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2272 - acc: 0.9204\n",
      "Epoch 00003: val_loss did not improve from 0.24174\n",
      "238/238 [==============================] - 56s 237ms/step - loss: 0.2272 - acc: 0.9204 - val_loss: 0.2437 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2152 - acc: 0.9230- ETA: 3s - loss: 0.215\n",
      "Epoch 00004: val_loss did not improve from 0.24174\n",
      "238/238 [==============================] - 62s 260ms/step - loss: 0.2152 - acc: 0.9230 - val_loss: 0.2464 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2029 - acc: 0.9279\n",
      "Epoch 00005: val_loss did not improve from 0.24174\n",
      "238/238 [==============================] - 75s 317ms/step - loss: 0.2029 - acc: 0.9279 - val_loss: 0.2430 - val_acc: 0.9168 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2005 - acc: 0.9290\n",
      "Epoch 00006: val_loss did not improve from 0.24174\n",
      "238/238 [==============================] - 64s 266ms/step - loss: 0.2005 - acc: 0.9290 - val_loss: 0.2425 - val_acc: 0.9173 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1981 - acc: 0.9294\n",
      "Epoch 00007: val_loss did not improve from 0.24174\n",
      "238/238 [==============================] - 76s 321ms/step - loss: 0.1981 - acc: 0.9294 - val_loss: 0.2426 - val_acc: 0.9173 - lr: 4.0000e-05\n",
      "AUC:  0.8814876310688167 AUPRC:  0.5822363585363335 F1:  0.48046309696092626\n",
      "0.874730152436338 0.5669108662740662 0.9142134314627415 0.4305343511450382\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2292 - acc: 0.9331\n",
      "Epoch 00001: val_loss improved from inf to 0.18015, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 93s 362ms/step - loss: 0.2292 - acc: 0.9331 - val_loss: 0.1802 - val_acc: 0.9441 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1755 - acc: 0.9436\n",
      "Epoch 00002: val_loss improved from 0.18015 to 0.17480, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 63s 266ms/step - loss: 0.1755 - acc: 0.9436 - val_loss: 0.1748 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1603 - acc: 0.9472\n",
      "Epoch 00003: val_loss improved from 0.17480 to 0.17046, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 72s 304ms/step - loss: 0.1603 - acc: 0.9472 - val_loss: 0.1705 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1487 - acc: 0.9511\n",
      "Epoch 00004: val_loss improved from 0.17046 to 0.16911, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 54s 226ms/step - loss: 0.1487 - acc: 0.9511 - val_loss: 0.1691 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1410 - acc: 0.9523\n",
      "Epoch 00005: val_loss did not improve from 0.16911\n",
      "238/238 [==============================] - 70s 295ms/step - loss: 0.1410 - acc: 0.9523 - val_loss: 0.1692 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1336 - acc: 0.9555\n",
      "Epoch 00006: val_loss did not improve from 0.16911\n",
      "238/238 [==============================] - 69s 289ms/step - loss: 0.1336 - acc: 0.9555 - val_loss: 0.1716 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1245 - acc: 0.9591\n",
      "Epoch 00007: val_loss did not improve from 0.16911\n",
      "238/238 [==============================] - 69s 290ms/step - loss: 0.1245 - acc: 0.9591 - val_loss: 0.1699 - val_acc: 0.9464 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1227 - acc: 0.9591\n",
      "Epoch 00008: val_loss did not improve from 0.16911\n",
      "238/238 [==============================] - 78s 328ms/step - loss: 0.1227 - acc: 0.9591 - val_loss: 0.1700 - val_acc: 0.9469 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1219 - acc: 0.9593\n",
      "Epoch 00009: val_loss did not improve from 0.16911\n",
      "238/238 [==============================] - 64s 268ms/step - loss: 0.1219 - acc: 0.9593 - val_loss: 0.1699 - val_acc: 0.9464 - lr: 4.0000e-05\n",
      "AUC:  0.8878458729341263 AUPRC:  0.5215827184533763 F1:  0.4491525423728813\n",
      "0.8864775972657898 0.5192444113395958 0.9397424103035878 0.425438596491228\n",
      "Iteration number:  5\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.3012 - acc: 0.9003\n",
      "Epoch 00001: val_loss improved from inf to 0.25132, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 74s 290ms/step - loss: 0.3012 - acc: 0.9003 - val_loss: 0.2513 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2422 - acc: 0.9160\n",
      "Epoch 00002: val_loss improved from 0.25132 to 0.24040, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 73s 308ms/step - loss: 0.2422 - acc: 0.9160 - val_loss: 0.2404 - val_acc: 0.9187 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2249 - acc: 0.9200\n",
      "Epoch 00003: val_loss improved from 0.24040 to 0.23859, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 60s 251ms/step - loss: 0.2249 - acc: 0.9200 - val_loss: 0.2386 - val_acc: 0.9154 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2136 - acc: 0.9241\n",
      "Epoch 00004: val_loss did not improve from 0.23859\n",
      "238/238 [==============================] - 82s 345ms/step - loss: 0.2136 - acc: 0.9241 - val_loss: 0.2399 - val_acc: 0.9131 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2036 - acc: 0.9281\n",
      "Epoch 00005: val_loss did not improve from 0.23859\n",
      "238/238 [==============================] - 65s 275ms/step - loss: 0.2036 - acc: 0.9281 - val_loss: 0.2393 - val_acc: 0.9159 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1932 - acc: 0.9306\n",
      "Epoch 00006: val_loss did not improve from 0.23859\n",
      "238/238 [==============================] - 68s 284ms/step - loss: 0.1932 - acc: 0.9306 - val_loss: 0.2395 - val_acc: 0.9164 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1912 - acc: 0.9313\n",
      "Epoch 00007: val_loss did not improve from 0.23859\n",
      "238/238 [==============================] - 66s 279ms/step - loss: 0.1912 - acc: 0.9313 - val_loss: 0.2400 - val_acc: 0.9159 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1892 - acc: 0.9319\n",
      "Epoch 00008: val_loss did not improve from 0.23859\n",
      "238/238 [==============================] - 57s 240ms/step - loss: 0.1892 - acc: 0.9319 - val_loss: 0.2399 - val_acc: 0.9159 - lr: 4.0000e-05\n",
      "AUC:  0.876024870032602 AUPRC:  0.5781544409402865 F1:  0.4628820960698691\n",
      "0.8746200105736188 0.5721166061498664 0.9158233670653174 0.43167701863354035\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2336 - acc: 0.9324\n",
      "Epoch 00001: val_loss improved from inf to 0.17934, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 88s 346ms/step - loss: 0.2336 - acc: 0.9324 - val_loss: 0.1793 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1763 - acc: 0.9419\n",
      "Epoch 00002: val_loss improved from 0.17934 to 0.17455, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 78s 328ms/step - loss: 0.1763 - acc: 0.9419 - val_loss: 0.1745 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1642 - acc: 0.9467\n",
      "Epoch 00003: val_loss improved from 0.17455 to 0.17253, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 67s 281ms/step - loss: 0.1642 - acc: 0.9467 - val_loss: 0.1725 - val_acc: 0.9427 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1533 - acc: 0.9489\n",
      "Epoch 00004: val_loss did not improve from 0.17253\n",
      "238/238 [==============================] - 83s 348ms/step - loss: 0.1533 - acc: 0.9489 - val_loss: 0.1737 - val_acc: 0.9422 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1455 - acc: 0.9507\n",
      "Epoch 00005: val_loss did not improve from 0.17253\n",
      "238/238 [==============================] - 75s 314ms/step - loss: 0.1455 - acc: 0.9507 - val_loss: 0.1739 - val_acc: 0.9390 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1371 - acc: 0.9532\n",
      "Epoch 00006: val_loss did not improve from 0.17253\n",
      "238/238 [==============================] - 70s 295ms/step - loss: 0.1371 - acc: 0.9532 - val_loss: 0.1743 - val_acc: 0.9390 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1347 - acc: 0.9545\n",
      "Epoch 00007: val_loss did not improve from 0.17253\n",
      "238/238 [==============================] - 90s 380ms/step - loss: 0.1347 - acc: 0.9545 - val_loss: 0.1747 - val_acc: 0.9390 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1338 - acc: 0.9545\n",
      "Epoch 00008: val_loss did not improve from 0.17253\n",
      "238/238 [==============================] - 71s 299ms/step - loss: 0.1338 - acc: 0.9545 - val_loss: 0.1748 - val_acc: 0.9390 - lr: 4.0000e-05\n",
      "AUC:  0.8883007943567894 AUPRC:  0.5167941225057879 F1:  0.436830835117773\n",
      "0.8869387611779578 0.5165403950031435 0.9390524379024839 0.39359267734553777\n",
      "Iteration number:  6\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2935 - acc: 0.9020\n",
      "Epoch 00001: val_loss improved from inf to 0.24865, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 75s 292ms/step - loss: 0.2935 - acc: 0.9020 - val_loss: 0.2486 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2385 - acc: 0.9158\n",
      "Epoch 00002: val_loss improved from 0.24865 to 0.24379, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 84s 352ms/step - loss: 0.2385 - acc: 0.9158 - val_loss: 0.2438 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2226 - acc: 0.9193\n",
      "Epoch 00003: val_loss improved from 0.24379 to 0.24019, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 72s 303ms/step - loss: 0.2226 - acc: 0.9193 - val_loss: 0.2402 - val_acc: 0.9168 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2089 - acc: 0.9236\n",
      "Epoch 00004: val_loss did not improve from 0.24019\n",
      "238/238 [==============================] - 69s 292ms/step - loss: 0.2089 - acc: 0.9236 - val_loss: 0.2404 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1989 - acc: 0.9269\n",
      "Epoch 00005: val_loss did not improve from 0.24019\n",
      "238/238 [==============================] - 84s 353ms/step - loss: 0.1989 - acc: 0.9269 - val_loss: 0.2437 - val_acc: 0.9154 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1864 - acc: 0.9330\n",
      "Epoch 00006: val_loss did not improve from 0.24019\n",
      "238/238 [==============================] - 68s 286ms/step - loss: 0.1864 - acc: 0.9330 - val_loss: 0.2426 - val_acc: 0.9136 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1841 - acc: 0.9344\n",
      "Epoch 00007: val_loss did not improve from 0.24019\n",
      "238/238 [==============================] - 77s 323ms/step - loss: 0.1841 - acc: 0.9344 - val_loss: 0.2430 - val_acc: 0.9136 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1815 - acc: 0.9349\n",
      "Epoch 00008: val_loss did not improve from 0.24019\n",
      "238/238 [==============================] - 88s 372ms/step - loss: 0.1815 - acc: 0.9349 - val_loss: 0.2432 - val_acc: 0.9131 - lr: 4.0000e-05\n",
      "AUC:  0.8806304520222047 AUPRC:  0.58076847343074 F1:  0.46685878962536015\n",
      "0.8792613886686054 0.5823330321656247 0.9153633854645814 0.4666666666666667\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2333 - acc: 0.9325\n",
      "Epoch 00001: val_loss improved from inf to 0.18312, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 77s 292ms/step - loss: 0.2333 - acc: 0.9325 - val_loss: 0.1831 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1759 - acc: 0.9438\n",
      "Epoch 00002: val_loss improved from 0.18312 to 0.17667, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 62s 261ms/step - loss: 0.1759 - acc: 0.9438 - val_loss: 0.1767 - val_acc: 0.9441 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1629 - acc: 0.9469\n",
      "Epoch 00003: val_loss improved from 0.17667 to 0.17548, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 85s 359ms/step - loss: 0.1629 - acc: 0.9469 - val_loss: 0.1755 - val_acc: 0.9390 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1546 - acc: 0.9475\n",
      "Epoch 00004: val_loss improved from 0.17548 to 0.17460, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 73s 308ms/step - loss: 0.1546 - acc: 0.9475 - val_loss: 0.1746 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1470 - acc: 0.9505\n",
      "Epoch 00005: val_loss did not improve from 0.17460\n",
      "238/238 [==============================] - 69s 290ms/step - loss: 0.1470 - acc: 0.9505 - val_loss: 0.1748 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1396 - acc: 0.9543\n",
      "Epoch 00006: val_loss did not improve from 0.17460\n",
      "238/238 [==============================] - 83s 347ms/step - loss: 0.1396 - acc: 0.9543 - val_loss: 0.1771 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1315 - acc: 0.9550\n",
      "Epoch 00007: val_loss did not improve from 0.17460\n",
      "238/238 [==============================] - 70s 293ms/step - loss: 0.1315 - acc: 0.9550 - val_loss: 0.1760 - val_acc: 0.9404 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1300 - acc: 0.9555\n",
      "Epoch 00008: val_loss did not improve from 0.17460\n",
      "238/238 [==============================] - 53s 222ms/step - loss: 0.1300 - acc: 0.9555 - val_loss: 0.1762 - val_acc: 0.9399 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1286 - acc: 0.9562\n",
      "Epoch 00009: val_loss did not improve from 0.17460\n",
      "238/238 [==============================] - 64s 269ms/step - loss: 0.1286 - acc: 0.9562 - val_loss: 0.1761 - val_acc: 0.9404 - lr: 4.0000e-05\n",
      "AUC:  0.8914212587980087 AUPRC:  0.5160717565342068 F1:  0.42735042735042733\n",
      "0.8906343149648079 0.5188011193906354 0.9399724011039559 0.42888402625820565\n",
      "Iteration number:  7\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2868 - acc: 0.9034\n",
      "Epoch 00001: val_loss improved from inf to 0.24802, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 77s 299ms/step - loss: 0.2868 - acc: 0.9034 - val_loss: 0.2480 - val_acc: 0.9136 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2386 - acc: 0.9175\n",
      "Epoch 00002: val_loss improved from 0.24802 to 0.24097, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 87s 364ms/step - loss: 0.2386 - acc: 0.9175 - val_loss: 0.2410 - val_acc: 0.9131 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2183 - acc: 0.9221\n",
      "Epoch 00003: val_loss improved from 0.24097 to 0.23988, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 72s 303ms/step - loss: 0.2183 - acc: 0.9221 - val_loss: 0.2399 - val_acc: 0.9127 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2049 - acc: 0.9271\n",
      "Epoch 00004: val_loss did not improve from 0.23988\n",
      "238/238 [==============================] - 64s 268ms/step - loss: 0.2049 - acc: 0.9271 - val_loss: 0.2422 - val_acc: 0.9127 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1903 - acc: 0.9317\n",
      "Epoch 00005: val_loss did not improve from 0.23988\n",
      "238/238 [==============================] - 86s 360ms/step - loss: 0.1903 - acc: 0.9317 - val_loss: 0.2438 - val_acc: 0.9117 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1767 - acc: 0.9383\n",
      "Epoch 00006: val_loss did not improve from 0.23988\n",
      "238/238 [==============================] - 71s 297ms/step - loss: 0.1767 - acc: 0.9383 - val_loss: 0.2454 - val_acc: 0.9094 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1737 - acc: 0.9390\n",
      "Epoch 00007: val_loss did not improve from 0.23988\n",
      "238/238 [==============================] - 75s 316ms/step - loss: 0.1737 - acc: 0.9390 - val_loss: 0.2461 - val_acc: 0.9080 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1712 - acc: 0.9395\n",
      "Epoch 00008: val_loss did not improve from 0.23988\n",
      "238/238 [==============================] - 72s 302ms/step - loss: 0.1712 - acc: 0.9395 - val_loss: 0.2463 - val_acc: 0.9085 - lr: 4.0000e-05\n",
      "AUC:  0.8773350074896467 AUPRC:  0.5706399160199481 F1:  0.474964234620887\n",
      "0.8788665300907569 0.575770543548499 0.9165133394664213 0.4606240713224368\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2246 - acc: 0.9333\n",
      "Epoch 00001: val_loss improved from inf to 0.18242, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 81s 312ms/step - loss: 0.2246 - acc: 0.9333 - val_loss: 0.1824 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1739 - acc: 0.9441\n",
      "Epoch 00002: val_loss improved from 0.18242 to 0.17782, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 60s 254ms/step - loss: 0.1739 - acc: 0.9441 - val_loss: 0.1778 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1585 - acc: 0.9464\n",
      "Epoch 00003: val_loss improved from 0.17782 to 0.17691, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 71s 297ms/step - loss: 0.1585 - acc: 0.9464 - val_loss: 0.1769 - val_acc: 0.9399 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1464 - acc: 0.9507\n",
      "Epoch 00004: val_loss did not improve from 0.17691\n",
      "238/238 [==============================] - 70s 293ms/step - loss: 0.1464 - acc: 0.9507 - val_loss: 0.1770 - val_acc: 0.9404 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1368 - acc: 0.9528\n",
      "Epoch 00005: val_loss did not improve from 0.17691\n",
      "238/238 [==============================] - 79s 331ms/step - loss: 0.1368 - acc: 0.9528 - val_loss: 0.1789 - val_acc: 0.9395 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1263 - acc: 0.9561\n",
      "Epoch 00006: val_loss did not improve from 0.17691\n",
      "238/238 [==============================] - 74s 311ms/step - loss: 0.1263 - acc: 0.9561 - val_loss: 0.1791 - val_acc: 0.9399 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1229 - acc: 0.9578\n",
      "Epoch 00007: val_loss did not improve from 0.17691\n",
      "238/238 [==============================] - 72s 301ms/step - loss: 0.1229 - acc: 0.9578 - val_loss: 0.1799 - val_acc: 0.9390 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1218 - acc: 0.9592\n",
      "Epoch 00008: val_loss did not improve from 0.17691\n",
      "238/238 [==============================] - 90s 379ms/step - loss: 0.1218 - acc: 0.9592 - val_loss: 0.1800 - val_acc: 0.9390 - lr: 4.0000e-05\n",
      "AUC:  0.8830368150818545 AUPRC:  0.5089945378897468 F1:  0.41921397379912667\n",
      "0.8839794309970816 0.5060476118261461 0.9388224471021159 0.3981900452488688\n",
      "Iteration number:  8\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2914 - acc: 0.9006\n",
      "Epoch 00001: val_loss improved from inf to 0.24604, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 95s 367ms/step - loss: 0.2914 - acc: 0.9006 - val_loss: 0.2460 - val_acc: 0.9154 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2384 - acc: 0.9163\n",
      "Epoch 00002: val_loss improved from 0.24604 to 0.23968, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 58s 243ms/step - loss: 0.2384 - acc: 0.9163 - val_loss: 0.2397 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2206 - acc: 0.9198\n",
      "Epoch 00003: val_loss improved from 0.23968 to 0.23830, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 76s 319ms/step - loss: 0.2206 - acc: 0.9198 - val_loss: 0.2383 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2092 - acc: 0.9237\n",
      "Epoch 00004: val_loss did not improve from 0.23830\n",
      "238/238 [==============================] - 66s 277ms/step - loss: 0.2092 - acc: 0.9237 - val_loss: 0.2395 - val_acc: 0.9150 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1967 - acc: 0.9286\n",
      "Epoch 00005: val_loss did not improve from 0.23830\n",
      "238/238 [==============================] - 66s 277ms/step - loss: 0.1967 - acc: 0.9286 - val_loss: 0.2389 - val_acc: 0.9113 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1851 - acc: 0.9328\n",
      "Epoch 00006: val_loss did not improve from 0.23830\n",
      "238/238 [==============================] - 70s 295ms/step - loss: 0.1851 - acc: 0.9328 - val_loss: 0.2389 - val_acc: 0.9136 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1822 - acc: 0.9340\n",
      "Epoch 00007: val_loss did not improve from 0.23830\n",
      "238/238 [==============================] - 63s 264ms/step - loss: 0.1822 - acc: 0.9340 - val_loss: 0.2392 - val_acc: 0.9113 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1815 - acc: 0.9337\n",
      "Epoch 00008: val_loss did not improve from 0.23830\n",
      "238/238 [==============================] - 60s 250ms/step - loss: 0.1815 - acc: 0.9337 - val_loss: 0.2393 - val_acc: 0.9113 - lr: 4.0000e-05\n",
      "AUC:  0.8809316900167417 AUPRC:  0.5876442463139073 F1:  0.47851002865329517\n",
      "0.8826796413780951 0.5851487799914739 0.9183532658693653 0.4892086330935252\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2480 - acc: 0.9300\n",
      "Epoch 00001: val_loss improved from inf to 0.18132, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 74s 280ms/step - loss: 0.2480 - acc: 0.9300 - val_loss: 0.1813 - val_acc: 0.9432 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1778 - acc: 0.9418\n",
      "Epoch 00002: val_loss improved from 0.18132 to 0.17567, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 65s 274ms/step - loss: 0.1778 - acc: 0.9418 - val_loss: 0.1757 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1646 - acc: 0.9455\n",
      "Epoch 00003: val_loss improved from 0.17567 to 0.17271, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 72s 304ms/step - loss: 0.1646 - acc: 0.9455 - val_loss: 0.1727 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1557 - acc: 0.9483\n",
      "Epoch 00004: val_loss did not improve from 0.17271\n",
      "238/238 [==============================] - 60s 253ms/step - loss: 0.1557 - acc: 0.9483 - val_loss: 0.1729 - val_acc: 0.9432 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1499 - acc: 0.9491\n",
      "Epoch 00005: val_loss improved from 0.17271 to 0.17262, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 76s 318ms/step - loss: 0.1499 - acc: 0.9491 - val_loss: 0.1726 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1415 - acc: 0.9526\n",
      "Epoch 00006: val_loss improved from 0.17262 to 0.17147, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 53s 223ms/step - loss: 0.1415 - acc: 0.9526 - val_loss: 0.1715 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1398 - acc: 0.9516- ETA: 5s - loss: 0.1382 - acc - ETA: 4s - loss: 0.1373 - acc: 0.9 - ETA: 3s - loss: \n",
      "Epoch 00007: val_loss did not improve from 0.17147\n",
      "238/238 [==============================] - 46s 192ms/step - loss: 0.1398 - acc: 0.9516 - val_loss: 0.1716 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1390 - acc: 0.9533\n",
      "Epoch 00008: val_loss did not improve from 0.17147\n",
      "238/238 [==============================] - 46s 192ms/step - loss: 0.1390 - acc: 0.9533 - val_loss: 0.1715 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1373 - acc: 0.9541  ETA: 11s -\n",
      "Epoch 00009: val_loss did not improve from 0.17147\n",
      "238/238 [==============================] - 47s 196ms/step - loss: 0.1373 - acc: 0.9541 - val_loss: 0.1716 - val_acc: 0.9413 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1374 - acc: 0.9539-\n",
      "Epoch 00010: val_loss did not improve from 0.17147\n",
      "238/238 [==============================] - 46s 193ms/step - loss: 0.1374 - acc: 0.9539 - val_loss: 0.1716 - val_acc: 0.9413 - lr: 4.0000e-05\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1373 - acc: 0.9535\n",
      "Epoch 00011: val_loss did not improve from 0.17147\n",
      "238/238 [==============================] - 47s 198ms/step - loss: 0.1373 - acc: 0.9535 - val_loss: 0.1716 - val_acc: 0.9413 - lr: 1.0000e-05\n",
      "AUC:  0.8907302932409445 AUPRC:  0.5300777589121812 F1:  0.46881720430107526\n",
      "0.8901118966243738 0.5293769245253684 0.9425022999080037 0.4493392070484582\n",
      "Iteration number:  9\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2953 - acc: 0.9019\n",
      "Epoch 00001: val_loss improved from inf to 0.24656, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 52s 196ms/step - loss: 0.2953 - acc: 0.9019 - val_loss: 0.2466 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2386 - acc: 0.9144\n",
      "Epoch 00002: val_loss improved from 0.24656 to 0.23825, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 46s 193ms/step - loss: 0.2386 - acc: 0.9144 - val_loss: 0.2382 - val_acc: 0.9154 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2211 - acc: 0.9216\n",
      "Epoch 00003: val_loss did not improve from 0.23825\n",
      "238/238 [==============================] - 45s 191ms/step - loss: 0.2211 - acc: 0.9216 - val_loss: 0.2409 - val_acc: 0.9104 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2073 - acc: 0.9259\n",
      "Epoch 00004: val_loss improved from 0.23825 to 0.23563, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 45s 188ms/step - loss: 0.2073 - acc: 0.9259 - val_loss: 0.2356 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1972 - acc: 0.9305\n",
      "Epoch 00005: val_loss did not improve from 0.23563\n",
      "238/238 [==============================] - 47s 199ms/step - loss: 0.1972 - acc: 0.9305 - val_loss: 0.2379 - val_acc: 0.9140 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1853 - acc: 0.9328\n",
      "Epoch 00006: val_loss did not improve from 0.23563\n",
      "238/238 [==============================] - 46s 194ms/step - loss: 0.1853 - acc: 0.9328 - val_loss: 0.2404 - val_acc: 0.9122 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1740 - acc: 0.9375\n",
      "Epoch 00007: val_loss did not improve from 0.23563\n",
      "238/238 [==============================] - 47s 199ms/step - loss: 0.1740 - acc: 0.9375 - val_loss: 0.2406 - val_acc: 0.9122 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1726 - acc: 0.9378\n",
      "Epoch 00008: val_loss did not improve from 0.23563\n",
      "238/238 [==============================] - 45s 190ms/step - loss: 0.1726 - acc: 0.9378 - val_loss: 0.2412 - val_acc: 0.9131 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1697 - acc: 0.9388- ETA: 4s - \n",
      "Epoch 00009: val_loss did not improve from 0.23563\n",
      "238/238 [==============================] - 45s 188ms/step - loss: 0.1697 - acc: 0.9388 - val_loss: 0.2411 - val_acc: 0.9127 - lr: 4.0000e-05\n",
      "AUC:  0.8740158824566042 AUPRC:  0.567124293825653 F1:  0.46086956521739125\n",
      "0.8776323905189884 0.5708068424122661 0.9128334866605335 0.42488619119878607\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2187 - acc: 0.9349\n",
      "Epoch 00001: val_loss improved from inf to 0.17731, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 57s 214ms/step - loss: 0.2187 - acc: 0.9349 - val_loss: 0.1773 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1727 - acc: 0.9429\n",
      "Epoch 00002: val_loss did not improve from 0.17731\n",
      "238/238 [==============================] - 47s 198ms/step - loss: 0.1727 - acc: 0.9429 - val_loss: 0.1805 - val_acc: 0.9432 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1561 - acc: 0.9470\n",
      "Epoch 00003: val_loss improved from 0.17731 to 0.17650, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 49s 205ms/step - loss: 0.1561 - acc: 0.9470 - val_loss: 0.1765 - val_acc: 0.9432 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1428 - acc: 0.9519\n",
      "Epoch 00004: val_loss did not improve from 0.17650\n",
      "238/238 [==============================] - 49s 206ms/step - loss: 0.1428 - acc: 0.9519 - val_loss: 0.1784 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1346 - acc: 0.9524 - ETA: 9s - loss: 0 - ETA:\n",
      "Epoch 00005: val_loss did not improve from 0.17650\n",
      "238/238 [==============================] - 48s 203ms/step - loss: 0.1346 - acc: 0.9524 - val_loss: 0.1785 - val_acc: 0.9422 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1222 - acc: 0.9581\n",
      "Epoch 00006: val_loss did not improve from 0.17650\n",
      "238/238 [==============================] - 50s 211ms/step - loss: 0.1222 - acc: 0.9581 - val_loss: 0.1796 - val_acc: 0.9418 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1203 - acc: 0.9581\n",
      "Epoch 00007: val_loss did not improve from 0.17650\n",
      "238/238 [==============================] - 48s 200ms/step - loss: 0.1203 - acc: 0.9581 - val_loss: 0.1804 - val_acc: 0.9409 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1187 - acc: 0.9589\n",
      "Epoch 00008: val_loss did not improve from 0.17650\n",
      "238/238 [==============================] - 49s 207ms/step - loss: 0.1187 - acc: 0.9589 - val_loss: 0.1806 - val_acc: 0.9413 - lr: 4.0000e-05\n",
      "AUC:  0.8754252695975155 AUPRC:  0.488303555303919 F1:  0.4112554112554113\n",
      "0.8810181500382352 0.4987158967541208 0.9397424103035878 0.39908256880733944\n",
      "Iteration number:  10\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.3076 - acc: 0.9002\n",
      "Epoch 00001: val_loss improved from inf to 0.25112, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 55s 212ms/step - loss: 0.3076 - acc: 0.9002 - val_loss: 0.2511 - val_acc: 0.9117 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2412 - acc: 0.9166\n",
      "Epoch 00002: val_loss improved from 0.25112 to 0.24024, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 50s 211ms/step - loss: 0.2412 - acc: 0.9166 - val_loss: 0.2402 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2223 - acc: 0.9208\n",
      "Epoch 00003: val_loss did not improve from 0.24024\n",
      "238/238 [==============================] - 49s 205ms/step - loss: 0.2223 - acc: 0.9208 - val_loss: 0.2414 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2121 - acc: 0.9246- ETA: 2s - loss: 0.2127 \n",
      "Epoch 00004: val_loss improved from 0.24024 to 0.23906, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 49s 206ms/step - loss: 0.2121 - acc: 0.9246 - val_loss: 0.2391 - val_acc: 0.9136 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2016 - acc: 0.9282\n",
      "Epoch 00005: val_loss did not improve from 0.23906\n",
      "238/238 [==============================] - 49s 204ms/step - loss: 0.2016 - acc: 0.9282 - val_loss: 0.2419 - val_acc: 0.9145 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1930 - acc: 0.9309\n",
      "Epoch 00006: val_loss did not improve from 0.23906\n",
      "238/238 [==============================] - 49s 204ms/step - loss: 0.1930 - acc: 0.9309 - val_loss: 0.2409 - val_acc: 0.9164 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1819 - acc: 0.9349\n",
      "Epoch 00007: val_loss did not improve from 0.23906\n",
      "238/238 [==============================] - 50s 209ms/step - loss: 0.1819 - acc: 0.9349 - val_loss: 0.2416 - val_acc: 0.9150 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1799 - acc: 0.9352\n",
      "Epoch 00008: val_loss did not improve from 0.23906\n",
      "238/238 [==============================] - 50s 209ms/step - loss: 0.1799 - acc: 0.9352 - val_loss: 0.2423 - val_acc: 0.9145 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1779 - acc: 0.9362\n",
      "Epoch 00009: val_loss did not improve from 0.23906\n",
      "238/238 [==============================] - 50s 210ms/step - loss: 0.1779 - acc: 0.9362 - val_loss: 0.2424 - val_acc: 0.9140 - lr: 4.0000e-05\n",
      "AUC:  0.878381355185479 AUPRC:  0.5757222362040333 F1:  0.47042253521126765\n",
      "0.8786076967133669 0.5742992459889529 0.9132934682612696 0.46524822695035456\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (15219, 24, 104) x_dev_lstm (2164, 24, 104)\n",
      "x_train_ner (15219, 64, 100) x_dev_ner (2164, 64, 100)\n",
      "(15219,)\n",
      "(15219, 24, 104) (15219, 64, 100) 2\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2184 - acc: 0.9348\n",
      "Epoch 00001: val_loss improved from inf to 0.17811, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 54s 207ms/step - loss: 0.2184 - acc: 0.9348 - val_loss: 0.1781 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1733 - acc: 0.9429\n",
      "Epoch 00002: val_loss improved from 0.17811 to 0.17271, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 49s 206ms/step - loss: 0.1733 - acc: 0.9429 - val_loss: 0.1727 - val_acc: 0.9422 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1572 - acc: 0.9466\n",
      "Epoch 00003: val_loss improved from 0.17271 to 0.17027, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 48s 202ms/step - loss: 0.1572 - acc: 0.9466 - val_loss: 0.1703 - val_acc: 0.9427 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1461 - acc: 0.9498\n",
      "Epoch 00004: val_loss did not improve from 0.17027\n",
      "238/238 [==============================] - 48s 201ms/step - loss: 0.1461 - acc: 0.9498 - val_loss: 0.1724 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1359 - acc: 0.9528\n",
      "Epoch 00005: val_loss did not improve from 0.17027\n",
      "238/238 [==============================] - 48s 203ms/step - loss: 0.1359 - acc: 0.9528 - val_loss: 0.1722 - val_acc: 0.9418 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1255 - acc: 0.9560\n",
      "Epoch 00006: val_loss did not improve from 0.17027\n",
      "238/238 [==============================] - 47s 199ms/step - loss: 0.1255 - acc: 0.9560 - val_loss: 0.1729 - val_acc: 0.9413 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1230 - acc: 0.9560\n",
      "Epoch 00007: val_loss did not improve from 0.17027\n",
      "238/238 [==============================] - 49s 206ms/step - loss: 0.1230 - acc: 0.9560 - val_loss: 0.1738 - val_acc: 0.9413 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1214 - acc: 0.9562\n",
      "Epoch 00008: val_loss did not improve from 0.17027\n",
      "238/238 [==============================] - 47s 199ms/step - loss: 0.1214 - acc: 0.9562 - val_loss: 0.1737 - val_acc: 0.9413 - lr: 4.0000e-05\n",
      "AUC:  0.8907150771727766 AUPRC:  0.5251415917172831 F1:  0.44396551724137934\n",
      "0.8898341058414095 0.5291942032092335 0.9411223551057958 0.43612334801762115\n"
     ]
    }
   ],
   "source": [
    "embedding_types = ['word2vec', 'fasttext']#, 'concat']\n",
    "embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
    "\n",
    "target_problems = ['mort_hosp', 'mort_icu']#, 'los_3', 'los_7']\n",
    "\n",
    "num_epoch = 100\n",
    "model_patience = 5\n",
    "monitor_criteria = 'val_loss'\n",
    "#monitor_criteria = 'val_acc'\n",
    "batch_size = 64\n",
    "\n",
    "filter_number = 32\n",
    "ner_representation_limit = 64\n",
    "activation_func = \"relu\"\n",
    "\n",
    "sequence_model = \"GRU\"\n",
    "sequence_hidden_unit = 256\n",
    "\n",
    "maxiter = 11\n",
    "for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n",
    "    print (\"Embedding: \", embed_name)\n",
    "    print(\"=============================\")\n",
    "    \n",
    "    temp_train_ner = dict((k, embed_dict[k]) for k in train_ids)\n",
    "    tem_dev_ner = dict((k, embed_dict[k]) for k in dev_ids)\n",
    "    temp_test_ner = dict((k, embed_dict[k]) for k in test_ids)\n",
    "\n",
    "    x_train_dict = {}\n",
    "    x_dev_dict = {}\n",
    "    x_test_dict = {}\n",
    "\n",
    "    x_train_dict = get_subvector_data(ner_representation_limit, embed_name, temp_train_ner)\n",
    "    x_dev_dict = get_subvector_data(ner_representation_limit, embed_name, tem_dev_ner)\n",
    "    x_test_dict = get_subvector_data(ner_representation_limit, embed_name, temp_test_ner)\n",
    "\n",
    "    x_train_dict_sorted = collections.OrderedDict(sorted(x_train_dict.items()))\n",
    "    x_dev_dict_sorted = collections.OrderedDict(sorted(x_dev_dict.items()))\n",
    "    x_test_dict_sorted = collections.OrderedDict(sorted(x_test_dict.items()))\n",
    "    \n",
    "#     x_train_dict_sorted = sorted(x_train_dict.items())\n",
    "#     x_dev_dict_sorted = sorted(x_dev_dict.items())\n",
    "#     x_test_dict_sorted = sorted(x_test_dict.items())\n",
    "    list_train_ner =[]\n",
    "    list_test_ner =[]\n",
    "    list_dev_ner =[]\n",
    "    for k,v in x_train_dict_sorted.items():\n",
    "            list_train_ner.append(v)\n",
    "    for k,v in x_test_dict_sorted.items():\n",
    "            list_test_ner.append(v)\n",
    "    for k,v in x_dev_dict_sorted.items():\n",
    "            list_dev_ner.append(v)\n",
    "    \n",
    "        \n",
    "    \n",
    "    x_train_ner = np.array(list_train_ner)\n",
    "    x_dev_ner = np.array(list_dev_ner)\n",
    "    x_test_ner = np.array(list_test_ner)\n",
    "    \n",
    "    print(x_train_ner.shape)\n",
    "    \n",
    "\n",
    "    #print('shape of x_train_ner{0} x_dev_ner{1} x_test_ner {2}'.format(x_train_ner.shape,x_dev_ner.shape,x_test_ner.shape))\n",
    "    \n",
    "        \n",
    "    for iteration in range(1,maxiter):\n",
    "        print (\"Iteration number: \", iteration)\n",
    "    \n",
    "        for each_problem in target_problems:\n",
    "            print (\"Problem type: \", each_problem)\n",
    "            print (\"__________________\")\n",
    "            \n",
    "            \n",
    "            early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "            \n",
    "            best_model_name = str(ner_representation_limit)+\"-basiccnn1d-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "            \n",
    "            checkpoint = ModelCheckpoint(best_model_name, monitor=monitor_criteria, verbose=1,\n",
    "                save_best_only=True, mode='min')\n",
    "            \n",
    "            reduce_lr = ReduceLROnPlateau(monitor=monitor_criteria, factor=0.2,\n",
    "                              patience=2, min_lr=0.00001, epsilon=1e-4, mode='min')\n",
    "            \n",
    "\n",
    "            callbacks = [early_stopping_monitor, checkpoint, reduce_lr]\n",
    "            \n",
    "            #model = textCNN(sequence_model, sequence_hidden_unit, embed_name, ner_representation_limit)\n",
    "            model = proposedmodel(sequence_model, sequence_hidden_unit, \n",
    "                               embed_name, ner_representation_limit,filter_number)\n",
    "            print('x_train_lstm {0} x_dev_lstm {1}'.format(x_train_lstm.shape,x_dev_lstm.shape))\n",
    "            print('x_train_ner {0} x_dev_ner {1}'.format(x_train_ner.shape,x_dev_ner.shape))\n",
    "            print(y_train[each_problem].shape)\n",
    "            aa = [x_train_lstm, x_train_ner]\n",
    "            print(x_train_lstm.shape, x_train_ner.shape, len(aa))\n",
    "            model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n",
    "                      validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, batch_size=batch_size)\n",
    "            \n",
    "            \n",
    "            probs, predictions = make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
    "            print_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration, sequence_hidden_unit)\n",
    "            \n",
    "            model.load_weights(best_model_name)\n",
    "                      \n",
    "            probs, predictions = make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
    "            save_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration,\n",
    "                            sequence_hidden_unit, sequence_model, type_of_ner)\n",
    "            del model\n",
    "            clear_session()\n",
    "            gc.collect()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding_types = ['word2vec', 'fasttext', 'concat']\n",
    "embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
    "\n",
    "target_problems = [ 'mort_icu', 'los_3', 'los_7']#['mort_hosp']#,\n",
    "\n",
    "num_epoch = 100\n",
    "model_patience = 5\n",
    "monitor_criteria = 'val_loss'\n",
    "#monitor_criteria = 'val_acc'\n",
    "batch_size = 64\n",
    "\n",
    "filter_number = 32\n",
    "ner_representation_limit = 64\n",
    "activation_func = \"relu\"\n",
    "\n",
    "sequence_model = \"GRU\"\n",
    "sequence_hidden_unit = 256\n",
    "\n",
    "maxiter = 11\n",
    "for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n",
    "    print (\"Embedding: \", embed_name)\n",
    "    print(\"=============================\")\n",
    "    \n",
    "    temp_train_ner = dict((k, embed_dict[k]) for k in train_ids)\n",
    "    tem_dev_ner = dict((k, embed_dict[k]) for k in dev_ids)\n",
    "    temp_test_ner = dict((k, embed_dict[k]) for k in test_ids)\n",
    "\n",
    "    x_train_dict = {}\n",
    "    x_dev_dict = {}\n",
    "    x_test_dict = {}\n",
    "\n",
    "    x_train_dict = get_subvector_data(ner_representation_limit, embed_name, temp_train_ner)\n",
    "    x_dev_dict = get_subvector_data(ner_representation_limit, embed_name, tem_dev_ner)\n",
    "    x_test_dict = get_subvector_data(ner_representation_limit, embed_name, temp_test_ner)\n",
    "\n",
    "    x_train_dict_sorted = collections.OrderedDict(sorted(x_train_dict.items()))\n",
    "    x_dev_dict_sorted = collections.OrderedDict(sorted(x_dev_dict.items()))\n",
    "    x_test_dict_sorted = collections.OrderedDict(sorted(x_test_dict.items()))\n",
    "    \n",
    "#     x_train_dict_sorted = sorted(x_train_dict.items())\n",
    "#     x_dev_dict_sorted = sorted(x_dev_dict.items())\n",
    "#     x_test_dict_sorted = sorted(x_test_dict.items())\n",
    "    list_train_ner =[]\n",
    "    list_test_ner =[]\n",
    "    list_dev_ner =[]\n",
    "    for k,v in x_train_dict_sorted.items():\n",
    "            list_train_ner.append(v)\n",
    "    for k,v in x_test_dict_sorted.items():\n",
    "            list_test_ner.append(v)\n",
    "    for k,v in x_dev_dict_sorted.items():\n",
    "            list_dev_ner.append(v)\n",
    "    \n",
    "        \n",
    "    \n",
    "    x_train_ner = np.array(list_train_ner)\n",
    "    x_dev_ner = np.array(list_dev_ner)\n",
    "    x_test_ner = np.array(list_test_ner)\n",
    "    \n",
    "    print(x_train_ner.shape)\n",
    "    \n",
    "\n",
    "    #print('shape of x_train_ner{0} x_dev_ner{1} x_test_ner {2}'.format(x_train_ner.shape,x_dev_ner.shape,x_test_ner.shape))\n",
    "    \n",
    "        \n",
    "    for iteration in range(1,maxiter):\n",
    "        print (\"Iteration number: \", iteration)\n",
    "    \n",
    "        for each_problem in target_problems:\n",
    "            print (\"Problem type: \", each_problem)\n",
    "            print (\"__________________\")\n",
    "            \n",
    "            \n",
    "            early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "            \n",
    "            best_model_name = str(ner_representation_limit)+\"-basiccnn1d-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "            \n",
    "            checkpoint = ModelCheckpoint(best_model_name, monitor=monitor_criteria, verbose=1,\n",
    "                save_best_only=True, mode='min')\n",
    "            \n",
    "            reduce_lr = ReduceLROnPlateau(monitor=monitor_criteria, factor=0.2,\n",
    "                              patience=2, min_lr=0.00001, epsilon=1e-4, mode='min')\n",
    "            \n",
    "\n",
    "            callbacks = [early_stopping_monitor, checkpoint, reduce_lr]\n",
    "            \n",
    "            #model = textCNN(sequence_model, sequence_hidden_unit, embed_name, ner_representation_limit)\n",
    "            model = proposedmodel(sequence_model, sequence_hidden_unit, \n",
    "                               embed_name, ner_representation_limit,filter_number)\n",
    "            print('x_train_lstm {0} x_dev_lstm {1}'.format(x_train_lstm.shape,x_dev_lstm.shape))\n",
    "            print('x_train_ner {0} x_dev_ner {1}'.format(x_train_ner.shape,x_dev_ner.shape))\n",
    "            print(y_train[each_problem].shape)\n",
    "            aa = [x_train_lstm, x_train_ner]\n",
    "            print(x_train_lstm.shape, x_train_ner.shape, len(aa))\n",
    "            model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n",
    "                      validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, batch_size=batch_size)\n",
    "            \n",
    "            \n",
    "            probs, predictions = make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
    "            print_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration, sequence_hidden_unit)\n",
    "            \n",
    "            model.load_weights(best_model_name)\n",
    "                      \n",
    "            probs, predictions = make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
    "            save_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration,\n",
    "                            sequence_hidden_unit, sequence_model, type_of_ner)\n",
    "            del model\n",
    "            clear_session()\n",
    "            gc.collect()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
