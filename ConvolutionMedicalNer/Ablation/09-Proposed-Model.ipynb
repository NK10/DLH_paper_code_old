{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "# import glove nitin commented as its not used\n",
    "# from glove import Corpus\n",
    "\n",
    "import collections\n",
    "import gc \n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, merge, Activation, Concatenate, LSTM, GRU\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n",
    "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D, merge\n",
    "\n",
    "# from keras.optimizers import Adam # nitin commented as Adam has been shifted to optimizer_v1 module.\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "#from keras.backend.tensorflow_backend import set_session, clear_session, get_session # nitin commented as tensorflow_backend not used anymore\n",
    "from keras.backend import set_session, clear_session, get_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nitin added as without it the read_pickel below was giving the error as in notebook 5 when its writing\n",
    "#pickel do a lazy execution and write the function as well\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_ner = \"new\"\n",
    "\n",
    "x_train_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_train.pkl\")\n",
    "x_dev_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_dev.pkl\")\n",
    "x_test_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_test.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(\"data/\"+type_of_ner+\"_y_train.pkl\")\n",
    "y_dev = pd.read_pickle(\"data/\"+type_of_ner+\"_y_dev.pkl\")\n",
    "y_test = pd.read_pickle(\"data/\"+type_of_ner+\"_y_test.pkl\")\n",
    "\n",
    "\n",
    "ner_word2vec = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_word2vec_limited_dict.pkl\")\n",
    "ner_fasttext = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_fasttext_limited_dict.pkl\")\n",
    "ner_concat = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_combined_limited_dict.pkl\")\n",
    "\n",
    "train_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_train_ids.pkl\")\n",
    "dev_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_dev_ids.pkl\")\n",
    "test_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_test_ids.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14665, 24, 104),\n",
       " (2090, 24, 104),\n",
       " (4171, 24, 104),\n",
       " (14665, 4),\n",
       " (2090, 4),\n",
       " (4171, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lstm.shape,x_dev_lstm.shape,x_test_lstm.shape ,y_train.shape,y_dev.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_cnn(model, test_data):\n",
    "    probs = model.predict(test_data)\n",
    "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
    "    return probs, y_pred\n",
    "\n",
    "def save_scores_cnn(predictions, probs, ground_truth, \n",
    "                          \n",
    "                          embed_name, problem_type, iteration, hidden_unit_size,\n",
    "                          \n",
    "                          sequence_name, type_of_ner):\n",
    "    \n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    result_dict = {}    \n",
    "    result_dict['auc'] = auc\n",
    "    result_dict['auprc'] = auprc\n",
    "    result_dict['acc'] = acc\n",
    "    result_dict['F1'] = F1\n",
    "\n",
    "    result_path = \"results/cnn/\"\n",
    "    file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n",
    "    file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-cnn-.p\"\n",
    "    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
    "\n",
    "    print(auc, auprc, acc, F1)\n",
    "    \n",
    "def print_scores_cnn(predictions, probs, ground_truth, model_name, problem_type, iteration, hidden_unit_size):\n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    print (\"AUC: \", auc, \"AUPRC: \", auprc, \"F1: \", F1)\n",
    "    \n",
    "def get_subvector_data(size, embed_name, data):\n",
    "    if embed_name == \"concat\":\n",
    "        vector_size = 200\n",
    "    else:\n",
    "        vector_size = 100\n",
    "\n",
    "    x_data = {}\n",
    "    for k, v in data.items():\n",
    "        number_of_additional_vector = len(v) - size\n",
    "        vector = []\n",
    "        for i in v:\n",
    "            vector.append(i)\n",
    "        if number_of_additional_vector < 0: \n",
    "            number_of_additional_vector = np.abs(number_of_additional_vector)\n",
    "\n",
    "            temp = vector[:size]\n",
    "            for i in range(0, number_of_additional_vector):\n",
    "                temp.append(np.zeros(vector_size))\n",
    "            x_data[k] = np.asarray(temp)\n",
    "        else:\n",
    "            x_data[k] = np.asarray(vector[:size])\n",
    "\n",
    "    return x_data\n",
    "\n",
    "\n",
    "def proposedmodel(layer_name, number_of_unit, embedding_name, ner_limit, num_filter):\n",
    "    if embedding_name == \"concat\":\n",
    "        input_dimension = 200\n",
    "    else:\n",
    "        input_dimension = 100\n",
    "\n",
    "    sequence_input = Input(shape=(24,104))\n",
    "\n",
    "    input_img = Input(shape=(ner_limit, input_dimension), name = \"cnn_input\")\n",
    "\n",
    "    convs = []\n",
    "    filter_sizes = [2,3,4]\n",
    "\n",
    "\n",
    "    #logits_regularizer = tf.compat.v1.estimator.layers.l2_regularizer(scale=0.01)\n",
    "    # removed tf.compat.v1.estimator.layers.xavier_initializer() with glorot_normal\n",
    "    \n",
    "    text_conv1d = Conv1D(filters=num_filter, kernel_size=3, \n",
    "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu', \n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal() )(input_img)\n",
    "    \n",
    "    text_conv1d = Conv1D(filters=num_filter*2, kernel_size=3, \n",
    "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal())(text_conv1d)   \n",
    "    \n",
    "    text_conv1d = Conv1D(filters=num_filter*3, kernel_size=3, \n",
    "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal())(text_conv1d)   \n",
    "\n",
    "    \n",
    "    #concat_conv = keras.layers.Concatenate()([text_conv1d, text_conv1d_2, text_conv1d_3])\n",
    "    text_embeddings = GlobalMaxPooling1D()(text_conv1d)\n",
    "    #text_embeddings = Dense(128, activation=\"relu\")(text_embeddings)\n",
    "    \n",
    "    if layer_name == \"GRU\":\n",
    "        x = GRU(number_of_unit)(sequence_input)\n",
    "    elif layer_name == \"LSTM\":\n",
    "        x = LSTM(number_of_unit)(sequence_input)\n",
    "\n",
    "    concatenated = keras.layers.Concatenate(axis =1)([x, text_embeddings])# nitin uncommented\n",
    "    #concatenated = merge([x, text_embeddings], mode='concat', concat_axis=1)# nitin commented\n",
    "\n",
    "    concatenated = Dense(512, activation='relu')(concatenated)\n",
    "    concatenated = Dropout(0.2)(concatenated)\n",
    "    #concatenated = Dense(256, activation='relu')(concatenated)\n",
    "    #concatenated = Dense(512, activation='relu')(concatenated)\n",
    "    \n",
    "    #concatenated = Dense(512, activation='relu')(concatenated)\n",
    "    \n",
    "    #logits_regularizer = tf.contrib.layers.l2_regularizer(scale=0.01) nitin commented as its deprecated\n",
    "    logits_regularizer = tf.keras.regularizers.L2(0.01)\n",
    "    \n",
    "    preds = Dense(1, activation='sigmoid',use_bias=False,\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal(), \n",
    "                  kernel_regularizer=logits_regularizer)(concatenated)\n",
    "    \n",
    "    \n",
    "    #opt = Adam(lr=1e-4, decay = 0.01)\n",
    "    \n",
    "    opt = Adam(lr=1e-3, decay = 0.01)\n",
    "    \n",
    "    #opt = Adam(lr=0.001)\n",
    "\n",
    "    model = Model(inputs=[sequence_input, input_img], outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_f = {\"a\": [1,2,3], \"b\": [1,2,3], \"c\": [1,2,3], \"d\": [1,2,3]}\n",
    "\n",
    "#data = list(dict.items())\n",
    "data = collections.OrderedDict(sorted(dict_f.items()))\n",
    "print(sorted(dict_f.items()))\n",
    "an_array = np.asarray(data.values())\n",
    "\n",
    "print(data)\n",
    "print('an_array',an_array)\n",
    "print(type(data))\n",
    "\n",
    "\n",
    "\n",
    "for a in data.items():\n",
    "    print(a[1])\n",
    "\n",
    "t1[0]\n",
    "\n",
    "i =0\n",
    "t = []\n",
    "for kk,v in x_train_dict_sorted.items():\n",
    "    i+=1\n",
    "    #print(kk, v.shape,i+1)\n",
    "    t.append(v)\n",
    "a  = np.array(t)\n",
    "    \n",
    "\n",
    "a.shape\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding:  word2vec\n",
      "=============================\n",
      "(14665, 64, 100)\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2944 - acc: 0.8998\n",
      "Epoch 00001: val_loss improved from inf to 0.24731, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 20s 73ms/step - loss: 0.2945 - acc: 0.8998 - val_loss: 0.2473 - val_acc: 0.9158 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2381 - acc: 0.9157\n",
      "Epoch 00002: val_loss improved from 0.24731 to 0.24633, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.2381 - acc: 0.9156 - val_loss: 0.2463 - val_acc: 0.9139 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2237 - acc: 0.9204\n",
      "Epoch 00003: val_loss improved from 0.24633 to 0.24369, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.2237 - acc: 0.9204 - val_loss: 0.2437 - val_acc: 0.9120 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9234\n",
      "Epoch 00004: val_loss improved from 0.24369 to 0.24116, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.2128 - acc: 0.9234 - val_loss: 0.2412 - val_acc: 0.9148 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9252\n",
      "Epoch 00005: val_loss did not improve from 0.24116\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.2047 - acc: 0.9252 - val_loss: 0.2448 - val_acc: 0.9091 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9290\n",
      "Epoch 00006: val_loss did not improve from 0.24116\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1966 - acc: 0.9289 - val_loss: 0.2436 - val_acc: 0.9148 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1868 - acc: 0.9318- ETA: 1s\n",
      "Epoch 00007: val_loss did not improve from 0.24116\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.1868 - acc: 0.9318 - val_loss: 0.2448 - val_acc: 0.9139 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9319\n",
      "Epoch 00008: val_loss did not improve from 0.24116\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1857 - acc: 0.9319 - val_loss: 0.2453 - val_acc: 0.9148 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9333\n",
      "Epoch 00009: val_loss did not improve from 0.24116\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1836 - acc: 0.9333 - val_loss: 0.2454 - val_acc: 0.9148 - lr: 4.0000e-05\n",
      "AUC:  0.8769090637000693 AUPRC:  0.5746354034209634 F1:  0.4702467343976778\n",
      "0.8759245577382404 0.5721797858457737 0.9156077679213618 0.4730538922155688\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9340\n",
      "Epoch 00001: val_loss improved from inf to 0.17672, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 59ms/step - loss: 0.2178 - acc: 0.9340 - val_loss: 0.1767 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9425\n",
      "Epoch 00002: val_loss improved from 0.17672 to 0.17377, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1738 - acc: 0.9425 - val_loss: 0.1738 - val_acc: 0.9388 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9476\n",
      "Epoch 00003: val_loss improved from 0.17377 to 0.17284, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 61ms/step - loss: 0.1597 - acc: 0.9476 - val_loss: 0.1728 - val_acc: 0.9435 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9483\n",
      "Epoch 00004: val_loss did not improve from 0.17284\n",
      "230/230 [==============================] - 14s 62ms/step - loss: 0.1487 - acc: 0.9483 - val_loss: 0.1729 - val_acc: 0.9435 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9516\n",
      "Epoch 00005: val_loss did not improve from 0.17284\n",
      "230/230 [==============================] - 14s 59ms/step - loss: 0.1396 - acc: 0.9517 - val_loss: 0.1735 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1295 - acc: 0.9550\n",
      "Epoch 00006: val_loss did not improve from 0.17284\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1295 - acc: 0.9550 - val_loss: 0.1734 - val_acc: 0.9435 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9565\n",
      "Epoch 00007: val_loss did not improve from 0.17284\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.1273 - acc: 0.9566 - val_loss: 0.1736 - val_acc: 0.9407 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9567\n",
      "Epoch 00008: val_loss did not improve from 0.17284\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.1260 - acc: 0.9567 - val_loss: 0.1737 - val_acc: 0.9402 - lr: 4.0000e-05\n",
      "AUC:  0.8852854433499594 AUPRC:  0.5187469575896249 F1:  0.45033112582781454\n",
      "0.8851267012557336 0.5277125475861096 0.9398225845121074 0.4038004750593824\n",
      "Iteration number:  2\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2908 - acc: 0.9022\n",
      "Epoch 00001: val_loss improved from inf to 0.24846, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 19s 66ms/step - loss: 0.2907 - acc: 0.9022 - val_loss: 0.2485 - val_acc: 0.9100 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2391 - acc: 0.9160\n",
      "Epoch 00002: val_loss improved from 0.24846 to 0.24611, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.2391 - acc: 0.9160 - val_loss: 0.2461 - val_acc: 0.9091 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9219\n",
      "Epoch 00003: val_loss improved from 0.24611 to 0.24186, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.2220 - acc: 0.9219 - val_loss: 0.2419 - val_acc: 0.9120 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9240\n",
      "Epoch 00004: val_loss did not improve from 0.24186\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2094 - acc: 0.9240 - val_loss: 0.2435 - val_acc: 0.9105 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1997 - acc: 0.9280\n",
      "Epoch 00005: val_loss did not improve from 0.24186\n",
      "230/230 [==============================] - 14s 61ms/step - loss: 0.1997 - acc: 0.9280 - val_loss: 0.2431 - val_acc: 0.9115 - lr: 0.0010\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9333\n",
      "Epoch 00006: val_loss did not improve from 0.24186\n",
      "230/230 [==============================] - 13s 54ms/step - loss: 0.1873 - acc: 0.9333 - val_loss: 0.2428 - val_acc: 0.9105 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9334\n",
      "Epoch 00007: val_loss did not improve from 0.24186\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1848 - acc: 0.9334 - val_loss: 0.2430 - val_acc: 0.9115 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9335\n",
      "Epoch 00008: val_loss did not improve from 0.24186\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1838 - acc: 0.9335 - val_loss: 0.2429 - val_acc: 0.9110 - lr: 4.0000e-05\n",
      "AUC:  0.8799214987586151 AUPRC:  0.5841802257497581 F1:  0.471281296023564\n",
      "0.8811399058974912 0.5904104572633758 0.9144090146247902 0.45827010622154774\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9355\n",
      "Epoch 00001: val_loss improved from inf to 0.18282, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 17s 63ms/step - loss: 0.2179 - acc: 0.9355 - val_loss: 0.1828 - val_acc: 0.9392 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1748 - acc: 0.9439- ETA: 3s - loss: 0 -\n",
      "Epoch 00002: val_loss improved from 0.18282 to 0.17851, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1749 - acc: 0.9438 - val_loss: 0.1785 - val_acc: 0.9416 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9473\n",
      "Epoch 00003: val_loss improved from 0.17851 to 0.17367, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.1576 - acc: 0.9474 - val_loss: 0.1737 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9510\n",
      "Epoch 00004: val_loss did not improve from 0.17367\n",
      "230/230 [==============================] - 16s 72ms/step - loss: 0.1462 - acc: 0.9510 - val_loss: 0.1769 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9548\n",
      "Epoch 00005: val_loss did not improve from 0.17367\n",
      "230/230 [==============================] - 19s 82ms/step - loss: 0.1362 - acc: 0.9548 - val_loss: 0.1781 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9572- ETA: 1s - lo\n",
      "Epoch 00006: val_loss did not improve from 0.17367\n",
      "230/230 [==============================] - 19s 81ms/step - loss: 0.1261 - acc: 0.9572 - val_loss: 0.1781 - val_acc: 0.9411 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1242 - acc: 0.9592\n",
      "Epoch 00007: val_loss did not improve from 0.17367\n",
      "230/230 [==============================] - 20s 87ms/step - loss: 0.1242 - acc: 0.9592 - val_loss: 0.1788 - val_acc: 0.9421 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9589\n",
      "Epoch 00008: val_loss did not improve from 0.17367\n",
      "230/230 [==============================] - 21s 91ms/step - loss: 0.1220 - acc: 0.9588 - val_loss: 0.1789 - val_acc: 0.9416 - lr: 4.0000e-05\n",
      "AUC:  0.8829661378048475 AUPRC:  0.5182886104641167 F1:  0.42920353982300885\n",
      "0.8811121972412294 0.5198167653936167 0.9386238312155358 0.39906103286384975\n",
      "Iteration number:  3\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2838 - acc: 0.9020- ETA: 0s - loss: 0.2847 \n",
      "Epoch 00001: val_loss improved from inf to 0.24630, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 18s 63ms/step - loss: 0.2838 - acc: 0.9019 - val_loss: 0.2463 - val_acc: 0.9115 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2382 - acc: 0.9163\n",
      "Epoch 00002: val_loss improved from 0.24630 to 0.24552, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 59ms/step - loss: 0.2381 - acc: 0.9163 - val_loss: 0.2455 - val_acc: 0.9120 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9216\n",
      "Epoch 00003: val_loss improved from 0.24552 to 0.24223, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.2181 - acc: 0.9217 - val_loss: 0.2422 - val_acc: 0.9105 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9271\n",
      "Epoch 00004: val_loss did not improve from 0.24223\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.2033 - acc: 0.9272 - val_loss: 0.2438 - val_acc: 0.9115 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9320\n",
      "Epoch 00005: val_loss did not improve from 0.24223\n",
      "230/230 [==============================] - 15s 64ms/step - loss: 0.1923 - acc: 0.9319 - val_loss: 0.2467 - val_acc: 0.9077 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9363\n",
      "Epoch 00006: val_loss did not improve from 0.24223\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1789 - acc: 0.9363 - val_loss: 0.2460 - val_acc: 0.9086 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9373\n",
      "Epoch 00007: val_loss did not improve from 0.24223\n",
      "230/230 [==============================] - 18s 78ms/step - loss: 0.1768 - acc: 0.9373 - val_loss: 0.2469 - val_acc: 0.9091 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9373\n",
      "Epoch 00008: val_loss did not improve from 0.24223\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1752 - acc: 0.9373 - val_loss: 0.2467 - val_acc: 0.9077 - lr: 4.0000e-05\n",
      "AUC:  0.8762618585540076 AUPRC:  0.5752046147523014 F1:  0.46920821114369504\n",
      "0.8768748917396945 0.5803008334011761 0.9141692639654759 0.44753086419753085\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9359\n",
      "Epoch 00001: val_loss improved from inf to 0.17521, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 24s 77ms/step - loss: 0.2168 - acc: 0.9358 - val_loss: 0.1752 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9436\n",
      "Epoch 00002: val_loss improved from 0.17521 to 0.17159, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1755 - acc: 0.9435 - val_loss: 0.1716 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9458\n",
      "Epoch 00003: val_loss improved from 0.17159 to 0.17055, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1597 - acc: 0.9458 - val_loss: 0.1705 - val_acc: 0.9435 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9484- ETA: 1s - \n",
      "Epoch 00004: val_loss did not improve from 0.17055\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1500 - acc: 0.9484 - val_loss: 0.1714 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9520\n",
      "Epoch 00005: val_loss did not improve from 0.17055\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.1409 - acc: 0.9519 - val_loss: 0.1708 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9548\n",
      "Epoch 00006: val_loss did not improve from 0.17055\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1309 - acc: 0.9548 - val_loss: 0.1707 - val_acc: 0.9421 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9536\n",
      "Epoch 00007: val_loss did not improve from 0.17055\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1301 - acc: 0.9536 - val_loss: 0.1714 - val_acc: 0.9426 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9560\n",
      "Epoch 00008: val_loss did not improve from 0.17055\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1283 - acc: 0.9559 - val_loss: 0.1713 - val_acc: 0.9421 - lr: 4.0000e-05\n",
      "AUC:  0.8836838191676901 AUPRC:  0.5243465238166812 F1:  0.4493392070484582\n",
      "0.8806844290715258 0.5262709023702727 0.9405418364900503 0.42056074766355145\n",
      "Iteration number:  4\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2880 - acc: 0.9036\n",
      "Epoch 00001: val_loss improved from inf to 0.24947, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 21s 76ms/step - loss: 0.2879 - acc: 0.9036 - val_loss: 0.2495 - val_acc: 0.9153 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9156\n",
      "Epoch 00002: val_loss improved from 0.24947 to 0.24534, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 17s 76ms/step - loss: 0.2393 - acc: 0.9156 - val_loss: 0.2453 - val_acc: 0.9148 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2210 - acc: 0.9213\n",
      "Epoch 00003: val_loss improved from 0.24534 to 0.24259, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 18s 79ms/step - loss: 0.2209 - acc: 0.9213 - val_loss: 0.2426 - val_acc: 0.9105 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9224\n",
      "Epoch 00004: val_loss improved from 0.24259 to 0.24209, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 18s 78ms/step - loss: 0.2099 - acc: 0.9223 - val_loss: 0.2421 - val_acc: 0.9134 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9270\n",
      "Epoch 00005: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 18s 78ms/step - loss: 0.1992 - acc: 0.9270 - val_loss: 0.2428 - val_acc: 0.9115 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9303\n",
      "Epoch 00006: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 19s 84ms/step - loss: 0.1906 - acc: 0.9304 - val_loss: 0.2474 - val_acc: 0.9100 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1806 - acc: 0.9347\n",
      "Epoch 00007: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 18s 80ms/step - loss: 0.1806 - acc: 0.9347 - val_loss: 0.2470 - val_acc: 0.9100 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9363\n",
      "Epoch 00008: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 18s 76ms/step - loss: 0.1776 - acc: 0.9363 - val_loss: 0.2478 - val_acc: 0.9115 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9370\n",
      "Epoch 00009: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 18s 77ms/step - loss: 0.1765 - acc: 0.9370 - val_loss: 0.2478 - val_acc: 0.9105 - lr: 4.0000e-05\n",
      "AUC:  0.8807539984139496 AUPRC:  0.5827958322924484 F1:  0.4739884393063584\n",
      "0.8813967847720318 0.5879128228678935 0.9160872692399904 0.46319018404907975\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9302\n",
      "Epoch 00001: val_loss improved from inf to 0.18344, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 21s 77ms/step - loss: 0.2247 - acc: 0.9302 - val_loss: 0.1834 - val_acc: 0.9450 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9434\n",
      "Epoch 00002: val_loss improved from 0.18344 to 0.17247, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 17s 75ms/step - loss: 0.1768 - acc: 0.9434 - val_loss: 0.1725 - val_acc: 0.9435 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9463\n",
      "Epoch 00003: val_loss improved from 0.17247 to 0.16921, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 72ms/step - loss: 0.1624 - acc: 0.9463 - val_loss: 0.1692 - val_acc: 0.9450 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9491\n",
      "Epoch 00004: val_loss did not improve from 0.16921\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1524 - acc: 0.9491 - val_loss: 0.1698 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9514\n",
      "Epoch 00005: val_loss did not improve from 0.16921\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1436 - acc: 0.9514 - val_loss: 0.1706 - val_acc: 0.9416 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9548\n",
      "Epoch 00006: val_loss did not improve from 0.16921\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1358 - acc: 0.9548 - val_loss: 0.1701 - val_acc: 0.9426 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9544\n",
      "Epoch 00007: val_loss did not improve from 0.16921\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1335 - acc: 0.9544 - val_loss: 0.1699 - val_acc: 0.9426 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9541\n",
      "Epoch 00008: val_loss did not improve from 0.16921\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1325 - acc: 0.9541 - val_loss: 0.1700 - val_acc: 0.9426 - lr: 4.0000e-05\n",
      "AUC:  0.8865019090825543 AUPRC:  0.5241253498008487 F1:  0.4340044742729307\n",
      "0.8826528310399279 0.5248334402006514 0.9412610884679933 0.4367816091954023\n",
      "Iteration number:  5\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.2927 - acc: 0.9011\n",
      "Epoch 00001: val_loss improved from inf to 0.25107, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 19s 64ms/step - loss: 0.2926 - acc: 0.9011 - val_loss: 0.2511 - val_acc: 0.9158 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.9157\n",
      "Epoch 00002: val_loss improved from 0.25107 to 0.24160, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.2387 - acc: 0.9157 - val_loss: 0.2416 - val_acc: 0.9129 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9198- ET\n",
      "Epoch 00003: val_loss did not improve from 0.24160\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.2249 - acc: 0.9198 - val_loss: 0.2429 - val_acc: 0.9124 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2139 - acc: 0.9227\n",
      "Epoch 00004: val_loss improved from 0.24160 to 0.24134, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.2140 - acc: 0.9225 - val_loss: 0.2413 - val_acc: 0.9134 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9262- ETA: 0s - loss: 0.2075 - acc: 0\n",
      "Epoch 00005: val_loss improved from 0.24134 to 0.23961, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.2064 - acc: 0.9262 - val_loss: 0.2396 - val_acc: 0.9129 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9271\n",
      "Epoch 00006: val_loss did not improve from 0.23961\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1991 - acc: 0.9271 - val_loss: 0.2397 - val_acc: 0.9139 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1922 - acc: 0.9297\n",
      "Epoch 00007: val_loss did not improve from 0.23961\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1921 - acc: 0.9297 - val_loss: 0.2402 - val_acc: 0.9139 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9316\n",
      "Epoch 00008: val_loss did not improve from 0.23961\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1852 - acc: 0.9316 - val_loss: 0.2414 - val_acc: 0.9153 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9336\n",
      "Epoch 00009: val_loss did not improve from 0.23961\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1834 - acc: 0.9337 - val_loss: 0.2421 - val_acc: 0.9148 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9329\n",
      "Epoch 00010: val_loss did not improve from 0.23961\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.1817 - acc: 0.9330 - val_loss: 0.2422 - val_acc: 0.9153 - lr: 4.0000e-05\n",
      "AUC:  0.8807198264535749 AUPRC:  0.5828049067811873 F1:  0.47605224963715537\n",
      "0.8812070714747792 0.5867823793675899 0.9151282666027332 0.4985835694050992\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9335- ETA: 5s - loss: 0.2373 - - ETA: 0s - loss: 0.2205 -\n",
      "Epoch 00001: val_loss improved from inf to 0.17496, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 18s 66ms/step - loss: 0.2172 - acc: 0.9335 - val_loss: 0.1750 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1748 - acc: 0.9430\n",
      "Epoch 00002: val_loss improved from 0.17496 to 0.16983, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1747 - acc: 0.9430 - val_loss: 0.1698 - val_acc: 0.9464 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9475\n",
      "Epoch 00003: val_loss improved from 0.16983 to 0.16840, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1577 - acc: 0.9474 - val_loss: 0.1684 - val_acc: 0.9440 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9494\n",
      "Epoch 00004: val_loss did not improve from 0.16840\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1470 - acc: 0.9494 - val_loss: 0.1693 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9527\n",
      "Epoch 00005: val_loss did not improve from 0.16840\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1383 - acc: 0.9527 - val_loss: 0.1718 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9555\n",
      "Epoch 00006: val_loss did not improve from 0.16840\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1284 - acc: 0.9555 - val_loss: 0.1705 - val_acc: 0.9426 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9566\n",
      "Epoch 00007: val_loss did not improve from 0.16840\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1270 - acc: 0.9566 - val_loss: 0.1709 - val_acc: 0.9445 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9567- \n",
      "Epoch 00008: val_loss did not improve from 0.16840\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1243 - acc: 0.9568 - val_loss: 0.1710 - val_acc: 0.9426 - lr: 4.0000e-05\n",
      "AUC:  0.8858151406538504 AUPRC:  0.508247826333887 F1:  0.4295010845986985\n",
      "0.8829569474730765 0.5081457675105475 0.9391033325341644 0.40375586854460094\n",
      "Iteration number:  6\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2832 - acc: 0.9052\n",
      "Epoch 00001: val_loss improved from inf to 0.25051, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 18s 64ms/step - loss: 0.2831 - acc: 0.9053 - val_loss: 0.2505 - val_acc: 0.9134 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2368 - acc: 0.9170\n",
      "Epoch 00002: val_loss improved from 0.25051 to 0.24128, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.2367 - acc: 0.9171 - val_loss: 0.2413 - val_acc: 0.9144 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2187 - acc: 0.9215\n",
      "Epoch 00003: val_loss improved from 0.24128 to 0.23887, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.2186 - acc: 0.9215 - val_loss: 0.2389 - val_acc: 0.9153 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9253\n",
      "Epoch 00004: val_loss did not improve from 0.23887\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.2063 - acc: 0.9253 - val_loss: 0.2392 - val_acc: 0.9158 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9293\n",
      "Epoch 00005: val_loss did not improve from 0.23887\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1959 - acc: 0.9294 - val_loss: 0.2460 - val_acc: 0.9081 - lr: 0.0010\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9327\n",
      "Epoch 00006: val_loss did not improve from 0.23887\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1842 - acc: 0.9327 - val_loss: 0.2411 - val_acc: 0.9148 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9344- ETA: 1s - los\n",
      "Epoch 00007: val_loss did not improve from 0.23887\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1805 - acc: 0.9344 - val_loss: 0.2418 - val_acc: 0.9124 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9356\n",
      "Epoch 00008: val_loss did not improve from 0.23887\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1782 - acc: 0.9356 - val_loss: 0.2418 - val_acc: 0.9120 - lr: 4.0000e-05\n",
      "AUC:  0.8837081054711664 AUPRC:  0.580418834325865 F1:  0.47214076246334313\n",
      "0.8845924522387936 0.5853172232284884 0.917286022536562 0.4700460829493088\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9332\n",
      "Epoch 00001: val_loss improved from inf to 0.17757, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 18s 65ms/step - loss: 0.2152 - acc: 0.9332 - val_loss: 0.1776 - val_acc: 0.9383 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9437-\n",
      "Epoch 00002: val_loss improved from 0.17757 to 0.17022, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.1722 - acc: 0.9437 - val_loss: 0.1702 - val_acc: 0.9459 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9469\n",
      "Epoch 00003: val_loss improved from 0.17022 to 0.16893, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 17s 73ms/step - loss: 0.1582 - acc: 0.9468 - val_loss: 0.1689 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9498\n",
      "Epoch 00004: val_loss did not improve from 0.16893\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1477 - acc: 0.9498 - val_loss: 0.1706 - val_acc: 0.9464 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9524\n",
      "Epoch 00005: val_loss did not improve from 0.16893\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.1388 - acc: 0.9524 - val_loss: 0.1715 - val_acc: 0.9435 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9561\n",
      "Epoch 00006: val_loss did not improve from 0.16893\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1288 - acc: 0.9561 - val_loss: 0.1708 - val_acc: 0.9455 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9564\n",
      "Epoch 00007: val_loss did not improve from 0.16893\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1267 - acc: 0.9564 - val_loss: 0.1712 - val_acc: 0.9431 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9565\n",
      "Epoch 00008: val_loss did not improve from 0.16893\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1256 - acc: 0.9565 - val_loss: 0.1713 - val_acc: 0.9431 - lr: 4.0000e-05\n",
      "AUC:  0.8803335254948158 AUPRC:  0.5150375058655381 F1:  0.4449339207048459\n",
      "0.8826085503504858 0.5187156036132754 0.940302085830736 0.44295302013422816\n",
      "Iteration number:  7\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2858 - acc: 0.9020\n",
      "Epoch 00001: val_loss improved from inf to 0.24995, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 20s 69ms/step - loss: 0.2856 - acc: 0.9020 - val_loss: 0.2500 - val_acc: 0.9129 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9157\n",
      "Epoch 00002: val_loss improved from 0.24995 to 0.24334, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.2361 - acc: 0.9156 - val_loss: 0.2433 - val_acc: 0.9153 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9215\n",
      "Epoch 00003: val_loss improved from 0.24334 to 0.24320, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 17s 76ms/step - loss: 0.2199 - acc: 0.9215 - val_loss: 0.2432 - val_acc: 0.9110 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9245\n",
      "Epoch 00004: val_loss improved from 0.24320 to 0.24294, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.2086 - acc: 0.9244 - val_loss: 0.2429 - val_acc: 0.9100 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9269\n",
      "Epoch 00005: val_loss improved from 0.24294 to 0.24118, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1994 - acc: 0.9270 - val_loss: 0.2412 - val_acc: 0.9096 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1903 - acc: 0.9307\n",
      "Epoch 00006: val_loss did not improve from 0.24118\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1902 - acc: 0.9307 - val_loss: 0.2472 - val_acc: 0.9091 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9344\n",
      "Epoch 00007: val_loss did not improve from 0.24118\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1804 - acc: 0.9344 - val_loss: 0.2461 - val_acc: 0.9081 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9385\n",
      "Epoch 00008: val_loss did not improve from 0.24118\n",
      "230/230 [==============================] - 17s 72ms/step - loss: 0.1718 - acc: 0.9385 - val_loss: 0.2472 - val_acc: 0.9091 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9402\n",
      "Epoch 00009: val_loss did not improve from 0.24118\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1695 - acc: 0.9402 - val_loss: 0.2477 - val_acc: 0.9081 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9400\n",
      "Epoch 00010: val_loss did not improve from 0.24118\n",
      "230/230 [==============================] - 17s 73ms/step - loss: 0.1676 - acc: 0.9400 - val_loss: 0.2478 - val_acc: 0.9086 - lr: 4.0000e-05\n",
      "AUC:  0.8798507981509435 AUPRC:  0.5761764917264133 F1:  0.4573082489146166\n",
      "0.8808453200321924 0.5803554988170972 0.9141692639654759 0.45426829268292684\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2153 - acc: 0.9346\n",
      "Epoch 00001: val_loss improved from inf to 0.18882, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 19s 70ms/step - loss: 0.2152 - acc: 0.9346 - val_loss: 0.1888 - val_acc: 0.9407 - lr: 0.0010\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9423\n",
      "Epoch 00002: val_loss improved from 0.18882 to 0.17219, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 72ms/step - loss: 0.1725 - acc: 0.9423 - val_loss: 0.1722 - val_acc: 0.9435 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9471\n",
      "Epoch 00003: val_loss did not improve from 0.17219\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1558 - acc: 0.9472 - val_loss: 0.1753 - val_acc: 0.9402 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 00004: val_loss improved from 0.17219 to 0.17211, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1451 - acc: 0.9500 - val_loss: 0.1721 - val_acc: 0.9450 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9531\n",
      "Epoch 00005: val_loss did not improve from 0.17211\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.1333 - acc: 0.9532 - val_loss: 0.1726 - val_acc: 0.9426 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9538\n",
      "Epoch 00006: val_loss did not improve from 0.17211\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.1312 - acc: 0.9538 - val_loss: 0.1736 - val_acc: 0.9402 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9550\n",
      "Epoch 00007: val_loss did not improve from 0.17211\n",
      "230/230 [==============================] - 17s 72ms/step - loss: 0.1291 - acc: 0.9550 - val_loss: 0.1734 - val_acc: 0.9411 - lr: 4.0000e-05\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9549\n",
      "Epoch 00008: val_loss did not improve from 0.17211\n",
      "230/230 [==============================] - 17s 72ms/step - loss: 0.1283 - acc: 0.9549 - val_loss: 0.1735 - val_acc: 0.9421 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9550\n",
      "Epoch 00009: val_loss did not improve from 0.17211\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1284 - acc: 0.9551 - val_loss: 0.1735 - val_acc: 0.9421 - lr: 1.0000e-05\n",
      "AUC:  0.8904946904946907 AUPRC:  0.5308492177799 F1:  0.4551422319474836\n",
      "0.8902051950439047 0.5282700464671072 0.9407815871493647 0.42956120092378747\n",
      "Iteration number:  8\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2901 - acc: 0.9013\n",
      "Epoch 00001: val_loss improved from inf to 0.25133, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 18s 65ms/step - loss: 0.2900 - acc: 0.9013 - val_loss: 0.2513 - val_acc: 0.9096 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9136\n",
      "Epoch 00002: val_loss improved from 0.25133 to 0.24762, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.2394 - acc: 0.9136 - val_loss: 0.2476 - val_acc: 0.9091 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2222 - acc: 0.9214\n",
      "Epoch 00003: val_loss improved from 0.24762 to 0.24456, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.2222 - acc: 0.9214 - val_loss: 0.2446 - val_acc: 0.9110 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2075 - acc: 0.9252\n",
      "Epoch 00004: val_loss did not improve from 0.24456\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.2075 - acc: 0.9252 - val_loss: 0.2505 - val_acc: 0.9053 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9286\n",
      "Epoch 00005: val_loss did not improve from 0.24456\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1984 - acc: 0.9285 - val_loss: 0.2465 - val_acc: 0.9077 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1864 - acc: 0.9334\n",
      "Epoch 00006: val_loss did not improve from 0.24456\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1866 - acc: 0.9333 - val_loss: 0.2468 - val_acc: 0.9057 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9344- ETA: 0s - loss: 0.1843 - acc: 0.9\n",
      "Epoch 00007: val_loss did not improve from 0.24456\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1844 - acc: 0.9344 - val_loss: 0.2474 - val_acc: 0.9062 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1822 - acc: 0.9342\n",
      "Epoch 00008: val_loss did not improve from 0.24456\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1821 - acc: 0.9343 - val_loss: 0.2475 - val_acc: 0.9067 - lr: 4.0000e-05\n",
      "AUC:  0.878551085313245 AUPRC:  0.574146416136978 F1:  0.4683357879234168\n",
      "0.8805407182474733 0.5817267776956363 0.9158475185806761 0.47218045112781953\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9322\n",
      "Epoch 00001: val_loss improved from inf to 0.17427, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 18s 64ms/step - loss: 0.2222 - acc: 0.9322 - val_loss: 0.1743 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9433\n",
      "Epoch 00002: val_loss improved from 0.17427 to 0.16847, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1742 - acc: 0.9433 - val_loss: 0.1685 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9455\n",
      "Epoch 00003: val_loss did not improve from 0.16847\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1611 - acc: 0.9455 - val_loss: 0.1697 - val_acc: 0.9450 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1519 - acc: 0.9489\n",
      "Epoch 00004: val_loss improved from 0.16847 to 0.16835, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1518 - acc: 0.9489 - val_loss: 0.1683 - val_acc: 0.9455 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9501\n",
      "Epoch 00005: val_loss improved from 0.16835 to 0.16805, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1441 - acc: 0.9501 - val_loss: 0.1680 - val_acc: 0.9402 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9526\n",
      "Epoch 00006: val_loss did not improve from 0.16805\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1375 - acc: 0.9526 - val_loss: 0.1695 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9539\n",
      "Epoch 00007: val_loss did not improve from 0.16805\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.1315 - acc: 0.9540 - val_loss: 0.1702 - val_acc: 0.9435 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9561\n",
      "Epoch 00008: val_loss did not improve from 0.16805\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1233 - acc: 0.9561 - val_loss: 0.1700 - val_acc: 0.9421 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9572\n",
      "Epoch 00009: val_loss did not improve from 0.16805\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.1229 - acc: 0.9572 - val_loss: 0.1703 - val_acc: 0.9421 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9567\n",
      "Epoch 00010: val_loss did not improve from 0.16805\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1214 - acc: 0.9568 - val_loss: 0.1703 - val_acc: 0.9421 - lr: 4.0000e-05\n",
      "AUC:  0.8837707095771612 AUPRC:  0.5206219314418529 F1:  0.4468546637744036\n",
      "0.8869321837063772 0.5279932486828324 0.9376648285782786 0.44206008583690987\n",
      "Iteration number:  9\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.9010\n",
      "Epoch 00001: val_loss improved from inf to 0.25144, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 20s 72ms/step - loss: 0.2858 - acc: 0.9011 - val_loss: 0.2514 - val_acc: 0.9144 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2353 - acc: 0.9165\n",
      "Epoch 00002: val_loss improved from 0.25144 to 0.24599, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.2353 - acc: 0.9165 - val_loss: 0.2460 - val_acc: 0.9134 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9240- ETA: 0s - loss: 0.2189 - \n",
      "Epoch 00003: val_loss improved from 0.24599 to 0.24394, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.2177 - acc: 0.9240 - val_loss: 0.2439 - val_acc: 0.9124 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9286\n",
      "Epoch 00004: val_loss did not improve from 0.24394\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.2044 - acc: 0.9285 - val_loss: 0.2483 - val_acc: 0.9072 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9297\n",
      "Epoch 00005: val_loss did not improve from 0.24394\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1937 - acc: 0.9297 - val_loss: 0.2464 - val_acc: 0.9100 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1807 - acc: 0.9349\n",
      "Epoch 00006: val_loss did not improve from 0.24394\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.1806 - acc: 0.9349 - val_loss: 0.2473 - val_acc: 0.9057 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9364\n",
      "Epoch 00007: val_loss did not improve from 0.24394\n",
      "230/230 [==============================] - 17s 73ms/step - loss: 0.1783 - acc: 0.9364 - val_loss: 0.2481 - val_acc: 0.9081 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9367\n",
      "Epoch 00008: val_loss did not improve from 0.24394\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.1757 - acc: 0.9368 - val_loss: 0.2482 - val_acc: 0.9077 - lr: 4.0000e-05\n",
      "AUC:  0.8797918809778836 AUPRC:  0.5852623481267591 F1:  0.48985507246376814\n",
      "0.8800911802170273 0.587086020624238 0.9153680172620474 0.47548291233283796\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2152 - acc: 0.9331\n",
      "Epoch 00001: val_loss improved from inf to 0.17465, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 18s 66ms/step - loss: 0.2151 - acc: 0.9332 - val_loss: 0.1746 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9431- ETA: 0s - loss: 0.1716 - acc: \n",
      "Epoch 00002: val_loss improved from 0.17465 to 0.17038, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1716 - acc: 0.9431 - val_loss: 0.1704 - val_acc: 0.9416 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9456\n",
      "Epoch 00003: val_loss improved from 0.17038 to 0.16822, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1590 - acc: 0.9456 - val_loss: 0.1682 - val_acc: 0.9435 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9501\n",
      "Epoch 00004: val_loss did not improve from 0.16822\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1481 - acc: 0.9501 - val_loss: 0.1691 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9526\n",
      "Epoch 00005: val_loss did not improve from 0.16822\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1387 - acc: 0.9526 - val_loss: 0.1685 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9554\n",
      "Epoch 00006: val_loss did not improve from 0.16822\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.1302 - acc: 0.9553 - val_loss: 0.1689 - val_acc: 0.9411 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9552\n",
      "Epoch 00007: val_loss did not improve from 0.16822\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1280 - acc: 0.9552 - val_loss: 0.1696 - val_acc: 0.9402 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9567\n",
      "Epoch 00008: val_loss did not improve from 0.16822\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.1260 - acc: 0.9567 - val_loss: 0.1696 - val_acc: 0.9407 - lr: 4.0000e-05\n",
      "AUC:  0.8887259693711307 AUPRC:  0.5271192252615514 F1:  0.4304347826086956\n",
      "0.8850874334745303 0.523726150693976 0.9393430831934788 0.4074941451990632\n",
      "Iteration number:  10\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9036\n",
      "Epoch 00001: val_loss improved from inf to 0.24892, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 17s 63ms/step - loss: 0.2841 - acc: 0.9036 - val_loss: 0.2489 - val_acc: 0.9086 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2374 - acc: 0.9151\n",
      "Epoch 00002: val_loss improved from 0.24892 to 0.24315, saving model to 64-basiccnn1d-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 67ms/step - loss: 0.2372 - acc: 0.9151 - val_loss: 0.2431 - val_acc: 0.9129 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9202\n",
      "Epoch 00003: val_loss did not improve from 0.24315\n",
      "230/230 [==============================] - 16s 70ms/step - loss: 0.2199 - acc: 0.9202 - val_loss: 0.2466 - val_acc: 0.9086 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9232\n",
      "Epoch 00004: val_loss did not improve from 0.24315\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.2098 - acc: 0.9232 - val_loss: 0.2441 - val_acc: 0.9158 - lr: 0.0010\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9288\n",
      "Epoch 00005: val_loss did not improve from 0.24315\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1966 - acc: 0.9288 - val_loss: 0.2444 - val_acc: 0.9144 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9292\n",
      "Epoch 00006: val_loss did not improve from 0.24315\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1942 - acc: 0.9291 - val_loss: 0.2452 - val_acc: 0.9144 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9310\n",
      "Epoch 00007: val_loss did not improve from 0.24315\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1905 - acc: 0.9310 - val_loss: 0.2452 - val_acc: 0.9144 - lr: 4.0000e-05\n",
      "AUC:  0.8837823411092219 AUPRC:  0.5821317022416761 F1:  0.46715328467153283\n",
      "0.8800240146397392 0.5820114320332163 0.9148885159434188 0.4580152671755725\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9354\n",
      "Epoch 00001: val_loss improved from inf to 0.17335, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 17s 62ms/step - loss: 0.2111 - acc: 0.9354 - val_loss: 0.1734 - val_acc: 0.9407 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9413\n",
      "Epoch 00002: val_loss improved from 0.17335 to 0.17155, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1728 - acc: 0.9412 - val_loss: 0.1716 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9471\n",
      "Epoch 00003: val_loss did not improve from 0.17155\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 0.1568 - acc: 0.9472 - val_loss: 0.1726 - val_acc: 0.9407 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9498\n",
      "Epoch 00004: val_loss improved from 0.17155 to 0.17105, saving model to 64-basiccnn1d-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1444 - acc: 0.9499 - val_loss: 0.1711 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9528\n",
      "Epoch 00005: val_loss did not improve from 0.17105\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1351 - acc: 0.9528 - val_loss: 0.1734 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9549\n",
      "Epoch 00006: val_loss did not improve from 0.17105\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 0.1253 - acc: 0.9549 - val_loss: 0.1749 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9598\n",
      "Epoch 00007: val_loss did not improve from 0.17105\n",
      "230/230 [==============================] - 16s 71ms/step - loss: 0.1153 - acc: 0.9598 - val_loss: 0.1747 - val_acc: 0.9411 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9600\n",
      "Epoch 00008: val_loss did not improve from 0.17105\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1133 - acc: 0.9600 - val_loss: 0.1751 - val_acc: 0.9435 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9599\n",
      "Epoch 00009: val_loss did not improve from 0.17105\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1119 - acc: 0.9599 - val_loss: 0.1752 - val_acc: 0.9411 - lr: 4.0000e-05\n",
      "AUC:  0.8883061383061384 AUPRC:  0.513838177284804 F1:  0.46382978723404256\n",
      "0.8866238898496962 0.5202884799142125 0.9422200911052505 0.4608501118568233\n",
      "Embedding:  fasttext\n",
      "=============================\n",
      "(14665, 64, 100)\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.3018 - acc: 0.8984\n",
      "Epoch 00001: val_loss improved from inf to 0.25098, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 212s 913ms/step - loss: 0.3018 - acc: 0.8984 - val_loss: 0.2510 - val_acc: 0.9115 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2407 - acc: 0.9142\n",
      "Epoch 00002: val_loss improved from 0.25098 to 0.24273, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 35s 151ms/step - loss: 0.2406 - acc: 0.9143 - val_loss: 0.2427 - val_acc: 0.9115 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9206\n",
      "Epoch 00003: val_loss did not improve from 0.24273\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.2220 - acc: 0.9207 - val_loss: 0.2449 - val_acc: 0.9129 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9231\n",
      "Epoch 00004: val_loss did not improve from 0.24273\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.2112 - acc: 0.9229 - val_loss: 0.2430 - val_acc: 0.9124 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9289\n",
      "Epoch 00005: val_loss improved from 0.24273 to 0.24194, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 29s 126ms/step - loss: 0.1984 - acc: 0.9289 - val_loss: 0.2419 - val_acc: 0.9144 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9281\n",
      "Epoch 00006: val_loss did not improve from 0.24194\n",
      "230/230 [==============================] - 28s 122ms/step - loss: 0.1957 - acc: 0.9281 - val_loss: 0.2422 - val_acc: 0.9144 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9303\n",
      "Epoch 00007: val_loss did not improve from 0.24194\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.1933 - acc: 0.9303 - val_loss: 0.2427 - val_acc: 0.9153 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9291\n",
      "Epoch 00008: val_loss did not improve from 0.24194\n",
      "230/230 [==============================] - 29s 126ms/step - loss: 0.1925 - acc: 0.9292 - val_loss: 0.2428 - val_acc: 0.9148 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9298\n",
      "Epoch 00009: val_loss did not improve from 0.24194\n",
      "230/230 [==============================] - 28s 121ms/step - loss: 0.1911 - acc: 0.9297 - val_loss: 0.2428 - val_acc: 0.9144 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1912 - acc: 0.9301\n",
      "Epoch 00010: val_loss did not improve from 0.24194\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 0.1911 - acc: 0.9302 - val_loss: 0.2429 - val_acc: 0.9144 - lr: 1.0000e-05\n",
      "AUC:  0.8782600344783296 AUPRC:  0.5716392065574237 F1:  0.4491017964071856\n",
      "0.8779495409763045 0.5740582464023144 0.9127307600095901 0.4484848484848485\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9314\n",
      "Epoch 00001: val_loss improved from inf to 0.17668, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 30s 117ms/step - loss: 0.2259 - acc: 0.9315 - val_loss: 0.1767 - val_acc: 0.9426 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9424\n",
      "Epoch 00002: val_loss improved from 0.17668 to 0.17100, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 115ms/step - loss: 0.1754 - acc: 0.9423 - val_loss: 0.1710 - val_acc: 0.9450 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9460\n",
      "Epoch 00003: val_loss improved from 0.17100 to 0.17077, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1607 - acc: 0.9459 - val_loss: 0.1708 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9480\n",
      "Epoch 00004: val_loss did not improve from 0.17077\n",
      "230/230 [==============================] - 26s 115ms/step - loss: 0.1509 - acc: 0.9480 - val_loss: 0.1714 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9506\n",
      "Epoch 00005: val_loss did not improve from 0.17077\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1417 - acc: 0.9506 - val_loss: 0.1711 - val_acc: 0.9450 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9531\n",
      "Epoch 00006: val_loss did not improve from 0.17077\n",
      "230/230 [==============================] - 27s 115ms/step - loss: 0.1325 - acc: 0.9531 - val_loss: 0.1715 - val_acc: 0.9435 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9548\n",
      "Epoch 00007: val_loss did not improve from 0.17077\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.1302 - acc: 0.9549 - val_loss: 0.1717 - val_acc: 0.9455 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9550\n",
      "Epoch 00008: val_loss did not improve from 0.17077\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.1287 - acc: 0.9551 - val_loss: 0.1717 - val_acc: 0.9450 - lr: 4.0000e-05\n",
      "AUC:  0.8820312304183272 AUPRC:  0.5199338501770522 F1:  0.456140350877193\n",
      "0.8822292402937563 0.5187682720110083 0.9398225845121074 0.4038004750593824\n",
      "Iteration number:  2\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.8982\n",
      "Epoch 00001: val_loss improved from inf to 0.25023, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 33s 129ms/step - loss: 0.3030 - acc: 0.8982 - val_loss: 0.2502 - val_acc: 0.9187 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9144\n",
      "Epoch 00002: val_loss improved from 0.25023 to 0.24381, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.2410 - acc: 0.9144 - val_loss: 0.2438 - val_acc: 0.9167 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2230 - acc: 0.9221\n",
      "Epoch 00003: val_loss improved from 0.24381 to 0.24323, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.2232 - acc: 0.9220 - val_loss: 0.2432 - val_acc: 0.9144 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9243\n",
      "Epoch 00004: val_loss did not improve from 0.24323\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.2126 - acc: 0.9242 - val_loss: 0.2441 - val_acc: 0.9134 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9284\n",
      "Epoch 00005: val_loss did not improve from 0.24323\n",
      "230/230 [==============================] - 25s 111ms/step - loss: 0.2020 - acc: 0.9284 - val_loss: 0.2445 - val_acc: 0.9144 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1908 - acc: 0.9314\n",
      "Epoch 00006: val_loss did not improve from 0.24323\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1908 - acc: 0.9314 - val_loss: 0.2454 - val_acc: 0.9124 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9330\n",
      "Epoch 00007: val_loss did not improve from 0.24323\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1885 - acc: 0.9330 - val_loss: 0.2464 - val_acc: 0.9115 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1866 - acc: 0.9332\n",
      "Epoch 00008: val_loss did not improve from 0.24323\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.1866 - acc: 0.9332 - val_loss: 0.2465 - val_acc: 0.9110 - lr: 4.0000e-05\n",
      "AUC:  0.875249956106706 AUPRC:  0.5797660455306295 F1:  0.4726735598227474\n",
      "0.8757074479555151 0.5819490754898872 0.9146487652841045 0.4718100890207715\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9341\n",
      "Epoch 00001: val_loss improved from inf to 0.17889, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 30s 116ms/step - loss: 0.2241 - acc: 0.9340 - val_loss: 0.1789 - val_acc: 0.9392 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9425\n",
      "Epoch 00002: val_loss improved from 0.17889 to 0.17314, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.1763 - acc: 0.9425 - val_loss: 0.1731 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9451\n",
      "Epoch 00003: val_loss did not improve from 0.17314\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1608 - acc: 0.9450 - val_loss: 0.1771 - val_acc: 0.9344 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9481\n",
      "Epoch 00004: val_loss did not improve from 0.17314\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1495 - acc: 0.9481 - val_loss: 0.1742 - val_acc: 0.9388 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9518\n",
      "Epoch 00005: val_loss did not improve from 0.17314\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.1389 - acc: 0.9519 - val_loss: 0.1745 - val_acc: 0.9397 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9524\n",
      "Epoch 00006: val_loss did not improve from 0.17314\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1361 - acc: 0.9525 - val_loss: 0.1753 - val_acc: 0.9402 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9533\n",
      "Epoch 00007: val_loss did not improve from 0.17314\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.1344 - acc: 0.9533 - val_loss: 0.1754 - val_acc: 0.9392 - lr: 4.0000e-05\n",
      "AUC:  0.8866827915215012 AUPRC:  0.5301405165956448 F1:  0.4529147982062781\n",
      "0.8850941173521819 0.5270128105241759 0.941021337808679 0.4459459459459459\n",
      "Iteration number:  3\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3011 - acc: 0.9009\n",
      "Epoch 00001: val_loss improved from inf to 0.25598, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 29s 112ms/step - loss: 0.3010 - acc: 0.9009 - val_loss: 0.2560 - val_acc: 0.9096 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2417 - acc: 0.9148\n",
      "Epoch 00002: val_loss improved from 0.25598 to 0.24681, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 22s 95ms/step - loss: 0.2417 - acc: 0.9148 - val_loss: 0.2468 - val_acc: 0.9120 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2239 - acc: 0.9188- E\n",
      "Epoch 00003: val_loss did not improve from 0.24681\n",
      "230/230 [==============================] - 22s 95ms/step - loss: 0.2238 - acc: 0.9189 - val_loss: 0.2478 - val_acc: 0.9124 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9236\n",
      "Epoch 00004: val_loss did not improve from 0.24681\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.2126 - acc: 0.9237 - val_loss: 0.2482 - val_acc: 0.9086 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9285\n",
      "Epoch 00005: val_loss did not improve from 0.24681\n",
      "230/230 [==============================] - 24s 102ms/step - loss: 0.1994 - acc: 0.9285 - val_loss: 0.2474 - val_acc: 0.9081 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9279- ETA: 5s - los - ETA: 3s - loss: 0 - ETA: 1s - loss: 0.1960 -\n",
      "Epoch 00006: val_loss did not improve from 0.24681\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.1972 - acc: 0.9279 - val_loss: 0.2478 - val_acc: 0.9077 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9297\n",
      "Epoch 00007: val_loss did not improve from 0.24681\n",
      "230/230 [==============================] - 23s 98ms/step - loss: 0.1950 - acc: 0.9296 - val_loss: 0.2477 - val_acc: 0.9081 - lr: 4.0000e-05\n",
      "AUC:  0.8818539820349757 AUPRC:  0.5871296691299527 F1:  0.48046309696092626\n",
      "0.8759899558003368 0.5808966570349899 0.9136897626468473 0.46587537091988124\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9325\n",
      "Epoch 00001: val_loss improved from inf to 0.18064, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 101ms/step - loss: 0.2294 - acc: 0.9325 - val_loss: 0.1806 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9437\n",
      "Epoch 00002: val_loss improved from 0.18064 to 0.17277, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.1750 - acc: 0.9437 - val_loss: 0.1728 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9465\n",
      "Epoch 00003: val_loss did not improve from 0.17277\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1606 - acc: 0.9465 - val_loss: 0.1735 - val_acc: 0.9402 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9504\n",
      "Epoch 00004: val_loss did not improve from 0.17277\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.1503 - acc: 0.9504 - val_loss: 0.1794 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9524- ETA: 2s - lo\n",
      "Epoch 00005: val_loss improved from 0.17277 to 0.17059, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.1400 - acc: 0.9525 - val_loss: 0.1706 - val_acc: 0.9411 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9525\n",
      "Epoch 00006: val_loss did not improve from 0.17059\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.1384 - acc: 0.9525 - val_loss: 0.1707 - val_acc: 0.9407 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9537\n",
      "Epoch 00007: val_loss did not improve from 0.17059\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.1359 - acc: 0.9538 - val_loss: 0.1709 - val_acc: 0.9416 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9537\n",
      "Epoch 00008: val_loss did not improve from 0.17059\n",
      "230/230 [==============================] - 32s 141ms/step - loss: 0.1353 - acc: 0.9537 - val_loss: 0.1709 - val_acc: 0.9407 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9532\n",
      "Epoch 00009: val_loss did not improve from 0.17059\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.1357 - acc: 0.9532 - val_loss: 0.1709 - val_acc: 0.9407 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9532\n",
      "Epoch 00010: val_loss did not improve from 0.17059\n",
      "230/230 [==============================] - 23s 102ms/step - loss: 0.1349 - acc: 0.9532 - val_loss: 0.1709 - val_acc: 0.9407 - lr: 1.0000e-05\n",
      "AUC:  0.8886014821498693 AUPRC:  0.5276540943493847 F1:  0.46017699115044247\n",
      "0.8887025757993501 0.530420440126772 0.9419803404459363 0.4598214285714286\n",
      "Iteration number:  4\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.9013\n",
      "Epoch 00001: val_loss improved from inf to 0.24761, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 33s 127ms/step - loss: 0.3014 - acc: 0.9012 - val_loss: 0.2476 - val_acc: 0.9144 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9155\n",
      "Epoch 00002: val_loss improved from 0.24761 to 0.24449, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 33s 144ms/step - loss: 0.2391 - acc: 0.9156 - val_loss: 0.2445 - val_acc: 0.9144 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2215 - acc: 0.9216\n",
      "Epoch 00003: val_loss improved from 0.24449 to 0.24353, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 30s 130ms/step - loss: 0.2216 - acc: 0.9216 - val_loss: 0.2435 - val_acc: 0.9139 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2096 - acc: 0.9241\n",
      "Epoch 00004: val_loss improved from 0.24353 to 0.24167, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.2098 - acc: 0.9240 - val_loss: 0.2417 - val_acc: 0.9120 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9273\n",
      "Epoch 00005: val_loss did not improve from 0.24167\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 0.1992 - acc: 0.9273 - val_loss: 0.2498 - val_acc: 0.9115 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9299\n",
      "Epoch 00006: val_loss did not improve from 0.24167\n",
      "230/230 [==============================] - 31s 134ms/step - loss: 0.1925 - acc: 0.9300 - val_loss: 0.2467 - val_acc: 0.9081 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9335\n",
      "Epoch 00007: val_loss did not improve from 0.24167\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 0.1807 - acc: 0.9334 - val_loss: 0.2463 - val_acc: 0.9091 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9345\n",
      "Epoch 00008: val_loss did not improve from 0.24167\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 0.1787 - acc: 0.9345 - val_loss: 0.2465 - val_acc: 0.9100 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9336\n",
      "Epoch 00009: val_loss did not improve from 0.24167\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.1782 - acc: 0.9336 - val_loss: 0.2465 - val_acc: 0.9100 - lr: 4.0000e-05\n",
      "AUC:  0.8753318509772592 AUPRC:  0.5795877147580027 F1:  0.4826589595375722\n",
      "0.8768236337991325 0.5863836218072976 0.917286022536562 0.4888888888888888\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9320\n",
      "Epoch 00001: val_loss improved from inf to 0.18114, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 30s 114ms/step - loss: 0.2246 - acc: 0.9320 - val_loss: 0.1811 - val_acc: 0.9402 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9421\n",
      "Epoch 00002: val_loss improved from 0.18114 to 0.17486, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.1768 - acc: 0.9421 - val_loss: 0.1749 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1617 - acc: 0.9464\n",
      "Epoch 00003: val_loss did not improve from 0.17486\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.1617 - acc: 0.9463 - val_loss: 0.1755 - val_acc: 0.9397 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9490\n",
      "Epoch 00004: val_loss improved from 0.17486 to 0.17439, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1508 - acc: 0.9489 - val_loss: 0.1744 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9517\n",
      "Epoch 00005: val_loss did not improve from 0.17439\n",
      "230/230 [==============================] - 28s 124ms/step - loss: 0.1416 - acc: 0.9517 - val_loss: 0.1762 - val_acc: 0.9416 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9544\n",
      "Epoch 00006: val_loss did not improve from 0.17439\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.1336 - acc: 0.9543 - val_loss: 0.1785 - val_acc: 0.9388 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9567\n",
      "Epoch 00007: val_loss did not improve from 0.17439\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.1252 - acc: 0.9566 - val_loss: 0.1788 - val_acc: 0.9388 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9570\n",
      "Epoch 00008: val_loss did not improve from 0.17439\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.1230 - acc: 0.9570 - val_loss: 0.1794 - val_acc: 0.9402 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9584\n",
      "Epoch 00009: val_loss did not improve from 0.17439\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.1209 - acc: 0.9584 - val_loss: 0.1794 - val_acc: 0.9388 - lr: 4.0000e-05\n",
      "AUC:  0.8852303013593337 AUPRC:  0.5200383777776083 F1:  0.44298245614035087\n",
      "0.8833972479133769 0.5225673702866678 0.9412610884679933 0.43935926773455386\n",
      "Iteration number:  5\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2903 - acc: 0.9024\n",
      "Epoch 00001: val_loss improved from inf to 0.24999, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 30s 110ms/step - loss: 0.2903 - acc: 0.9024 - val_loss: 0.2500 - val_acc: 0.9153 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9169\n",
      "Epoch 00002: val_loss improved from 0.24999 to 0.24623, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.2377 - acc: 0.9169 - val_loss: 0.2462 - val_acc: 0.9110 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9196\n",
      "Epoch 00003: val_loss improved from 0.24623 to 0.24436, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 24s 102ms/step - loss: 0.2212 - acc: 0.9195 - val_loss: 0.2444 - val_acc: 0.9105 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9244\n",
      "Epoch 00004: val_loss did not improve from 0.24436\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.2098 - acc: 0.9244 - val_loss: 0.2470 - val_acc: 0.9086 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1990 - acc: 0.9275\n",
      "Epoch 00005: val_loss did not improve from 0.24436\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.1990 - acc: 0.9275 - val_loss: 0.2476 - val_acc: 0.9115 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9313- ETA: 0s - loss: 0.1876 - acc: \n",
      "Epoch 00006: val_loss did not improve from 0.24436\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1876 - acc: 0.9313 - val_loss: 0.2482 - val_acc: 0.9100 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9329\n",
      "Epoch 00007: val_loss did not improve from 0.24436\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1838 - acc: 0.9329 - val_loss: 0.2490 - val_acc: 0.9110 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9344\n",
      "Epoch 00008: val_loss did not improve from 0.24436\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1818 - acc: 0.9344 - val_loss: 0.2492 - val_acc: 0.9105 - lr: 4.0000e-05\n",
      "AUC:  0.8792150818536286 AUPRC:  0.5820357513130217 F1:  0.47838616714697413\n",
      "0.8799639191232183 0.5807732131676697 0.9139295133061616 0.478955007256894\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9335\n",
      "Epoch 00001: val_loss improved from inf to 0.17864, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 28s 105ms/step - loss: 0.2295 - acc: 0.9336 - val_loss: 0.1786 - val_acc: 0.9397 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9424\n",
      "Epoch 00002: val_loss improved from 0.17864 to 0.17546, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1756 - acc: 0.9424 - val_loss: 0.1755 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1594 - acc: 0.9479\n",
      "Epoch 00003: val_loss did not improve from 0.17546\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1593 - acc: 0.9479 - val_loss: 0.1761 - val_acc: 0.9431 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9490\n",
      "Epoch 00004: val_loss improved from 0.17546 to 0.17480, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.1492 - acc: 0.9490 - val_loss: 0.1748 - val_acc: 0.9431 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9517\n",
      "Epoch 00005: val_loss did not improve from 0.17480\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1396 - acc: 0.9517 - val_loss: 0.1763 - val_acc: 0.9402 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9565\n",
      "Epoch 00006: val_loss did not improve from 0.17480\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.1316 - acc: 0.9565 - val_loss: 0.1769 - val_acc: 0.9416 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9567\n",
      "Epoch 00007: val_loss did not improve from 0.17480\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.1220 - acc: 0.9567 - val_loss: 0.1776 - val_acc: 0.9416 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9589\n",
      "Epoch 00008: val_loss did not improve from 0.17480\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.1201 - acc: 0.9589 - val_loss: 0.1782 - val_acc: 0.9416 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9603\n",
      "Epoch 00009: val_loss did not improve from 0.17480\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.1180 - acc: 0.9603 - val_loss: 0.1783 - val_acc: 0.9416 - lr: 4.0000e-05\n",
      "AUC:  0.8822492919267112 AUPRC:  0.5189892869217512 F1:  0.45033112582781454\n",
      "0.8816193364580461 0.5186707518885502 0.9407815871493647 0.4399092970521542\n",
      "Iteration number:  6\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2923 - acc: 0.9030\n",
      "Epoch 00001: val_loss improved from inf to 0.25317, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 27s 106ms/step - loss: 0.2923 - acc: 0.9030 - val_loss: 0.2532 - val_acc: 0.9124 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9143\n",
      "Epoch 00002: val_loss improved from 0.25317 to 0.24284, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.2391 - acc: 0.9144 - val_loss: 0.2428 - val_acc: 0.9120 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2211 - acc: 0.9199\n",
      "Epoch 00003: val_loss did not improve from 0.24284\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.2210 - acc: 0.9199 - val_loss: 0.2469 - val_acc: 0.9120 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9255\n",
      "Epoch 00004: val_loss did not improve from 0.24284\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.2053 - acc: 0.9255 - val_loss: 0.2485 - val_acc: 0.9124 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9301\n",
      "Epoch 00005: val_loss did not improve from 0.24284\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1912 - acc: 0.9302 - val_loss: 0.2496 - val_acc: 0.9105 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9320\n",
      "Epoch 00006: val_loss did not improve from 0.24284\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.1885 - acc: 0.9321 - val_loss: 0.2504 - val_acc: 0.9110 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9334\n",
      "Epoch 00007: val_loss did not improve from 0.24284\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1866 - acc: 0.9334 - val_loss: 0.2505 - val_acc: 0.9115 - lr: 4.0000e-05\n",
      "AUC:  0.8765608632072858 AUPRC:  0.5732102439125151 F1:  0.4704142011834319\n",
      "0.872653476289962 0.5585589987442144 0.9110525053943899 0.41390205371248023\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9340\n",
      "Epoch 00001: val_loss improved from inf to 0.17973, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 27s 105ms/step - loss: 0.2205 - acc: 0.9339 - val_loss: 0.1797 - val_acc: 0.9392 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9433\n",
      "Epoch 00002: val_loss improved from 0.17973 to 0.17208, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.1733 - acc: 0.9433 - val_loss: 0.1721 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9480\n",
      "Epoch 00003: val_loss improved from 0.17208 to 0.16967, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.1560 - acc: 0.9480 - val_loss: 0.1697 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9517\n",
      "Epoch 00004: val_loss did not improve from 0.16967\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.1437 - acc: 0.9517 - val_loss: 0.1705 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9535\n",
      "Epoch 00005: val_loss did not improve from 0.16967\n",
      "230/230 [==============================] - 23s 102ms/step - loss: 0.1332 - acc: 0.9535 - val_loss: 0.1731 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9586\n",
      "Epoch 00006: val_loss did not improve from 0.16967\n",
      "230/230 [==============================] - 22s 97ms/step - loss: 0.1219 - acc: 0.9586 - val_loss: 0.1727 - val_acc: 0.9407 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9588- ETA: 0s - loss: 0.1199 - acc: 0.95\n",
      "Epoch 00007: val_loss did not improve from 0.16967\n",
      "230/230 [==============================] - 23s 98ms/step - loss: 0.1199 - acc: 0.9588 - val_loss: 0.1734 - val_acc: 0.9407 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9599\n",
      "Epoch 00008: val_loss did not improve from 0.16967\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 0.1171 - acc: 0.9598 - val_loss: 0.1735 - val_acc: 0.9402 - lr: 4.0000e-05\n",
      "AUC:  0.8897511091059479 AUPRC:  0.5175999163237727 F1:  0.4434589800443459\n",
      "0.8912925783893526 0.5208627949334946 0.9412610884679933 0.43418013856812937\n",
      "Iteration number:  7\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2923 - acc: 0.9007\n",
      "Epoch 00001: val_loss improved from inf to 0.24645, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 27s 104ms/step - loss: 0.2922 - acc: 0.9008 - val_loss: 0.2465 - val_acc: 0.9134 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9163\n",
      "Epoch 00002: val_loss improved from 0.24645 to 0.24498, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.2377 - acc: 0.9163 - val_loss: 0.2450 - val_acc: 0.9144 - lr: 0.0010\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9213\n",
      "Epoch 00003: val_loss improved from 0.24498 to 0.23958, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.2209 - acc: 0.9213 - val_loss: 0.2396 - val_acc: 0.9134 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9264\n",
      "Epoch 00004: val_loss did not improve from 0.23958\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.2099 - acc: 0.9264 - val_loss: 0.2461 - val_acc: 0.9153 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9285\n",
      "Epoch 00005: val_loss did not improve from 0.23958\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.1980 - acc: 0.9284 - val_loss: 0.2411 - val_acc: 0.9144 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9327\n",
      "Epoch 00006: val_loss did not improve from 0.23958\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.1861 - acc: 0.9326 - val_loss: 0.2421 - val_acc: 0.9124 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9342\n",
      "Epoch 00007: val_loss did not improve from 0.23958\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.1828 - acc: 0.9342 - val_loss: 0.2428 - val_acc: 0.9129 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9345- ETA: 1s - loss: 0\n",
      "Epoch 00008: val_loss did not improve from 0.23958\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.1815 - acc: 0.9345 - val_loss: 0.2430 - val_acc: 0.9124 - lr: 4.0000e-05\n",
      "AUC:  0.8782450105991995 AUPRC:  0.5750819230554168 F1:  0.47782546494992845\n",
      "0.8776502417371611 0.5782217867353482 0.9153680172620474 0.46433990895295896\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9313- ETA: 0s - loss: 0.2379 - acc\n",
      "Epoch 00001: val_loss improved from inf to 0.18229, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 100ms/step - loss: 0.2351 - acc: 0.9313 - val_loss: 0.1823 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9430\n",
      "Epoch 00002: val_loss improved from 0.18229 to 0.17419, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.1781 - acc: 0.9430 - val_loss: 0.1742 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1637 - acc: 0.9456- ETA: 0s - loss: 0.1633 - acc: \n",
      "Epoch 00003: val_loss improved from 0.17419 to 0.17356, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 23s 98ms/step - loss: 0.1636 - acc: 0.9456 - val_loss: 0.1736 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9480- ETA: 1s - loss: 0.15\n",
      "Epoch 00004: val_loss improved from 0.17356 to 0.17039, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 22s 95ms/step - loss: 0.1542 - acc: 0.9480 - val_loss: 0.1704 - val_acc: 0.9402 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9503\n",
      "Epoch 00005: val_loss did not improve from 0.17039\n",
      "230/230 [==============================] - 22s 97ms/step - loss: 0.1464 - acc: 0.9503 - val_loss: 0.1727 - val_acc: 0.9392 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9512\n",
      "Epoch 00006: val_loss did not improve from 0.17039\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 0.1404 - acc: 0.9512 - val_loss: 0.1751 - val_acc: 0.9416 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9533- ETA: 8s - loss: 0.1 - \n",
      "Epoch 00007: val_loss did not improve from 0.17039\n",
      "230/230 [==============================] - 22s 96ms/step - loss: 0.1325 - acc: 0.9534 - val_loss: 0.1732 - val_acc: 0.9383 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9544- ETA: 1s - loss: 0.1305 - acc: - ETA: 1s - loss: 0.1312 - \n",
      "Epoch 00008: val_loss did not improve from 0.17039\n",
      "230/230 [==============================] - 24s 102ms/step - loss: 0.1300 - acc: 0.9544 - val_loss: 0.1737 - val_acc: 0.9392 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9561\n",
      "Epoch 00009: val_loss did not improve from 0.17039\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 0.1282 - acc: 0.9562 - val_loss: 0.1737 - val_acc: 0.9388 - lr: 4.0000e-05\n",
      "AUC:  0.8836403739629546 AUPRC:  0.5188768850689964 F1:  0.44008714596949894\n",
      "0.8837230869488936 0.5190558100270556 0.9386238312155358 0.43362831858407075\n",
      "Iteration number:  8\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3022 - acc: 0.8994\n",
      "Epoch 00001: val_loss improved from inf to 0.24952, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 23s 89ms/step - loss: 0.3024 - acc: 0.8994 - val_loss: 0.2495 - val_acc: 0.9105 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.9157\n",
      "Epoch 00002: val_loss improved from 0.24952 to 0.24507, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 20s 88ms/step - loss: 0.2388 - acc: 0.9156 - val_loss: 0.2451 - val_acc: 0.9153 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.9191\n",
      "Epoch 00003: val_loss did not improve from 0.24507\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 0.2213 - acc: 0.9192 - val_loss: 0.2471 - val_acc: 0.9105 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9258\n",
      "Epoch 00004: val_loss improved from 0.24507 to 0.24458, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 0.2097 - acc: 0.9258 - val_loss: 0.2446 - val_acc: 0.9124 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9277\n",
      "Epoch 00005: val_loss did not improve from 0.24458\n",
      "230/230 [==============================] - 21s 90ms/step - loss: 0.1995 - acc: 0.9277 - val_loss: 0.2462 - val_acc: 0.9057 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1908 - acc: 0.9320\n",
      "Epoch 00006: val_loss did not improve from 0.24458\n",
      "230/230 [==============================] - 20s 89ms/step - loss: 0.1907 - acc: 0.9321 - val_loss: 0.2501 - val_acc: 0.9110 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9365\n",
      "Epoch 00007: val_loss did not improve from 0.24458\n",
      "230/230 [==============================] - 21s 91ms/step - loss: 0.1792 - acc: 0.9365 - val_loss: 0.2492 - val_acc: 0.9091 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9362\n",
      "Epoch 00008: val_loss did not improve from 0.24458\n",
      "230/230 [==============================] - 20s 89ms/step - loss: 0.1781 - acc: 0.9362 - val_loss: 0.2499 - val_acc: 0.9086 - lr: 2.0000e-04\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9387- ETA: 5s -  - ETA: 2\n",
      "Epoch 00009: val_loss did not improve from 0.24458\n",
      "230/230 [==============================] - 22s 95ms/step - loss: 0.1754 - acc: 0.9386 - val_loss: 0.2498 - val_acc: 0.9081 - lr: 4.0000e-05\n",
      "AUC:  0.8772749393447703 AUPRC:  0.5818694160569384 F1:  0.4787077826725404\n",
      "0.8775288723606579 0.5842044493217542 0.9148885159434188 0.4563552833078101\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9351\n",
      "Epoch 00001: val_loss improved from inf to 0.17807, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 28s 111ms/step - loss: 0.2165 - acc: 0.9352 - val_loss: 0.1781 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9414\n",
      "Epoch 00002: val_loss improved from 0.17807 to 0.17119, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 23s 98ms/step - loss: 0.1739 - acc: 0.9414 - val_loss: 0.1712 - val_acc: 0.9421 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9468\n",
      "Epoch 00003: val_loss improved from 0.17119 to 0.17103, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.1563 - acc: 0.9467 - val_loss: 0.1710 - val_acc: 0.9407 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9503\n",
      "Epoch 00004: val_loss did not improve from 0.17103\n",
      "230/230 [==============================] - 23s 102ms/step - loss: 0.1444 - acc: 0.9503 - val_loss: 0.1727 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9542\n",
      "Epoch 00005: val_loss did not improve from 0.17103\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.1342 - acc: 0.9542 - val_loss: 0.1741 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9587- ETA: 2s -\n",
      "Epoch 00006: val_loss did not improve from 0.17103\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.1225 - acc: 0.9587 - val_loss: 0.1755 - val_acc: 0.9416 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9589\n",
      "Epoch 00007: val_loss did not improve from 0.17103\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1202 - acc: 0.9589 - val_loss: 0.1766 - val_acc: 0.9421 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9595\n",
      "Epoch 00008: val_loss did not improve from 0.17103\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1187 - acc: 0.9595 - val_loss: 0.1767 - val_acc: 0.9421 - lr: 4.0000e-05\n",
      "AUC:  0.8806000451161741 AUPRC:  0.5168347608420871 F1:  0.46696035242290757\n",
      "0.8826545020093407 0.5236930230599274 0.9417405897866219 0.45393258426966293\n",
      "Iteration number:  9\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2915 - acc: 0.9009\n",
      "Epoch 00001: val_loss improved from inf to 0.24879, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 30s 115ms/step - loss: 0.2914 - acc: 0.9010 - val_loss: 0.2488 - val_acc: 0.9077 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9163\n",
      "Epoch 00002: val_loss improved from 0.24879 to 0.24811, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.2384 - acc: 0.9163 - val_loss: 0.2481 - val_acc: 0.9120 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9198\n",
      "Epoch 00003: val_loss improved from 0.24811 to 0.24638, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.2219 - acc: 0.9198 - val_loss: 0.2464 - val_acc: 0.9129 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2083 - acc: 0.9248\n",
      "Epoch 00004: val_loss did not improve from 0.24638\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.2083 - acc: 0.9249 - val_loss: 0.2473 - val_acc: 0.9110 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9299\n",
      "Epoch 00005: val_loss did not improve from 0.24638\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.1960 - acc: 0.9298 - val_loss: 0.2485 - val_acc: 0.9096 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9338\n",
      "Epoch 00006: val_loss did not improve from 0.24638\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.1838 - acc: 0.9338 - val_loss: 0.2485 - val_acc: 0.9105 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9363\n",
      "Epoch 00007: val_loss did not improve from 0.24638\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.1811 - acc: 0.9362 - val_loss: 0.2490 - val_acc: 0.9115 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9360\n",
      "Epoch 00008: val_loss did not improve from 0.24638\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.1787 - acc: 0.9360 - val_loss: 0.2491 - val_acc: 0.9100 - lr: 4.0000e-05\n",
      "AUC:  0.8779630919261086 AUPRC:  0.5711820417847558 F1:  0.4567164179104478\n",
      "0.873871883428838 0.5681926037781811 0.9110525053943899 0.40064620355411956\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9317\n",
      "Epoch 00001: val_loss improved from inf to 0.18142, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 29s 110ms/step - loss: 0.2282 - acc: 0.9317 - val_loss: 0.1814 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9434\n",
      "Epoch 00002: val_loss improved from 0.18142 to 0.17493, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1756 - acc: 0.9433 - val_loss: 0.1749 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9465\n",
      "Epoch 00003: val_loss improved from 0.17493 to 0.17289, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.1606 - acc: 0.9465 - val_loss: 0.1729 - val_acc: 0.9411 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9493\n",
      "Epoch 00004: val_loss did not improve from 0.17289\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.1493 - acc: 0.9493 - val_loss: 0.1784 - val_acc: 0.9378 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9515\n",
      "Epoch 00005: val_loss did not improve from 0.17289\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.1414 - acc: 0.9515 - val_loss: 0.1736 - val_acc: 0.9373 - lr: 0.0010\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9556\n",
      "Epoch 00006: val_loss did not improve from 0.17289\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.1309 - acc: 0.9555 - val_loss: 0.1747 - val_acc: 0.9383 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9559\n",
      "Epoch 00007: val_loss did not improve from 0.17289\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.1289 - acc: 0.9558 - val_loss: 0.1753 - val_acc: 0.9383 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9569\n",
      "Epoch 00008: val_loss did not improve from 0.17289\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.1267 - acc: 0.9568 - val_loss: 0.1753 - val_acc: 0.9373 - lr: 4.0000e-05\n",
      "AUC:  0.8855168726136466 AUPRC:  0.5279251938339963 F1:  0.46551724137931033\n",
      "0.8817713946746205 0.520536113617849 0.9405418364900503 0.4464285714285714\n",
      "Iteration number:  10\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9020\n",
      "Epoch 00001: val_loss improved from inf to 0.24744, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 30s 115ms/step - loss: 0.2883 - acc: 0.9020 - val_loss: 0.2474 - val_acc: 0.9148 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.9155\n",
      "Epoch 00002: val_loss improved from 0.24744 to 0.24188, saving model to 64-basiccnn1d-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.2376 - acc: 0.9154 - val_loss: 0.2419 - val_acc: 0.9105 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2195 - acc: 0.9205\n",
      "Epoch 00003: val_loss did not improve from 0.24188\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.2194 - acc: 0.9206 - val_loss: 0.2431 - val_acc: 0.9100 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2054 - acc: 0.9249\n",
      "Epoch 00004: val_loss did not improve from 0.24188\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.2053 - acc: 0.9249 - val_loss: 0.2430 - val_acc: 0.9124 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9306\n",
      "Epoch 00005: val_loss did not improve from 0.24188\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1905 - acc: 0.9306 - val_loss: 0.2425 - val_acc: 0.9120 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1873 - acc: 0.9316\n",
      "Epoch 00006: val_loss did not improve from 0.24188\n",
      "230/230 [==============================] - 27s 115ms/step - loss: 0.1873 - acc: 0.9315 - val_loss: 0.2426 - val_acc: 0.9124 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9329\n",
      "Epoch 00007: val_loss did not improve from 0.24188\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1852 - acc: 0.9330 - val_loss: 0.2427 - val_acc: 0.9124 - lr: 4.0000e-05\n",
      "AUC:  0.8808117372435482 AUPRC:  0.5753601316106379 F1:  0.4753623188405798\n",
      "0.8763051626762065 0.5765679070725772 0.9144090146247902 0.46795827123695977\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "x_train_lstm (14665, 24, 104) x_dev_lstm (2090, 24, 104)\n",
      "x_train_ner (14665, 64, 100) x_dev_ner (2090, 64, 100)\n",
      "(14665,)\n",
      "(14665, 24, 104) (14665, 64, 100) 2\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9300\n",
      "Epoch 00001: val_loss improved from inf to 0.18184, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 30s 118ms/step - loss: 0.2364 - acc: 0.9300 - val_loss: 0.1818 - val_acc: 0.9440 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1773 - acc: 0.9419\n",
      "Epoch 00002: val_loss improved from 0.18184 to 0.17456, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1773 - acc: 0.9419 - val_loss: 0.1746 - val_acc: 0.9426 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1631 - acc: 0.9463\n",
      "Epoch 00003: val_loss improved from 0.17456 to 0.17255, saving model to 64-basiccnn1d-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1631 - acc: 0.9463 - val_loss: 0.1726 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9483\n",
      "Epoch 00004: val_loss did not improve from 0.17255\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1530 - acc: 0.9483 - val_loss: 0.1736 - val_acc: 0.9445 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9515\n",
      "Epoch 00005: val_loss did not improve from 0.17255\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.1444 - acc: 0.9514 - val_loss: 0.1748 - val_acc: 0.9435 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9536\n",
      "Epoch 00006: val_loss did not improve from 0.17255\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1362 - acc: 0.9536 - val_loss: 0.1750 - val_acc: 0.9411 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9546\n",
      "Epoch 00007: val_loss did not improve from 0.17255\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.1336 - acc: 0.9546 - val_loss: 0.1751 - val_acc: 0.9411 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9550\n",
      "Epoch 00008: val_loss did not improve from 0.17255\n",
      "230/230 [==============================] - 25s 111ms/step - loss: 0.1314 - acc: 0.9550 - val_loss: 0.1751 - val_acc: 0.9411 - lr: 4.0000e-05\n",
      "AUC:  0.885531911338363 AUPRC:  0.5188734619169956 F1:  0.4478935698447894\n",
      "0.8813887426790653 0.5186208954203407 0.9400623351714217 0.4292237442922375\n"
     ]
    }
   ],
   "source": [
    "embedding_types = ['word2vec', 'fasttext']#, 'concat']\n",
    "embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
    "\n",
    "target_problems = ['mort_hosp', 'mort_icu']#, 'los_3', 'los_7']\n",
    "\n",
    "num_epoch = 100\n",
    "model_patience = 5\n",
    "monitor_criteria = 'val_loss'\n",
    "#monitor_criteria = 'val_acc'\n",
    "batch_size = 64\n",
    "\n",
    "filter_number = 32\n",
    "ner_representation_limit = 64\n",
    "activation_func = \"relu\"\n",
    "\n",
    "sequence_model = \"GRU\"\n",
    "sequence_hidden_unit = 256\n",
    "\n",
    "maxiter = 11\n",
    "for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n",
    "    print (\"Embedding: \", embed_name)\n",
    "    print(\"=============================\")\n",
    "    \n",
    "    temp_train_ner = dict((k, embed_dict[k]) for k in train_ids)\n",
    "    tem_dev_ner = dict((k, embed_dict[k]) for k in dev_ids)\n",
    "    temp_test_ner = dict((k, embed_dict[k]) for k in test_ids)\n",
    "\n",
    "    x_train_dict = {}\n",
    "    x_dev_dict = {}\n",
    "    x_test_dict = {}\n",
    "\n",
    "    x_train_dict = get_subvector_data(ner_representation_limit, embed_name, temp_train_ner)\n",
    "    x_dev_dict = get_subvector_data(ner_representation_limit, embed_name, tem_dev_ner)\n",
    "    x_test_dict = get_subvector_data(ner_representation_limit, embed_name, temp_test_ner)\n",
    "\n",
    "    x_train_dict_sorted = collections.OrderedDict(sorted(x_train_dict.items()))\n",
    "    x_dev_dict_sorted = collections.OrderedDict(sorted(x_dev_dict.items()))\n",
    "    x_test_dict_sorted = collections.OrderedDict(sorted(x_test_dict.items()))\n",
    "    \n",
    "#     x_train_dict_sorted = sorted(x_train_dict.items())\n",
    "#     x_dev_dict_sorted = sorted(x_dev_dict.items())\n",
    "#     x_test_dict_sorted = sorted(x_test_dict.items())\n",
    "    list_train_ner =[]\n",
    "    list_test_ner =[]\n",
    "    list_dev_ner =[]\n",
    "    for k,v in x_train_dict_sorted.items():\n",
    "            list_train_ner.append(v)\n",
    "    for k,v in x_test_dict_sorted.items():\n",
    "            list_test_ner.append(v)\n",
    "    for k,v in x_dev_dict_sorted.items():\n",
    "            list_dev_ner.append(v)\n",
    "    \n",
    "        \n",
    "    \n",
    "    x_train_ner = np.array(list_train_ner)\n",
    "    x_dev_ner = np.array(list_dev_ner)\n",
    "    x_test_ner = np.array(list_test_ner)\n",
    "    \n",
    "    print(x_train_ner.shape)\n",
    "    \n",
    "\n",
    "    #print('shape of x_train_ner{0} x_dev_ner{1} x_test_ner {2}'.format(x_train_ner.shape,x_dev_ner.shape,x_test_ner.shape))\n",
    "    \n",
    "        \n",
    "    for iteration in range(1,maxiter):\n",
    "        print (\"Iteration number: \", iteration)\n",
    "    \n",
    "        for each_problem in target_problems:\n",
    "            print (\"Problem type: \", each_problem)\n",
    "            print (\"__________________\")\n",
    "            \n",
    "            \n",
    "            early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "            \n",
    "            best_model_name = str(ner_representation_limit)+\"-basiccnn1d-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "            \n",
    "            checkpoint = ModelCheckpoint(best_model_name, monitor=monitor_criteria, verbose=1,\n",
    "                save_best_only=True, mode='min')\n",
    "            \n",
    "            reduce_lr = ReduceLROnPlateau(monitor=monitor_criteria, factor=0.2,\n",
    "                              patience=2, min_lr=0.00001, epsilon=1e-4, mode='min')\n",
    "            \n",
    "\n",
    "            callbacks = [early_stopping_monitor, checkpoint, reduce_lr]\n",
    "            \n",
    "            #model = textCNN(sequence_model, sequence_hidden_unit, embed_name, ner_representation_limit)\n",
    "            model = proposedmodel(sequence_model, sequence_hidden_unit, \n",
    "                               embed_name, ner_representation_limit,filter_number)\n",
    "            print('x_train_lstm {0} x_dev_lstm {1}'.format(x_train_lstm.shape,x_dev_lstm.shape))\n",
    "            print('x_train_ner {0} x_dev_ner {1}'.format(x_train_ner.shape,x_dev_ner.shape))\n",
    "            print(y_train[each_problem].shape)\n",
    "            aa = [x_train_lstm, x_train_ner]\n",
    "            print(x_train_lstm.shape, x_train_ner.shape, len(aa))\n",
    "            model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n",
    "                      validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, batch_size=batch_size)\n",
    "            \n",
    "            \n",
    "            probs, predictions = make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
    "            print_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration, sequence_hidden_unit)\n",
    "            \n",
    "            model.load_weights(best_model_name)\n",
    "                      \n",
    "            probs, predictions = make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
    "            save_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration,\n",
    "                            sequence_hidden_unit, sequence_model, type_of_ner)\n",
    "            del model\n",
    "            clear_session()\n",
    "            gc.collect()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding_types = ['word2vec', 'fasttext', 'concat']\n",
    "embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
    "\n",
    "target_problems = [ 'mort_icu', 'los_3', 'los_7']#['mort_hosp']#,\n",
    "\n",
    "num_epoch = 100\n",
    "model_patience = 5\n",
    "monitor_criteria = 'val_loss'\n",
    "#monitor_criteria = 'val_acc'\n",
    "batch_size = 64\n",
    "\n",
    "filter_number = 32\n",
    "ner_representation_limit = 64\n",
    "activation_func = \"relu\"\n",
    "\n",
    "sequence_model = \"GRU\"\n",
    "sequence_hidden_unit = 256\n",
    "\n",
    "maxiter = 11\n",
    "for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n",
    "    print (\"Embedding: \", embed_name)\n",
    "    print(\"=============================\")\n",
    "    \n",
    "    temp_train_ner = dict((k, embed_dict[k]) for k in train_ids)\n",
    "    tem_dev_ner = dict((k, embed_dict[k]) for k in dev_ids)\n",
    "    temp_test_ner = dict((k, embed_dict[k]) for k in test_ids)\n",
    "\n",
    "    x_train_dict = {}\n",
    "    x_dev_dict = {}\n",
    "    x_test_dict = {}\n",
    "\n",
    "    x_train_dict = get_subvector_data(ner_representation_limit, embed_name, temp_train_ner)\n",
    "    x_dev_dict = get_subvector_data(ner_representation_limit, embed_name, tem_dev_ner)\n",
    "    x_test_dict = get_subvector_data(ner_representation_limit, embed_name, temp_test_ner)\n",
    "\n",
    "    x_train_dict_sorted = collections.OrderedDict(sorted(x_train_dict.items()))\n",
    "    x_dev_dict_sorted = collections.OrderedDict(sorted(x_dev_dict.items()))\n",
    "    x_test_dict_sorted = collections.OrderedDict(sorted(x_test_dict.items()))\n",
    "    \n",
    "#     x_train_dict_sorted = sorted(x_train_dict.items())\n",
    "#     x_dev_dict_sorted = sorted(x_dev_dict.items())\n",
    "#     x_test_dict_sorted = sorted(x_test_dict.items())\n",
    "    list_train_ner =[]\n",
    "    list_test_ner =[]\n",
    "    list_dev_ner =[]\n",
    "    for k,v in x_train_dict_sorted.items():\n",
    "            list_train_ner.append(v)\n",
    "    for k,v in x_test_dict_sorted.items():\n",
    "            list_test_ner.append(v)\n",
    "    for k,v in x_dev_dict_sorted.items():\n",
    "            list_dev_ner.append(v)\n",
    "    \n",
    "        \n",
    "    \n",
    "    x_train_ner = np.array(list_train_ner)\n",
    "    x_dev_ner = np.array(list_dev_ner)\n",
    "    x_test_ner = np.array(list_test_ner)\n",
    "    \n",
    "    print(x_train_ner.shape)\n",
    "    \n",
    "\n",
    "    #print('shape of x_train_ner{0} x_dev_ner{1} x_test_ner {2}'.format(x_train_ner.shape,x_dev_ner.shape,x_test_ner.shape))\n",
    "    \n",
    "        \n",
    "    for iteration in range(1,maxiter):\n",
    "        print (\"Iteration number: \", iteration)\n",
    "    \n",
    "        for each_problem in target_problems:\n",
    "            print (\"Problem type: \", each_problem)\n",
    "            print (\"__________________\")\n",
    "            \n",
    "            \n",
    "            early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "            \n",
    "            best_model_name = str(ner_representation_limit)+\"-basiccnn1d-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "            \n",
    "            checkpoint = ModelCheckpoint(best_model_name, monitor=monitor_criteria, verbose=1,\n",
    "                save_best_only=True, mode='min')\n",
    "            \n",
    "            reduce_lr = ReduceLROnPlateau(monitor=monitor_criteria, factor=0.2,\n",
    "                              patience=2, min_lr=0.00001, epsilon=1e-4, mode='min')\n",
    "            \n",
    "\n",
    "            callbacks = [early_stopping_monitor, checkpoint, reduce_lr]\n",
    "            \n",
    "            #model = textCNN(sequence_model, sequence_hidden_unit, embed_name, ner_representation_limit)\n",
    "            model = proposedmodel(sequence_model, sequence_hidden_unit, \n",
    "                               embed_name, ner_representation_limit,filter_number)\n",
    "            print('x_train_lstm {0} x_dev_lstm {1}'.format(x_train_lstm.shape,x_dev_lstm.shape))\n",
    "            print('x_train_ner {0} x_dev_ner {1}'.format(x_train_ner.shape,x_dev_ner.shape))\n",
    "            print(y_train[each_problem].shape)\n",
    "            aa = [x_train_lstm, x_train_ner]\n",
    "            print(x_train_lstm.shape, x_train_ner.shape, len(aa))\n",
    "            model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n",
    "                      validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, batch_size=batch_size)\n",
    "            \n",
    "            \n",
    "            probs, predictions = make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
    "            print_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration, sequence_hidden_unit)\n",
    "            \n",
    "            model.load_weights(best_model_name)\n",
    "                      \n",
    "            probs, predictions = make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
    "            save_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration,\n",
    "                            sequence_hidden_unit, sequence_model, type_of_ner)\n",
    "            del model\n",
    "            clear_session()\n",
    "            gc.collect()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
