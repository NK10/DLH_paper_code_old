{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "# import glove nitin commented as its not used\n",
    "# from glove import Corpus\n",
    "\n",
    "import collections\n",
    "import gc \n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, merge, Activation, Concatenate, LSTM, GRU\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n",
    "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D, merge\n",
    "\n",
    "# from keras.optimizers import Adam # nitin commented as Adam has been shifted to optimizer_v1 module.\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "#from keras.backend.tensorflow_backend import set_session, clear_session, get_session # nitin commented as tensorflow_backend not used anymore\n",
    "from keras.backend import set_session, clear_session, get_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dict_of_ner):\n",
    "    temp_data = []\n",
    "    for k, v in sorted(dict_of_ner.items()):\n",
    "        temp = []\n",
    "        for embed in v:\n",
    "            temp.append(embed)\n",
    "            #print(embed)\n",
    "        temp_data.append(np.mean(temp, axis = 0)) \n",
    "    return np.asarray(temp_data)\n",
    "\n",
    "def make_prediction_multi_avg(model, test_data):\n",
    "    probs = model.predict(test_data)\n",
    "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
    "    return probs, y_pred\n",
    "\n",
    "def save_scores_multi_avg(predictions, probs, ground_truth, \n",
    "                          \n",
    "                          embed_name, problem_type, iteration, hidden_unit_size,\n",
    "                          \n",
    "                          sequence_name, type_of_ner):\n",
    "    \n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    result_dict = {}    \n",
    "    result_dict['auc'] = auc\n",
    "    result_dict['auprc'] = auprc\n",
    "    result_dict['acc'] = acc\n",
    "    result_dict['F1'] = F1\n",
    "    \n",
    "    result_path = \"results/\"\n",
    "    file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n",
    "    file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-avg-.p\"\n",
    "    \n",
    "    print('auc{0}, auprc{1}, acc{2}, F1{3} '.format(auc,auprc,acc,F1))\n",
    "    \n",
    "    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
    "\n",
    "    print(auc, auprc, acc, F1)\n",
    "    \n",
    "def avg_ner_model(layer_name, number_of_unit, embedding_name):\n",
    "\n",
    "    if embedding_name == \"concat\":\n",
    "        input_dimension = 200\n",
    "    else:\n",
    "        input_dimension = 100\n",
    "\n",
    "    sequence_input = Input(shape=(24,104))\n",
    "\n",
    "    input_avg = Input(shape=(input_dimension, ), name = \"avg\")        \n",
    "#     x_1 = Dense(256, activation='relu')(input_avg)\n",
    "#     x_1 = Dropout(0.3)(x_1)\n",
    "    \n",
    "    if layer_name == \"GRU\":\n",
    "        x = GRU(number_of_unit)(sequence_input)\n",
    "    elif layer_name == \"LSTM\":\n",
    "        x = LSTM(number_of_unit)(sequence_input)\n",
    "\n",
    "    x = keras.layers.Concatenate()([x, input_avg])\n",
    "\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    #logits_regularizer = tf.contrib.layers.l2_regularizer(scale=0.01) nitin commented as its deprecated\n",
    "    logits_regularizer = tf.keras.regularizers.L2(0.01)\n",
    "    # removed tf.compat.v1.estimator.layers.xavier_initializer() with glorot_normal\n",
    "    preds = Dense(1, activation='sigmoid',use_bias=False,\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal(), \n",
    "                  kernel_regularizer=logits_regularizer)(x)\n",
    "    \n",
    "    \n",
    "    opt = Adam(lr=0.001, decay = 0.01)\n",
    "    model = Model(inputs=[sequence_input, input_avg], outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nitin added as without it the read_pickel below was giving the error as in notebook 5 when its writing\n",
    "#pickel do a lazy execution and write the function as well\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_ner = \"new\"\n",
    "\n",
    "x_train_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_train.pkl\")\n",
    "x_dev_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_dev.pkl\")\n",
    "x_test_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_test.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(\"data/\"+type_of_ner+\"_y_train.pkl\")\n",
    "y_dev = pd.read_pickle(\"data/\"+type_of_ner+\"_y_dev.pkl\")\n",
    "y_test = pd.read_pickle(\"data/\"+type_of_ner+\"_y_test.pkl\")\n",
    "\n",
    "ner_word2vec = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_word2vec_limited_dict.pkl\")\n",
    "ner_fasttext = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_fasttext_limited_dict.pkl\")\n",
    "ner_concat = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_combined_limited_dict.pkl\")\n",
    "\n",
    "train_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_train_ids.pkl\")\n",
    "dev_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_dev_ids.pkl\")\n",
    "test_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_test_ids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from collections.abc import Iterable, Iterator\n",
    "def create_dataset(dict_of_ner):\n",
    "    temp_data = []\n",
    "    for k, v in sorted(dict_of_ner.items()):\n",
    "        temp = []\n",
    "        for embed in v:\n",
    "            print(type(embed),embed)\n",
    "            print(isinstance(embed, Iterator))\n",
    "            temp.append(embed)\n",
    "            \n",
    "        temp_data.append(np.mean(temp, axis = 0)) \n",
    "    return np.asarray(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tt = dict({ke:va})\n",
    "create_dataset(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for ke, va in temp_train_ner.items():\n",
    "    print(ke, va)\n",
    "    print(nit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:  GRU\n",
      "Hidden unit:  128\n",
      "Embedding:  word2vec\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3136 - acc: 0.8913\n",
      "Epoch 00001: val_loss improved from inf to 0.25143, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 19ms/step - loss: 0.3135 - acc: 0.8914 - val_loss: 0.2514 - val_acc: 0.9124\n",
      "Epoch 2/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.2539 - acc: 0.9122\n",
      "Epoch 00002: val_loss improved from 0.25143 to 0.24561, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2549 - acc: 0.9120 - val_loss: 0.2456 - val_acc: 0.9153\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9159\n",
      "Epoch 00003: val_loss did not improve from 0.24561\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2442 - acc: 0.9159 - val_loss: 0.2460 - val_acc: 0.9172\n",
      "Epoch 4/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.2351 - acc: 0.9187\n",
      "Epoch 00004: val_loss improved from 0.24561 to 0.24382, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.2347 - acc: 0.9188 - val_loss: 0.2438 - val_acc: 0.9153\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9171\n",
      "Epoch 00005: val_loss improved from 0.24382 to 0.24217, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2295 - acc: 0.9171 - val_loss: 0.2422 - val_acc: 0.9158\n",
      "Epoch 6/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9206\n",
      "Epoch 00006: val_loss did not improve from 0.24217\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2266 - acc: 0.9202 - val_loss: 0.2428 - val_acc: 0.9148\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2236 - acc: 0.9218\n",
      "Epoch 00007: val_loss improved from 0.24217 to 0.24172, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2236 - acc: 0.9218 - val_loss: 0.2417 - val_acc: 0.9148\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2204 - acc: 0.9237\n",
      "Epoch 00008: val_loss did not improve from 0.24172\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2204 - acc: 0.9237 - val_loss: 0.2417 - val_acc: 0.9134\n",
      "Epoch 9/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9239\n",
      "Epoch 00009: val_loss improved from 0.24172 to 0.24117, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2158 - acc: 0.9237 - val_loss: 0.2412 - val_acc: 0.9139\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9248\n",
      "Epoch 00010: val_loss improved from 0.24117 to 0.24067, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2137 - acc: 0.9247 - val_loss: 0.2407 - val_acc: 0.9158\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2131 - acc: 0.9230\n",
      "Epoch 00011: val_loss did not improve from 0.24067\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2129 - acc: 0.9232 - val_loss: 0.2412 - val_acc: 0.9144\n",
      "Epoch 12/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9235\n",
      "Epoch 00012: val_loss improved from 0.24067 to 0.24061, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.2119 - acc: 0.9238 - val_loss: 0.2406 - val_acc: 0.9139\n",
      "Epoch 13/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9248\n",
      "Epoch 00013: val_loss improved from 0.24061 to 0.24001, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 0.2111 - acc: 0.9249 - val_loss: 0.2400 - val_acc: 0.9148\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2083 - acc: 0.9243\n",
      "Epoch 00014: val_loss did not improve from 0.24001\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 0.2083 - acc: 0.9243 - val_loss: 0.2408 - val_acc: 0.9134\n",
      "Epoch 15/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9255\n",
      "Epoch 00015: val_loss did not improve from 0.24001\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.2079 - acc: 0.9254 - val_loss: 0.2408 - val_acc: 0.9124\n",
      "Epoch 16/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9271\n",
      "Epoch 00016: val_loss did not improve from 0.24001\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2067 - acc: 0.9270 - val_loss: 0.2407 - val_acc: 0.9124\n",
      "Epoch 17/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2057 - acc: 0.9262\n",
      "Epoch 00017: val_loss did not improve from 0.24001\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2057 - acc: 0.9262 - val_loss: 0.2406 - val_acc: 0.9129\n",
      "Epoch 18/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2047 - acc: 0.9268\n",
      "Epoch 00018: val_loss did not improve from 0.24001\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.2054 - acc: 0.9266 - val_loss: 0.2404 - val_acc: 0.9129\n",
      "auc0.8804214109720273, auprc0.5796555403960645, acc0.9110525053943899, F10.445440956651719 \n",
      "0.8804214109720273 0.5796555403960645 0.9110525053943899 0.445440956651719\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2400 - acc: 0.9283\n",
      "Epoch 00001: val_loss improved from inf to 0.19367, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 19ms/step - loss: 0.2400 - acc: 0.9283 - val_loss: 0.1937 - val_acc: 0.9388\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1920 - acc: 0.9399- ETA: 0s - loss: 0.1910 \n",
      "Epoch 00002: val_loss improved from 0.19367 to 0.18431, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.1920 - acc: 0.9399 - val_loss: 0.1843 - val_acc: 0.9440\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9432\n",
      "Epoch 00003: val_loss improved from 0.18431 to 0.18358, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.1802 - acc: 0.9431 - val_loss: 0.1836 - val_acc: 0.9431\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9450\n",
      "Epoch 00004: val_loss improved from 0.18358 to 0.17937, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.1748 - acc: 0.9452 - val_loss: 0.1794 - val_acc: 0.9435\n",
      "Epoch 5/100\n",
      "227/230 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9460\n",
      "Epoch 00005: val_loss improved from 0.17937 to 0.17865, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.1697 - acc: 0.9461 - val_loss: 0.1787 - val_acc: 0.9411\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9459\n",
      "Epoch 00006: val_loss did not improve from 0.17865\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1656 - acc: 0.9458 - val_loss: 0.1788 - val_acc: 0.9431\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1617 - acc: 0.9469\n",
      "Epoch 00007: val_loss did not improve from 0.17865\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1617 - acc: 0.9469 - val_loss: 0.1787 - val_acc: 0.9392\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9481\n",
      "Epoch 00008: val_loss improved from 0.17865 to 0.17743, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1605 - acc: 0.9482 - val_loss: 0.1774 - val_acc: 0.9416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1582 - acc: 0.9480\n",
      "Epoch 00009: val_loss did not improve from 0.17743\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1582 - acc: 0.9480 - val_loss: 0.1780 - val_acc: 0.9416\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9484\n",
      "Epoch 00010: val_loss did not improve from 0.17743\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1556 - acc: 0.9484 - val_loss: 0.1785 - val_acc: 0.9407\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9492\n",
      "Epoch 00011: val_loss did not improve from 0.17743\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1553 - acc: 0.9493 - val_loss: 0.1783 - val_acc: 0.9411\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9492\n",
      "Epoch 00012: val_loss did not improve from 0.17743\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1525 - acc: 0.9491 - val_loss: 0.1781 - val_acc: 0.9407\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9488\n",
      "Epoch 00013: val_loss did not improve from 0.17743\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1519 - acc: 0.9487 - val_loss: 0.1777 - val_acc: 0.9421\n",
      "auc0.884372258565807, auprc0.5131820197118032, acc0.9386238312155358, F10.4260089686098655 \n",
      "0.884372258565807 0.5131820197118032 0.9386238312155358 0.4260089686098655\n",
      "Iteration number:  2\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.9002\n",
      "Epoch 00001: val_loss improved from inf to 0.25558, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 8s 28ms/step - loss: 0.2983 - acc: 0.9001 - val_loss: 0.2556 - val_acc: 0.9124\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9103\n",
      "Epoch 00002: val_loss improved from 0.25558 to 0.24830, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.2553 - acc: 0.9104 - val_loss: 0.2483 - val_acc: 0.9129\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9154\n",
      "Epoch 00003: val_loss improved from 0.24830 to 0.24209, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2403 - acc: 0.9151 - val_loss: 0.2421 - val_acc: 0.9153\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2335 - acc: 0.9181\n",
      "Epoch 00004: val_loss improved from 0.24209 to 0.23956, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2331 - acc: 0.9182 - val_loss: 0.2396 - val_acc: 0.9182\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9211\n",
      "Epoch 00005: val_loss improved from 0.23956 to 0.23931, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2265 - acc: 0.9212 - val_loss: 0.2393 - val_acc: 0.9182\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9213\n",
      "Epoch 00006: val_loss improved from 0.23931 to 0.23743, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2248 - acc: 0.9213 - val_loss: 0.2374 - val_acc: 0.9167\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9219\n",
      "Epoch 00007: val_loss did not improve from 0.23743\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2197 - acc: 0.9220 - val_loss: 0.2385 - val_acc: 0.9158\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2166 - acc: 0.9236\n",
      "Epoch 00008: val_loss did not improve from 0.23743\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.2166 - acc: 0.9236 - val_loss: 0.2377 - val_acc: 0.9167\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2145 - acc: 0.9235\n",
      "Epoch 00009: val_loss improved from 0.23743 to 0.23666, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.2141 - acc: 0.9236 - val_loss: 0.2367 - val_acc: 0.9177\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2117 - acc: 0.9253\n",
      "Epoch 00010: val_loss did not improve from 0.23666\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.2117 - acc: 0.9253 - val_loss: 0.2380 - val_acc: 0.9172\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9246\n",
      "Epoch 00011: val_loss did not improve from 0.23666\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.2111 - acc: 0.9247 - val_loss: 0.2374 - val_acc: 0.9148\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9260\n",
      "Epoch 00012: val_loss did not improve from 0.23666\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.2079 - acc: 0.9259 - val_loss: 0.2374 - val_acc: 0.9153\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9257\n",
      "Epoch 00013: val_loss improved from 0.23666 to 0.23632, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.2077 - acc: 0.9257 - val_loss: 0.2363 - val_acc: 0.9167\n",
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9276\n",
      "Epoch 00014: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.2066 - acc: 0.9277 - val_loss: 0.2371 - val_acc: 0.9163\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9257\n",
      "Epoch 00015: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.2039 - acc: 0.9257 - val_loss: 0.2371 - val_acc: 0.9163\n",
      "Epoch 16/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9263\n",
      "Epoch 00016: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.2044 - acc: 0.9260 - val_loss: 0.2373 - val_acc: 0.9148\n",
      "Epoch 17/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9275\n",
      "Epoch 00017: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.2025 - acc: 0.9274 - val_loss: 0.2377 - val_acc: 0.9139\n",
      "Epoch 18/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2020 - acc: 0.9287\n",
      "Epoch 00018: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.2020 - acc: 0.9287 - val_loss: 0.2371 - val_acc: 0.9167\n",
      "auc0.8782806554889006, auprc0.5749854790670337, acc0.9108127547350755, F10.4670487106017192 \n",
      "0.8782806554889006 0.5749854790670337 0.9108127547350755 0.4670487106017192\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9304\n",
      "Epoch 00001: val_loss improved from inf to 0.18302, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 31ms/step - loss: 0.2327 - acc: 0.9304 - val_loss: 0.1830 - val_acc: 0.9402\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1876 - acc: 0.9397\n",
      "Epoch 00002: val_loss improved from 0.18302 to 0.18014, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1877 - acc: 0.9397 - val_loss: 0.1801 - val_acc: 0.9388\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9440- ETA: 0s - loss: 0.1738 - a\n",
      "Epoch 00003: val_loss improved from 0.18014 to 0.17926, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1758 - acc: 0.9440 - val_loss: 0.1793 - val_acc: 0.9388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9450\n",
      "Epoch 00004: val_loss improved from 0.17926 to 0.17830, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1697 - acc: 0.9449 - val_loss: 0.1783 - val_acc: 0.9368\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9472\n",
      "Epoch 00005: val_loss improved from 0.17830 to 0.17674, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1652 - acc: 0.9472 - val_loss: 0.1767 - val_acc: 0.9402\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1607 - acc: 0.9467\n",
      "Epoch 00006: val_loss did not improve from 0.17674\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1607 - acc: 0.9467 - val_loss: 0.1771 - val_acc: 0.9383\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9486\n",
      "Epoch 00007: val_loss did not improve from 0.17674\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1583 - acc: 0.9486 - val_loss: 0.1770 - val_acc: 0.9388\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1542 - acc: 0.9480\n",
      "Epoch 00008: val_loss did not improve from 0.17674\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1542 - acc: 0.9480 - val_loss: 0.1769 - val_acc: 0.9402\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9493\n",
      "Epoch 00009: val_loss did not improve from 0.17674\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1536 - acc: 0.9493 - val_loss: 0.1776 - val_acc: 0.9407\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9506\n",
      "Epoch 00010: val_loss did not improve from 0.17674\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1494 - acc: 0.9506 - val_loss: 0.1770 - val_acc: 0.9397\n",
      "auc0.8842202003492328, auprc0.5140696491568527, acc0.9381443298969072, F10.4189189189189189 \n",
      "0.8842202003492328 0.5140696491568527 0.9381443298969072 0.4189189189189189\n",
      "Iteration number:  3\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8982\n",
      "Epoch 00001: val_loss improved from inf to 0.24632, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 31ms/step - loss: 0.2980 - acc: 0.8982 - val_loss: 0.2463 - val_acc: 0.9144\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2485 - acc: 0.9137- ETA: 0s - loss: 0.249\n",
      "Epoch 00002: val_loss improved from 0.24632 to 0.24106, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2488 - acc: 0.9137 - val_loss: 0.2411 - val_acc: 0.9163\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9161\n",
      "Epoch 00003: val_loss improved from 0.24106 to 0.23905, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2353 - acc: 0.9162 - val_loss: 0.2390 - val_acc: 0.9144\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9185\n",
      "Epoch 00004: val_loss improved from 0.23905 to 0.23902, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2290 - acc: 0.9184 - val_loss: 0.2390 - val_acc: 0.9134\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9201\n",
      "Epoch 00005: val_loss improved from 0.23902 to 0.23888, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2234 - acc: 0.9201 - val_loss: 0.2389 - val_acc: 0.9144\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9215\n",
      "Epoch 00006: val_loss did not improve from 0.23888\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2196 - acc: 0.9218 - val_loss: 0.2392 - val_acc: 0.9158\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2170 - acc: 0.9223\n",
      "Epoch 00007: val_loss did not improve from 0.23888\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.2170 - acc: 0.9223 - val_loss: 0.2391 - val_acc: 0.9134\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9215\n",
      "Epoch 00008: val_loss improved from 0.23888 to 0.23851, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2147 - acc: 0.9214 - val_loss: 0.2385 - val_acc: 0.9124\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9255\n",
      "Epoch 00009: val_loss improved from 0.23851 to 0.23823, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2107 - acc: 0.9255 - val_loss: 0.2382 - val_acc: 0.9167\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9245\n",
      "Epoch 00010: val_loss did not improve from 0.23823\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2096 - acc: 0.9245 - val_loss: 0.2387 - val_acc: 0.9129\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2082 - acc: 0.9252\n",
      "Epoch 00011: val_loss did not improve from 0.23823\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2082 - acc: 0.9251 - val_loss: 0.2395 - val_acc: 0.9110\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9254\n",
      "Epoch 00012: val_loss improved from 0.23823 to 0.23809, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2073 - acc: 0.9256 - val_loss: 0.2381 - val_acc: 0.9134\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2049 - acc: 0.9267\n",
      "Epoch 00013: val_loss did not improve from 0.23809\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2056 - acc: 0.9264 - val_loss: 0.2385 - val_acc: 0.9120\n",
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9261- ETA: 1s\n",
      "Epoch 00014: val_loss did not improve from 0.23809\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2044 - acc: 0.9262 - val_loss: 0.2389 - val_acc: 0.9129\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9277\n",
      "Epoch 00015: val_loss did not improve from 0.23809\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2023 - acc: 0.9277 - val_loss: 0.2381 - val_acc: 0.9139\n",
      "Epoch 16/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9276\n",
      "Epoch 00016: val_loss did not improve from 0.23809\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2020 - acc: 0.9277 - val_loss: 0.2384 - val_acc: 0.9144\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9271\n",
      "Epoch 00017: val_loss did not improve from 0.23809\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2019 - acc: 0.9271 - val_loss: 0.2388 - val_acc: 0.9144\n",
      "auc0.8813520077205064, auprc0.5878580712723122, acc0.9139295133061616, F10.478955007256894 \n",
      "0.8813520077205064 0.5878580712723122 0.9139295133061616 0.478955007256894\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2239 - acc: 0.9331\n",
      "Epoch 00001: val_loss improved from inf to 0.18032, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 32ms/step - loss: 0.2238 - acc: 0.9331 - val_loss: 0.1803 - val_acc: 0.9431\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9407\n",
      "Epoch 00002: val_loss improved from 0.18032 to 0.17756, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1848 - acc: 0.9407 - val_loss: 0.1776 - val_acc: 0.9397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9430\n",
      "Epoch 00003: val_loss improved from 0.17756 to 0.17468, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1762 - acc: 0.9430 - val_loss: 0.1747 - val_acc: 0.9411\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9450\n",
      "Epoch 00004: val_loss improved from 0.17468 to 0.17385, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1707 - acc: 0.9448 - val_loss: 0.1738 - val_acc: 0.9416\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9451\n",
      "Epoch 00005: val_loss did not improve from 0.17385\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1649 - acc: 0.9450 - val_loss: 0.1751 - val_acc: 0.9411\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1633 - acc: 0.9464\n",
      "Epoch 00006: val_loss improved from 0.17385 to 0.17180, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1633 - acc: 0.9465 - val_loss: 0.1718 - val_acc: 0.9407\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9475\n",
      "Epoch 00007: val_loss did not improve from 0.17180\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1587 - acc: 0.9476 - val_loss: 0.1725 - val_acc: 0.9411\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1569 - acc: 0.9476\n",
      "Epoch 00008: val_loss did not improve from 0.17180\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1569 - acc: 0.9476 - val_loss: 0.1723 - val_acc: 0.9402\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9477- ETA: 1s - \n",
      "Epoch 00009: val_loss did not improve from 0.17180\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.1559 - acc: 0.9479 - val_loss: 0.1720 - val_acc: 0.9421\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9488\n",
      "Epoch 00010: val_loss improved from 0.17180 to 0.17151, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1529 - acc: 0.9489 - val_loss: 0.1715 - val_acc: 0.9421\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9498\n",
      "Epoch 00011: val_loss did not improve from 0.17151\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1517 - acc: 0.9497 - val_loss: 0.1718 - val_acc: 0.9411\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1497 - acc: 0.9493\n",
      "Epoch 00012: val_loss did not improve from 0.17151\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1497 - acc: 0.9493 - val_loss: 0.1716 - val_acc: 0.9407\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9503\n",
      "Epoch 00013: val_loss improved from 0.17151 to 0.17130, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1488 - acc: 0.9502 - val_loss: 0.1713 - val_acc: 0.9416\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9507\n",
      "Epoch 00014: val_loss improved from 0.17130 to 0.17129, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1477 - acc: 0.9508 - val_loss: 0.1713 - val_acc: 0.9411\n",
      "Epoch 15/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9500\n",
      "Epoch 00015: val_loss did not improve from 0.17129\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1468 - acc: 0.9500 - val_loss: 0.1716 - val_acc: 0.9411\n",
      "Epoch 16/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9499\n",
      "Epoch 00016: val_loss did not improve from 0.17129\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1456 - acc: 0.9499 - val_loss: 0.1714 - val_acc: 0.9411\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9503\n",
      "Epoch 00017: val_loss improved from 0.17129 to 0.17120, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1455 - acc: 0.9504 - val_loss: 0.1712 - val_acc: 0.9411\n",
      "Epoch 18/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9516\n",
      "Epoch 00018: val_loss did not improve from 0.17120\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1447 - acc: 0.9517 - val_loss: 0.1714 - val_acc: 0.9416\n",
      "Epoch 19/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9515\n",
      "Epoch 00019: val_loss did not improve from 0.17120\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1443 - acc: 0.9514 - val_loss: 0.1714 - val_acc: 0.9411\n",
      "Epoch 20/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1427 - acc: 0.9523\n",
      "Epoch 00020: val_loss did not improve from 0.17120\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1427 - acc: 0.9523 - val_loss: 0.1713 - val_acc: 0.9416\n",
      "Epoch 21/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9516\n",
      "Epoch 00021: val_loss improved from 0.17120 to 0.17108, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1426 - acc: 0.9516 - val_loss: 0.1711 - val_acc: 0.9411\n",
      "Epoch 22/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1418 - acc: 0.9507\n",
      "Epoch 00022: val_loss did not improve from 0.17108\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1418 - acc: 0.9507 - val_loss: 0.1716 - val_acc: 0.9416\n",
      "Epoch 23/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9524\n",
      "Epoch 00023: val_loss did not improve from 0.17108\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1406 - acc: 0.9524 - val_loss: 0.1716 - val_acc: 0.9416\n",
      "Epoch 24/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9525\n",
      "Epoch 00024: val_loss did not improve from 0.17108\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1404 - acc: 0.9524 - val_loss: 0.1718 - val_acc: 0.9416\n",
      "Epoch 25/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9529\n",
      "Epoch 00025: val_loss did not improve from 0.17108\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1401 - acc: 0.9528 - val_loss: 0.1716 - val_acc: 0.9411\n",
      "Epoch 26/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9514\n",
      "Epoch 00026: val_loss did not improve from 0.17108\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1387 - acc: 0.9514 - val_loss: 0.1715 - val_acc: 0.9411\n",
      "auc0.8848142299755204, auprc0.5221199021455004, acc0.9417405897866219, F10.4751619870410367 \n",
      "0.8848142299755204 0.5221199021455004 0.9417405897866219 0.4751619870410367\n",
      "Iteration number:  4\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.3042 - acc: 0.8980\n",
      "Epoch 00001: val_loss improved from inf to 0.25192, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 29ms/step - loss: 0.3042 - acc: 0.8980 - val_loss: 0.2519 - val_acc: 0.9167\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2537 - acc: 0.9125\n",
      "Epoch 00002: val_loss improved from 0.25192 to 0.24542, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2537 - acc: 0.9124 - val_loss: 0.2454 - val_acc: 0.9163\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2423 - acc: 0.9152\n",
      "Epoch 00003: val_loss improved from 0.24542 to 0.24470, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2419 - acc: 0.9154 - val_loss: 0.2447 - val_acc: 0.9144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2341 - acc: 0.9175\n",
      "Epoch 00004: val_loss improved from 0.24470 to 0.24349, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2341 - acc: 0.9175 - val_loss: 0.2435 - val_acc: 0.9144\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9191\n",
      "Epoch 00005: val_loss improved from 0.24349 to 0.24230, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2283 - acc: 0.9191 - val_loss: 0.2423 - val_acc: 0.9144\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2225 - acc: 0.9207\n",
      "Epoch 00006: val_loss improved from 0.24230 to 0.24139, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2224 - acc: 0.9208 - val_loss: 0.2414 - val_acc: 0.9139\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2206 - acc: 0.9211\n",
      "Epoch 00007: val_loss improved from 0.24139 to 0.24102, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2206 - acc: 0.9211 - val_loss: 0.2410 - val_acc: 0.9129\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2178 - acc: 0.9221\n",
      "Epoch 00008: val_loss did not improve from 0.24102\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2178 - acc: 0.9221 - val_loss: 0.2414 - val_acc: 0.9139\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2172 - acc: 0.9225\n",
      "Epoch 00009: val_loss did not improve from 0.24102\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2166 - acc: 0.9227 - val_loss: 0.2417 - val_acc: 0.9129\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2147 - acc: 0.9240\n",
      "Epoch 00010: val_loss did not improve from 0.24102\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2147 - acc: 0.9240 - val_loss: 0.2417 - val_acc: 0.9134\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2144 - acc: 0.9228\n",
      "Epoch 00011: val_loss did not improve from 0.24102\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2142 - acc: 0.9229 - val_loss: 0.2414 - val_acc: 0.9139\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9253\n",
      "Epoch 00012: val_loss did not improve from 0.24102\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2108 - acc: 0.9253 - val_loss: 0.2419 - val_acc: 0.9139\n",
      "auc0.8786665629724422, auprc0.5817561732880917, acc0.9139295133061616, F10.47591240875912405 \n",
      "0.8786665629724422 0.5817561732880917 0.9139295133061616 0.47591240875912405\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9285\n",
      "Epoch 00001: val_loss improved from inf to 0.18152, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 26ms/step - loss: 0.2360 - acc: 0.9287 - val_loss: 0.1815 - val_acc: 0.9397\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9400\n",
      "Epoch 00002: val_loss improved from 0.18152 to 0.17844, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1867 - acc: 0.9400 - val_loss: 0.1784 - val_acc: 0.9426\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9442\n",
      "Epoch 00003: val_loss did not improve from 0.17844\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1754 - acc: 0.9442 - val_loss: 0.1788 - val_acc: 0.9435\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9453\n",
      "Epoch 00004: val_loss improved from 0.17844 to 0.17746, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1694 - acc: 0.9454 - val_loss: 0.1775 - val_acc: 0.9440\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1647 - acc: 0.9467\n",
      "Epoch 00005: val_loss improved from 0.17746 to 0.17674, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1647 - acc: 0.9467 - val_loss: 0.1767 - val_acc: 0.9440\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9481\n",
      "Epoch 00006: val_loss improved from 0.17674 to 0.17511, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1623 - acc: 0.9481 - val_loss: 0.1751 - val_acc: 0.9426\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9485\n",
      "Epoch 00007: val_loss improved from 0.17511 to 0.17497, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1597 - acc: 0.9484 - val_loss: 0.1750 - val_acc: 0.9431\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9473\n",
      "Epoch 00008: val_loss did not improve from 0.17497\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1579 - acc: 0.9473 - val_loss: 0.1751 - val_acc: 0.9435\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9483\n",
      "Epoch 00009: val_loss did not improve from 0.17497\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1543 - acc: 0.9484 - val_loss: 0.1752 - val_acc: 0.9416\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9490\n",
      "Epoch 00010: val_loss improved from 0.17497 to 0.17488, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1533 - acc: 0.9491 - val_loss: 0.1749 - val_acc: 0.9402\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9490\n",
      "Epoch 00011: val_loss did not improve from 0.17488\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.1517 - acc: 0.9489 - val_loss: 0.1754 - val_acc: 0.9411\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9500\n",
      "Epoch 00012: val_loss did not improve from 0.17488\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1513 - acc: 0.9501 - val_loss: 0.1753 - val_acc: 0.9407\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9512\n",
      "Epoch 00013: val_loss did not improve from 0.17488\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1504 - acc: 0.9510 - val_loss: 0.1754 - val_acc: 0.9402\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1477 - acc: 0.9497\n",
      "Epoch 00014: val_loss did not improve from 0.17488\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1477 - acc: 0.9497 - val_loss: 0.1757 - val_acc: 0.9402\n",
      "Epoch 15/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1467 - acc: 0.9512-\n",
      "Epoch 00015: val_loss did not improve from 0.17488\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1467 - acc: 0.9512 - val_loss: 0.1757 - val_acc: 0.9402\n",
      "auc0.8847181492342782, auprc0.5189875326713302, acc0.9393430831934788, F10.4559139784946236 \n",
      "0.8847181492342782 0.5189875326713302 0.9393430831934788 0.4559139784946236\n",
      "Iteration number:  5\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.8974\n",
      "Epoch 00001: val_loss improved from inf to 0.24979, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 8s 30ms/step - loss: 0.3052 - acc: 0.8974 - val_loss: 0.2498 - val_acc: 0.9144\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.9128\n",
      "Epoch 00002: val_loss improved from 0.24979 to 0.24720, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2535 - acc: 0.9128 - val_loss: 0.2472 - val_acc: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9165\n",
      "Epoch 00003: val_loss improved from 0.24720 to 0.24529, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2444 - acc: 0.9165 - val_loss: 0.2453 - val_acc: 0.9134\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2327 - acc: 0.9200\n",
      "Epoch 00004: val_loss improved from 0.24529 to 0.24521, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2330 - acc: 0.9199 - val_loss: 0.2452 - val_acc: 0.9120\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2281 - acc: 0.9203\n",
      "Epoch 00005: val_loss improved from 0.24521 to 0.24169, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2281 - acc: 0.9203 - val_loss: 0.2417 - val_acc: 0.9100\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9228\n",
      "Epoch 00006: val_loss improved from 0.24169 to 0.24006, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2222 - acc: 0.9227 - val_loss: 0.2401 - val_acc: 0.9129\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9225\n",
      "Epoch 00007: val_loss improved from 0.24006 to 0.23988, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2198 - acc: 0.9225 - val_loss: 0.2399 - val_acc: 0.9105\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9235\n",
      "Epoch 00008: val_loss improved from 0.23988 to 0.23969, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2162 - acc: 0.9236 - val_loss: 0.2397 - val_acc: 0.9105\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9250\n",
      "Epoch 00009: val_loss improved from 0.23969 to 0.23922, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2135 - acc: 0.9251 - val_loss: 0.2392 - val_acc: 0.9120\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9258\n",
      "Epoch 00010: val_loss improved from 0.23922 to 0.23899, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2114 - acc: 0.9260 - val_loss: 0.2390 - val_acc: 0.9100\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2092 - acc: 0.9244\n",
      "Epoch 00011: val_loss improved from 0.23899 to 0.23898, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2093 - acc: 0.9243 - val_loss: 0.2390 - val_acc: 0.9105\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2088 - acc: 0.9254\n",
      "Epoch 00012: val_loss improved from 0.23898 to 0.23851, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2088 - acc: 0.9253 - val_loss: 0.2385 - val_acc: 0.9120\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9271\n",
      "Epoch 00013: val_loss did not improve from 0.23851\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2062 - acc: 0.9270 - val_loss: 0.2388 - val_acc: 0.9115\n",
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9270\n",
      "Epoch 00014: val_loss improved from 0.23851 to 0.23833, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2062 - acc: 0.9270 - val_loss: 0.2383 - val_acc: 0.9120\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9269\n",
      "Epoch 00015: val_loss improved from 0.23833 to 0.23819, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2041 - acc: 0.9268 - val_loss: 0.2382 - val_acc: 0.9105\n",
      "Epoch 16/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9286\n",
      "Epoch 00016: val_loss did not improve from 0.23819\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2013 - acc: 0.9286 - val_loss: 0.2385 - val_acc: 0.9124\n",
      "Epoch 17/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9284\n",
      "Epoch 00017: val_loss did not improve from 0.23819\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2020 - acc: 0.9285 - val_loss: 0.2388 - val_acc: 0.9120\n",
      "Epoch 18/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9283\n",
      "Epoch 00018: val_loss did not improve from 0.23819\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2000 - acc: 0.9281 - val_loss: 0.2391 - val_acc: 0.9115\n",
      "Epoch 19/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9287\n",
      "Epoch 00019: val_loss did not improve from 0.23819\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1992 - acc: 0.9287 - val_loss: 0.2385 - val_acc: 0.9115\n",
      "Epoch 20/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9283\n",
      "Epoch 00020: val_loss did not improve from 0.23819\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1973 - acc: 0.9283 - val_loss: 0.2387 - val_acc: 0.9124\n",
      "auc0.8785440152524776, auprc0.5783408095765274, acc0.9144090146247902, F10.47422680412371143 \n",
      "0.8785440152524776 0.5783408095765274 0.9144090146247902 0.47422680412371143\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2458 - acc: 0.9254\n",
      "Epoch 00001: val_loss improved from inf to 0.18778, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 28ms/step - loss: 0.2456 - acc: 0.9255 - val_loss: 0.1878 - val_acc: 0.9407\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9406\n",
      "Epoch 00002: val_loss improved from 0.18778 to 0.18142, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1901 - acc: 0.9405 - val_loss: 0.1814 - val_acc: 0.9445\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9427- ETA: 1s - loss: 0.\n",
      "Epoch 00003: val_loss improved from 0.18142 to 0.17939, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1792 - acc: 0.9429 - val_loss: 0.1794 - val_acc: 0.9431\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9455\n",
      "Epoch 00004: val_loss improved from 0.17939 to 0.17781, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1714 - acc: 0.9454 - val_loss: 0.1778 - val_acc: 0.9435\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9454\n",
      "Epoch 00005: val_loss improved from 0.17781 to 0.17699, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1683 - acc: 0.9452 - val_loss: 0.1770 - val_acc: 0.9459\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1631 - acc: 0.9468\n",
      "Epoch 00006: val_loss improved from 0.17699 to 0.17550, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1631 - acc: 0.9468 - val_loss: 0.1755 - val_acc: 0.9435\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9481\n",
      "Epoch 00007: val_loss did not improve from 0.17550\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1607 - acc: 0.9481 - val_loss: 0.1756 - val_acc: 0.9426\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1595 - acc: 0.9476\n",
      "Epoch 00008: val_loss did not improve from 0.17550\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1595 - acc: 0.9476 - val_loss: 0.1755 - val_acc: 0.9435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1562 - acc: 0.9493\n",
      "Epoch 00009: val_loss improved from 0.17550 to 0.17502, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1563 - acc: 0.9493 - val_loss: 0.1750 - val_acc: 0.9440\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9489\n",
      "Epoch 00010: val_loss improved from 0.17502 to 0.17476, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1552 - acc: 0.9489 - val_loss: 0.1748 - val_acc: 0.9431\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9492\n",
      "Epoch 00011: val_loss did not improve from 0.17476\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1541 - acc: 0.9492 - val_loss: 0.1749 - val_acc: 0.9431\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9496\n",
      "Epoch 00012: val_loss improved from 0.17476 to 0.17470, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1519 - acc: 0.9495 - val_loss: 0.1747 - val_acc: 0.9431\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9509- ETA: 2s - loss: 0.1479 - acc: - ETA: 2\n",
      "Epoch 00013: val_loss improved from 0.17470 to 0.17456, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1504 - acc: 0.9508 - val_loss: 0.1746 - val_acc: 0.9426\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9508- ETA\n",
      "Epoch 00014: val_loss improved from 0.17456 to 0.17424, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1502 - acc: 0.9508 - val_loss: 0.1742 - val_acc: 0.9431\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9493\n",
      "Epoch 00015: val_loss did not improve from 0.17424\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1491 - acc: 0.9493 - val_loss: 0.1748 - val_acc: 0.9426\n",
      "Epoch 16/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9513\n",
      "Epoch 00016: val_loss did not improve from 0.17424\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1471 - acc: 0.9512 - val_loss: 0.1743 - val_acc: 0.9426\n",
      "Epoch 17/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9520\n",
      "Epoch 00017: val_loss did not improve from 0.17424\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1465 - acc: 0.9521 - val_loss: 0.1743 - val_acc: 0.9426\n",
      "Epoch 18/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9517\n",
      "Epoch 00018: val_loss improved from 0.17424 to 0.17401, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1458 - acc: 0.9516 - val_loss: 0.1740 - val_acc: 0.9435\n",
      "Epoch 19/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9526\n",
      "Epoch 00019: val_loss did not improve from 0.17401\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1448 - acc: 0.9524 - val_loss: 0.1742 - val_acc: 0.9416\n",
      "Epoch 20/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9530\n",
      "Epoch 00020: val_loss improved from 0.17401 to 0.17383, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1457 - acc: 0.9529 - val_loss: 0.1738 - val_acc: 0.9440\n",
      "Epoch 21/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9519\n",
      "Epoch 00021: val_loss improved from 0.17383 to 0.17349, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1438 - acc: 0.9519 - val_loss: 0.1735 - val_acc: 0.9416\n",
      "Epoch 22/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9520\n",
      "Epoch 00022: val_loss did not improve from 0.17349\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1433 - acc: 0.9521 - val_loss: 0.1737 - val_acc: 0.9407\n",
      "Epoch 23/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9533\n",
      "Epoch 00023: val_loss did not improve from 0.17349\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1419 - acc: 0.9534 - val_loss: 0.1739 - val_acc: 0.9426\n",
      "Epoch 24/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9526\n",
      "Epoch 00024: val_loss did not improve from 0.17349\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1421 - acc: 0.9525 - val_loss: 0.1740 - val_acc: 0.9411\n",
      "Epoch 25/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9523\n",
      "Epoch 00025: val_loss did not improve from 0.17349\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1414 - acc: 0.9523 - val_loss: 0.1736 - val_acc: 0.9411\n",
      "Epoch 26/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9521\n",
      "Epoch 00026: val_loss did not improve from 0.17349\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1411 - acc: 0.9522 - val_loss: 0.1736 - val_acc: 0.9416\n",
      "auc0.8842202003492328, auprc0.5204778203517519, acc0.9388635818748502, F10.4539614561027837 \n",
      "0.8842202003492328 0.5204778203517519 0.9388635818748502 0.4539614561027837\n",
      "Iteration number:  6\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2941 - acc: 0.9035\n",
      "Epoch 00001: val_loss improved from inf to 0.25780, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 31ms/step - loss: 0.2938 - acc: 0.9036 - val_loss: 0.2578 - val_acc: 0.9105\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2513 - acc: 0.9135\n",
      "Epoch 00002: val_loss improved from 0.25780 to 0.24582, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2513 - acc: 0.9135 - val_loss: 0.2458 - val_acc: 0.9153\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2400 - acc: 0.9169\n",
      "Epoch 00003: val_loss improved from 0.24582 to 0.24337, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2398 - acc: 0.9170 - val_loss: 0.2434 - val_acc: 0.9182\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9196\n",
      "Epoch 00004: val_loss improved from 0.24337 to 0.24163, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2316 - acc: 0.9196 - val_loss: 0.2416 - val_acc: 0.9148\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2252 - acc: 0.9219\n",
      "Epoch 00005: val_loss improved from 0.24163 to 0.24049, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2248 - acc: 0.9221 - val_loss: 0.2405 - val_acc: 0.9153\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9207\n",
      "Epoch 00006: val_loss did not improve from 0.24049\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2220 - acc: 0.9208 - val_loss: 0.2407 - val_acc: 0.9158\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9210\n",
      "Epoch 00007: val_loss improved from 0.24049 to 0.24049, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2184 - acc: 0.9210 - val_loss: 0.2405 - val_acc: 0.9144\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9241\n",
      "Epoch 00008: val_loss improved from 0.24049 to 0.23980, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2166 - acc: 0.9240 - val_loss: 0.2398 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9233\n",
      "Epoch 00009: val_loss improved from 0.23980 to 0.23951, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2147 - acc: 0.9234 - val_loss: 0.2395 - val_acc: 0.9172\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9248- ETA: 1s - \n",
      "Epoch 00010: val_loss improved from 0.23951 to 0.23880, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2124 - acc: 0.9249 - val_loss: 0.2388 - val_acc: 0.9172\n",
      "Epoch 11/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2096 - acc: 0.9261\n",
      "Epoch 00011: val_loss improved from 0.23880 to 0.23874, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2096 - acc: 0.9261 - val_loss: 0.2387 - val_acc: 0.9167\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2082 - acc: 0.9262\n",
      "Epoch 00012: val_loss improved from 0.23874 to 0.23844, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2082 - acc: 0.9262 - val_loss: 0.2384 - val_acc: 0.9177\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9260\n",
      "Epoch 00013: val_loss did not improve from 0.23844\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2073 - acc: 0.9258 - val_loss: 0.2386 - val_acc: 0.9148\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2057 - acc: 0.9267\n",
      "Epoch 00014: val_loss did not improve from 0.23844\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2057 - acc: 0.9267 - val_loss: 0.2387 - val_acc: 0.9144\n",
      "Epoch 15/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2045 - acc: 0.9273\n",
      "Epoch 00015: val_loss did not improve from 0.23844\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2045 - acc: 0.9273 - val_loss: 0.2390 - val_acc: 0.9153\n",
      "Epoch 16/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2022 - acc: 0.9277\n",
      "Epoch 00016: val_loss did not improve from 0.23844\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2022 - acc: 0.9277 - val_loss: 0.2391 - val_acc: 0.9144\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2017 - acc: 0.9269\n",
      "Epoch 00017: val_loss did not improve from 0.23844\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2016 - acc: 0.9270 - val_loss: 0.2392 - val_acc: 0.9148\n",
      "auc0.879121992720194, auprc0.5776775912855625, acc0.9136897626468473, F10.47521865889212833 \n",
      "0.879121992720194 0.5776775912855625 0.9136897626468473 0.47521865889212833\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9353\n",
      "Epoch 00001: val_loss improved from inf to 0.18972, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 29ms/step - loss: 0.2219 - acc: 0.9354 - val_loss: 0.1897 - val_acc: 0.9397\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9418- \n",
      "Epoch 00002: val_loss improved from 0.18972 to 0.18257, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1849 - acc: 0.9418 - val_loss: 0.1826 - val_acc: 0.9421\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9447\n",
      "Epoch 00003: val_loss improved from 0.18257 to 0.18015, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1769 - acc: 0.9446 - val_loss: 0.1802 - val_acc: 0.9402\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9456\n",
      "Epoch 00004: val_loss improved from 0.18015 to 0.17885, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1688 - acc: 0.9456 - val_loss: 0.1789 - val_acc: 0.9416\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9465\n",
      "Epoch 00005: val_loss did not improve from 0.17885\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1651 - acc: 0.9466 - val_loss: 0.1791 - val_acc: 0.9411\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9476\n",
      "Epoch 00006: val_loss improved from 0.17885 to 0.17759, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1606 - acc: 0.9476 - val_loss: 0.1776 - val_acc: 0.9411\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9487\n",
      "Epoch 00007: val_loss improved from 0.17759 to 0.17744, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1570 - acc: 0.9487 - val_loss: 0.1774 - val_acc: 0.9407\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9490\n",
      "Epoch 00008: val_loss did not improve from 0.17744\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1552 - acc: 0.9490 - val_loss: 0.1778 - val_acc: 0.9411\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1539 - acc: 0.9494\n",
      "Epoch 00009: val_loss improved from 0.17744 to 0.17692, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.1539 - acc: 0.9494 - val_loss: 0.1769 - val_acc: 0.9407\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1524 - acc: 0.9497\n",
      "Epoch 00010: val_loss did not improve from 0.17692\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1524 - acc: 0.9497 - val_loss: 0.1769 - val_acc: 0.9392\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9494\n",
      "Epoch 00011: val_loss did not improve from 0.17692\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1493 - acc: 0.9495 - val_loss: 0.1769 - val_acc: 0.9392\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9515\n",
      "Epoch 00012: val_loss did not improve from 0.17692\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1481 - acc: 0.9515 - val_loss: 0.1772 - val_acc: 0.9407\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9524\n",
      "Epoch 00013: val_loss did not improve from 0.17692\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1467 - acc: 0.9524 - val_loss: 0.1775 - val_acc: 0.9411\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9525\n",
      "Epoch 00014: val_loss did not improve from 0.17692\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1455 - acc: 0.9525 - val_loss: 0.1775 - val_acc: 0.9402\n",
      "auc0.8850586092521576, auprc0.5200463402907501, acc0.9391033325341644, F10.4454148471615721 \n",
      "0.8850586092521576 0.5200463402907501 0.9391033325341644 0.4454148471615721\n",
      "Iteration number:  7\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.9022\n",
      "Epoch 00001: val_loss improved from inf to 0.25058, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 30ms/step - loss: 0.2982 - acc: 0.9020 - val_loss: 0.2506 - val_acc: 0.9172\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2482 - acc: 0.9156\n",
      "Epoch 00002: val_loss improved from 0.25058 to 0.24964, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2482 - acc: 0.9156 - val_loss: 0.2496 - val_acc: 0.9163\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.2384 - acc: 0.9170\n",
      "Epoch 00003: val_loss improved from 0.24964 to 0.24381, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2384 - acc: 0.9170 - val_loss: 0.2438 - val_acc: 0.9153\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2303 - acc: 0.9189\n",
      "Epoch 00004: val_loss improved from 0.24381 to 0.24378, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2303 - acc: 0.9189 - val_loss: 0.2438 - val_acc: 0.9163\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9203\n",
      "Epoch 00005: val_loss improved from 0.24378 to 0.24351, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2257 - acc: 0.9203 - val_loss: 0.2435 - val_acc: 0.9163\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9215\n",
      "Epoch 00006: val_loss improved from 0.24351 to 0.24277, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2215 - acc: 0.9214 - val_loss: 0.2428 - val_acc: 0.9167\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2176 - acc: 0.9217\n",
      "Epoch 00007: val_loss improved from 0.24277 to 0.24191, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2180 - acc: 0.9214 - val_loss: 0.2419 - val_acc: 0.9177\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2129 - acc: 0.9251\n",
      "Epoch 00008: val_loss did not improve from 0.24191\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2131 - acc: 0.9251 - val_loss: 0.2422 - val_acc: 0.9153\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9229\n",
      "Epoch 00009: val_loss improved from 0.24191 to 0.24164, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2135 - acc: 0.9230 - val_loss: 0.2416 - val_acc: 0.9172\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2099 - acc: 0.9249\n",
      "Epoch 00010: val_loss did not improve from 0.24164\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2099 - acc: 0.9249 - val_loss: 0.2419 - val_acc: 0.9187\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2088 - acc: 0.9262\n",
      "Epoch 00011: val_loss improved from 0.24164 to 0.24136, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2088 - acc: 0.9263 - val_loss: 0.2414 - val_acc: 0.9167\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9256\n",
      "Epoch 00012: val_loss did not improve from 0.24136\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2075 - acc: 0.9257 - val_loss: 0.2424 - val_acc: 0.9134\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9247\n",
      "Epoch 00013: val_loss improved from 0.24136 to 0.24132, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2061 - acc: 0.9247 - val_loss: 0.2413 - val_acc: 0.9158\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2042 - acc: 0.9266\n",
      "Epoch 00014: val_loss did not improve from 0.24132\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2042 - acc: 0.9266 - val_loss: 0.2415 - val_acc: 0.9134\n",
      "Epoch 15/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2023 - acc: 0.9272\n",
      "Epoch 00015: val_loss improved from 0.24132 to 0.24118, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2023 - acc: 0.9272 - val_loss: 0.2412 - val_acc: 0.9148\n",
      "Epoch 16/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2022 - acc: 0.9277\n",
      "Epoch 00016: val_loss improved from 0.24118 to 0.24091, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2022 - acc: 0.9277 - val_loss: 0.2409 - val_acc: 0.9139\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9274\n",
      "Epoch 00017: val_loss did not improve from 0.24091\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2011 - acc: 0.9274 - val_loss: 0.2417 - val_acc: 0.9139\n",
      "Epoch 18/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9283\n",
      "Epoch 00018: val_loss did not improve from 0.24091\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2002 - acc: 0.9283 - val_loss: 0.2419 - val_acc: 0.9153\n",
      "Epoch 19/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9276\n",
      "Epoch 00019: val_loss did not improve from 0.24091\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1999 - acc: 0.9278 - val_loss: 0.2426 - val_acc: 0.9129\n",
      "Epoch 20/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9285\n",
      "Epoch 00020: val_loss did not improve from 0.24091\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1976 - acc: 0.9285 - val_loss: 0.2420 - val_acc: 0.9129\n",
      "Epoch 21/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9300\n",
      "Epoch 00021: val_loss did not improve from 0.24091\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1972 - acc: 0.9299 - val_loss: 0.2415 - val_acc: 0.9139\n",
      "auc0.874932392543914, auprc0.5790226593292057, acc0.9136897626468473, F10.48275862068965525 \n",
      "0.874932392543914 0.5790226593292057 0.9136897626468473 0.48275862068965525\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9330\n",
      "Epoch 00001: val_loss improved from inf to 0.18569, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 28ms/step - loss: 0.2264 - acc: 0.9330 - val_loss: 0.1857 - val_acc: 0.9411\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9421\n",
      "Epoch 00002: val_loss improved from 0.18569 to 0.18205, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1842 - acc: 0.9422 - val_loss: 0.1820 - val_acc: 0.9388\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9438\n",
      "Epoch 00003: val_loss improved from 0.18205 to 0.18064, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1764 - acc: 0.9437 - val_loss: 0.1806 - val_acc: 0.9392\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9454\n",
      "Epoch 00004: val_loss improved from 0.18064 to 0.17871, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1699 - acc: 0.9454 - val_loss: 0.1787 - val_acc: 0.9426\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9463\n",
      "Epoch 00005: val_loss improved from 0.17871 to 0.17747, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1646 - acc: 0.9463 - val_loss: 0.1775 - val_acc: 0.9426\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9466- ETA: 1s\n",
      "Epoch 00006: val_loss did not improve from 0.17747\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1611 - acc: 0.9466 - val_loss: 0.1775 - val_acc: 0.9421\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1582 - acc: 0.9485- ETA: \n",
      "Epoch 00007: val_loss did not improve from 0.17747\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1586 - acc: 0.9483 - val_loss: 0.1775 - val_acc: 0.9421\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1553 - acc: 0.9477\n",
      "Epoch 00008: val_loss improved from 0.17747 to 0.17736, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1554 - acc: 0.9476 - val_loss: 0.1774 - val_acc: 0.9407\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9496\n",
      "Epoch 00009: val_loss improved from 0.17736 to 0.17731, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1543 - acc: 0.9497 - val_loss: 0.1773 - val_acc: 0.9411\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9490\n",
      "Epoch 00010: val_loss did not improve from 0.17731\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1531 - acc: 0.9490 - val_loss: 0.1778 - val_acc: 0.9397\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9502\n",
      "Epoch 00011: val_loss improved from 0.17731 to 0.17730, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1513 - acc: 0.9503 - val_loss: 0.1773 - val_acc: 0.9402\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9509\n",
      "Epoch 00012: val_loss did not improve from 0.17730\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1505 - acc: 0.9508 - val_loss: 0.1773 - val_acc: 0.9407\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9507\n",
      "Epoch 00013: val_loss did not improve from 0.17730\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1480 - acc: 0.9507 - val_loss: 0.1778 - val_acc: 0.9402\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9511\n",
      "Epoch 00014: val_loss did not improve from 0.17730\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1470 - acc: 0.9510 - val_loss: 0.1776 - val_acc: 0.9392\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9508\n",
      "Epoch 00015: val_loss did not improve from 0.17730\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1458 - acc: 0.9508 - val_loss: 0.1777 - val_acc: 0.9392\n",
      "Epoch 16/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1440 - acc: 0.9523\n",
      "Epoch 00016: val_loss did not improve from 0.17730\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1440 - acc: 0.9523 - val_loss: 0.1780 - val_acc: 0.9397\n",
      "auc0.8869196514357804, auprc0.5190283425129181, acc0.9415008391273076, F10.4672489082969432 \n",
      "0.8869196514357804 0.5190283425129181 0.9415008391273076 0.4672489082969432\n",
      "Iteration number:  8\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3047 - acc: 0.8966\n",
      "Epoch 00001: val_loss improved from inf to 0.24466, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 29ms/step - loss: 0.3046 - acc: 0.8966 - val_loss: 0.2447 - val_acc: 0.9163\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2512 - acc: 0.9123\n",
      "Epoch 00002: val_loss improved from 0.24466 to 0.24021, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2512 - acc: 0.9123 - val_loss: 0.2402 - val_acc: 0.9187\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9176\n",
      "Epoch 00003: val_loss improved from 0.24021 to 0.24018, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2393 - acc: 0.9177 - val_loss: 0.2402 - val_acc: 0.9129\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2317 - acc: 0.9186\n",
      "Epoch 00004: val_loss improved from 0.24018 to 0.23825, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2317 - acc: 0.9186 - val_loss: 0.2382 - val_acc: 0.9182\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9200\n",
      "Epoch 00005: val_loss improved from 0.23825 to 0.23787, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2266 - acc: 0.9200 - val_loss: 0.2379 - val_acc: 0.9153\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2222 - acc: 0.9213\n",
      "Epoch 00006: val_loss improved from 0.23787 to 0.23648, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.2223 - acc: 0.9213 - val_loss: 0.2365 - val_acc: 0.9148\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9217\n",
      "Epoch 00007: val_loss did not improve from 0.23648\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2191 - acc: 0.9217 - val_loss: 0.2379 - val_acc: 0.9158\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2170 - acc: 0.9234\n",
      "Epoch 00008: val_loss did not improve from 0.23648\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2170 - acc: 0.9234 - val_loss: 0.2386 - val_acc: 0.9153\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9229\n",
      "Epoch 00009: val_loss did not improve from 0.23648\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2148 - acc: 0.9229 - val_loss: 0.2391 - val_acc: 0.9139\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9237\n",
      "Epoch 00010: val_loss did not improve from 0.23648\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2125 - acc: 0.9238 - val_loss: 0.2370 - val_acc: 0.9158\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2104 - acc: 0.9244\n",
      "Epoch 00011: val_loss did not improve from 0.23648\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2104 - acc: 0.9244 - val_loss: 0.2382 - val_acc: 0.9134\n",
      "auc0.8770722642694447, auprc0.5758135202969684, acc0.9129705106689043, F10.4474885844748858 \n",
      "0.8770722642694447 0.5758135202969684 0.9129705106689043 0.4474885844748858\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9323\n",
      "Epoch 00001: val_loss improved from inf to 0.18687, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 28ms/step - loss: 0.2277 - acc: 0.9324 - val_loss: 0.1869 - val_acc: 0.9378\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1864 - acc: 0.9389- ETA: 0s - loss: 0.1861 -\n",
      "Epoch 00002: val_loss improved from 0.18687 to 0.17898, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1863 - acc: 0.9390 - val_loss: 0.1790 - val_acc: 0.9407\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9428\n",
      "Epoch 00003: val_loss improved from 0.17898 to 0.17621, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1755 - acc: 0.9429 - val_loss: 0.1762 - val_acc: 0.9426\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1676 - acc: 0.9450\n",
      "Epoch 00004: val_loss improved from 0.17621 to 0.17506, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1676 - acc: 0.9450 - val_loss: 0.1751 - val_acc: 0.9426\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1642 - acc: 0.9450\n",
      "Epoch 00005: val_loss improved from 0.17506 to 0.17408, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1642 - acc: 0.9450 - val_loss: 0.1741 - val_acc: 0.9431\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9464\n",
      "Epoch 00006: val_loss did not improve from 0.17408\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1608 - acc: 0.9464 - val_loss: 0.1756 - val_acc: 0.9383\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9474\n",
      "Epoch 00007: val_loss did not improve from 0.17408\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1592 - acc: 0.9474 - val_loss: 0.1741 - val_acc: 0.9411\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1555 - acc: 0.9482\n",
      "Epoch 00008: val_loss did not improve from 0.17408\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1555 - acc: 0.9482 - val_loss: 0.1744 - val_acc: 0.9421\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9492\n",
      "Epoch 00009: val_loss did not improve from 0.17408\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1544 - acc: 0.9490 - val_loss: 0.1746 - val_acc: 0.9407\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1519 - acc: 0.9495- ETA\n",
      "Epoch 00010: val_loss did not improve from 0.17408\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1519 - acc: 0.9495 - val_loss: 0.1749 - val_acc: 0.9411\n",
      "auc0.883208846112072, auprc0.5102328229470605, acc0.9386238312155358, F10.42342342342342343 \n",
      "0.883208846112072 0.5102328229470605 0.9386238312155358 0.42342342342342343\n",
      "Iteration number:  9\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2925 - acc: 0.9026\n",
      "Epoch 00001: val_loss improved from inf to 0.24822, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 30ms/step - loss: 0.2926 - acc: 0.9026 - val_loss: 0.2482 - val_acc: 0.9115\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2511 - acc: 0.9130\n",
      "Epoch 00002: val_loss improved from 0.24822 to 0.24198, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2515 - acc: 0.9127 - val_loss: 0.2420 - val_acc: 0.9167\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9161\n",
      "Epoch 00003: val_loss improved from 0.24198 to 0.24079, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2384 - acc: 0.9162 - val_loss: 0.2408 - val_acc: 0.9129\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9185\n",
      "Epoch 00004: val_loss improved from 0.24079 to 0.23902, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2305 - acc: 0.9186 - val_loss: 0.2390 - val_acc: 0.9163\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9206\n",
      "Epoch 00005: val_loss did not improve from 0.23902\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2249 - acc: 0.9206 - val_loss: 0.2414 - val_acc: 0.9134\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9218\n",
      "Epoch 00006: val_loss did not improve from 0.23902\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2220 - acc: 0.9218 - val_loss: 0.2392 - val_acc: 0.9129\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2170 - acc: 0.9229\n",
      "Epoch 00007: val_loss did not improve from 0.23902\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2171 - acc: 0.9229 - val_loss: 0.2398 - val_acc: 0.9120\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2164 - acc: 0.9224\n",
      "Epoch 00008: val_loss did not improve from 0.23902\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2161 - acc: 0.9227 - val_loss: 0.2392 - val_acc: 0.9120\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9242\n",
      "Epoch 00009: val_loss did not improve from 0.23902\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2127 - acc: 0.9242 - val_loss: 0.2399 - val_acc: 0.9105\n",
      "auc0.870789336934351, auprc0.5686139994976566, acc0.9129705106689043, F10.4458015267175573 \n",
      "0.870789336934351 0.5686139994976566 0.9129705106689043 0.4458015267175573\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2326 - acc: 0.9289\n",
      "Epoch 00001: val_loss improved from inf to 0.18492, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 30ms/step - loss: 0.2321 - acc: 0.9290 - val_loss: 0.1849 - val_acc: 0.9426\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1880 - acc: 0.9405\n",
      "Epoch 00002: val_loss improved from 0.18492 to 0.18012, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1880 - acc: 0.9405 - val_loss: 0.1801 - val_acc: 0.9426\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9427\n",
      "Epoch 00003: val_loss improved from 0.18012 to 0.17716, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1787 - acc: 0.9427 - val_loss: 0.1772 - val_acc: 0.9450\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9442\n",
      "Epoch 00004: val_loss improved from 0.17716 to 0.17620, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1739 - acc: 0.9439 - val_loss: 0.1762 - val_acc: 0.9440\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9450\n",
      "Epoch 00005: val_loss did not improve from 0.17620\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1679 - acc: 0.9453 - val_loss: 0.1772 - val_acc: 0.9450\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9469\n",
      "Epoch 00006: val_loss improved from 0.17620 to 0.17619, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1641 - acc: 0.9467 - val_loss: 0.1762 - val_acc: 0.9435\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1617 - acc: 0.9459\n",
      "Epoch 00007: val_loss did not improve from 0.17619\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1614 - acc: 0.9460 - val_loss: 0.1777 - val_acc: 0.9411\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9484\n",
      "Epoch 00008: val_loss did not improve from 0.17619\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1602 - acc: 0.9484 - val_loss: 0.1762 - val_acc: 0.9416\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9490\n",
      "Epoch 00009: val_loss did not improve from 0.17619\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1559 - acc: 0.9489 - val_loss: 0.1768 - val_acc: 0.9421\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1559 - acc: 0.9488\n",
      "Epoch 00010: val_loss did not improve from 0.17619\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1555 - acc: 0.9490 - val_loss: 0.1767 - val_acc: 0.9426\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9500- ETA: 1s - los\n",
      "Epoch 00011: val_loss improved from 0.17619 to 0.17587, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1540 - acc: 0.9499 - val_loss: 0.1759 - val_acc: 0.9431\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1533 - acc: 0.9491\n",
      "Epoch 00012: val_loss did not improve from 0.17587\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1533 - acc: 0.9491 - val_loss: 0.1759 - val_acc: 0.9426\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/230 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9501\n",
      "Epoch 00013: val_loss did not improve from 0.17587\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1507 - acc: 0.9500 - val_loss: 0.1762 - val_acc: 0.9416\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9505\n",
      "Epoch 00014: val_loss did not improve from 0.17587\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1502 - acc: 0.9505 - val_loss: 0.1763 - val_acc: 0.9407\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9506\n",
      "Epoch 00015: val_loss did not improve from 0.17587\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1482 - acc: 0.9506 - val_loss: 0.1764 - val_acc: 0.9411\n",
      "Epoch 16/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9523\n",
      "Epoch 00016: val_loss did not improve from 0.17587\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1465 - acc: 0.9521 - val_loss: 0.1761 - val_acc: 0.9407\n",
      "auc0.8831825283438186, auprc0.5164775687882609, acc0.940302085830736, F10.4478935698447894 \n",
      "0.8831825283438186 0.5164775687882609 0.940302085830736 0.4478935698447894\n",
      "Iteration number:  10\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.9024\n",
      "Epoch 00001: val_loss improved from inf to 0.24780, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 31ms/step - loss: 0.2958 - acc: 0.9024 - val_loss: 0.2478 - val_acc: 0.9110\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2515 - acc: 0.9119\n",
      "Epoch 00002: val_loss improved from 0.24780 to 0.24285, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2510 - acc: 0.9120 - val_loss: 0.2429 - val_acc: 0.9167\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9162\n",
      "Epoch 00003: val_loss improved from 0.24285 to 0.24146, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2372 - acc: 0.9161 - val_loss: 0.2415 - val_acc: 0.9153\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9189\n",
      "Epoch 00004: val_loss improved from 0.24146 to 0.23953, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2282 - acc: 0.9190 - val_loss: 0.2395 - val_acc: 0.9158\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9202\n",
      "Epoch 00005: val_loss improved from 0.23953 to 0.23886, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2247 - acc: 0.9202 - val_loss: 0.2389 - val_acc: 0.9129\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9217\n",
      "Epoch 00006: val_loss did not improve from 0.23886\n",
      "230/230 [==============================] - 7s 33ms/step - loss: 0.2198 - acc: 0.9218 - val_loss: 0.2389 - val_acc: 0.9148\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9224\n",
      "Epoch 00007: val_loss improved from 0.23886 to 0.23803, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2164 - acc: 0.9225 - val_loss: 0.2380 - val_acc: 0.9172\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9228\n",
      "Epoch 00008: val_loss improved from 0.23803 to 0.23770, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.2137 - acc: 0.9228 - val_loss: 0.2377 - val_acc: 0.9163\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2122 - acc: 0.9230\n",
      "Epoch 00009: val_loss improved from 0.23770 to 0.23754, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2122 - acc: 0.9230 - val_loss: 0.2375 - val_acc: 0.9163\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9235\n",
      "Epoch 00010: val_loss improved from 0.23754 to 0.23723, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2109 - acc: 0.9236 - val_loss: 0.2372 - val_acc: 0.9172\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9236\n",
      "Epoch 00011: val_loss did not improve from 0.23723\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2086 - acc: 0.9236 - val_loss: 0.2373 - val_acc: 0.9163\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9247\n",
      "Epoch 00012: val_loss improved from 0.23723 to 0.23686, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2081 - acc: 0.9246 - val_loss: 0.2369 - val_acc: 0.9163\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9264- ETA: 1s - l\n",
      "Epoch 00013: val_loss did not improve from 0.23686\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2061 - acc: 0.9264 - val_loss: 0.2373 - val_acc: 0.9172\n",
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9258\n",
      "Epoch 00014: val_loss did not improve from 0.23686\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2053 - acc: 0.9257 - val_loss: 0.2378 - val_acc: 0.9144\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9243- ETA: 0s - loss: 0.2051 \n",
      "Epoch 00015: val_loss did not improve from 0.23686\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2035 - acc: 0.9244 - val_loss: 0.2379 - val_acc: 0.9172\n",
      "Epoch 16/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9265\n",
      "Epoch 00016: val_loss did not improve from 0.23686\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2022 - acc: 0.9265 - val_loss: 0.2383 - val_acc: 0.9134\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2017 - acc: 0.9274\n",
      "Epoch 00017: val_loss did not improve from 0.23686\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2017 - acc: 0.9273 - val_loss: 0.2379 - val_acc: 0.9172\n",
      "auc0.8731666448673128, auprc0.5823027482764122, acc0.9132102613282187, F10.47687861271676296 \n",
      "0.8731666448673128 0.5823027482764122 0.9132102613282187 0.47687861271676296\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2237 - acc: 0.9333\n",
      "Epoch 00001: val_loss improved from inf to 0.18618, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 30ms/step - loss: 0.2243 - acc: 0.9332 - val_loss: 0.1862 - val_acc: 0.9440\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1863 - acc: 0.9411\n",
      "Epoch 00002: val_loss improved from 0.18618 to 0.18280, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1863 - acc: 0.9411 - val_loss: 0.1828 - val_acc: 0.9426\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9433\n",
      "Epoch 00003: val_loss improved from 0.18280 to 0.18210, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1773 - acc: 0.9433 - val_loss: 0.1821 - val_acc: 0.9440\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9459\n",
      "Epoch 00004: val_loss improved from 0.18210 to 0.17887, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1688 - acc: 0.9461 - val_loss: 0.1789 - val_acc: 0.9440\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/230 [============================>.] - ETA: 0s - loss: 0.1639 - acc: 0.9472\n",
      "Epoch 00005: val_loss did not improve from 0.17887\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1640 - acc: 0.9472 - val_loss: 0.1797 - val_acc: 0.9392\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9483\n",
      "Epoch 00006: val_loss improved from 0.17887 to 0.17712, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1602 - acc: 0.9483 - val_loss: 0.1771 - val_acc: 0.9421\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9487\n",
      "Epoch 00007: val_loss did not improve from 0.17712\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1570 - acc: 0.9487 - val_loss: 0.1774 - val_acc: 0.9426\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1555 - acc: 0.9489\n",
      "Epoch 00008: val_loss did not improve from 0.17712\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1555 - acc: 0.9489 - val_loss: 0.1773 - val_acc: 0.9411\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9506\n",
      "Epoch 00009: val_loss improved from 0.17712 to 0.17690, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1525 - acc: 0.9506 - val_loss: 0.1769 - val_acc: 0.9435\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9480- ETA\n",
      "Epoch 00010: val_loss improved from 0.17690 to 0.17677, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1526 - acc: 0.9481 - val_loss: 0.1768 - val_acc: 0.9421\n",
      "Epoch 11/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1505 - acc: 0.9504\n",
      "Epoch 00011: val_loss did not improve from 0.17677\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1505 - acc: 0.9504 - val_loss: 0.1770 - val_acc: 0.9426\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9514\n",
      "Epoch 00012: val_loss did not improve from 0.17677\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1484 - acc: 0.9514 - val_loss: 0.1770 - val_acc: 0.9426\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9499\n",
      "Epoch 00013: val_loss did not improve from 0.17677\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1474 - acc: 0.9499 - val_loss: 0.1773 - val_acc: 0.9407\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9508- ETA: 0s - loss: 0.1460 - acc:\n",
      "Epoch 00014: val_loss did not improve from 0.17677\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1475 - acc: 0.9508 - val_loss: 0.1773 - val_acc: 0.9397\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9516\n",
      "Epoch 00015: val_loss did not improve from 0.17677\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1447 - acc: 0.9516 - val_loss: 0.1772 - val_acc: 0.9402\n",
      "auc0.8822760274373178, auprc0.50917862992832, acc0.9395828338527931, F10.4545454545454545 \n",
      "0.8822760274373178 0.50917862992832 0.9395828338527931 0.4545454545454545\n",
      "Embedding:  fasttext\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.8933\n",
      "Epoch 00001: val_loss improved from inf to 0.25351, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 10s 33ms/step - loss: 0.3164 - acc: 0.8933 - val_loss: 0.2535 - val_acc: 0.9144\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2551 - acc: 0.9110- ETA: 0s - loss: 0.2571 - ac\n",
      "Epoch 00002: val_loss improved from 0.25351 to 0.24797, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.2553 - acc: 0.9109 - val_loss: 0.2480 - val_acc: 0.9139\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2428 - acc: 0.9166\n",
      "Epoch 00003: val_loss improved from 0.24797 to 0.24366, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2428 - acc: 0.9165 - val_loss: 0.2437 - val_acc: 0.9134\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.9193\n",
      "Epoch 00004: val_loss improved from 0.24366 to 0.24318, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2333 - acc: 0.9193 - val_loss: 0.2432 - val_acc: 0.9134\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9205\n",
      "Epoch 00005: val_loss did not improve from 0.24318\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2295 - acc: 0.9206 - val_loss: 0.2432 - val_acc: 0.9158\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9213\n",
      "Epoch 00006: val_loss improved from 0.24318 to 0.24192, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2244 - acc: 0.9214 - val_loss: 0.2419 - val_acc: 0.9144\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2202 - acc: 0.9223-\n",
      "Epoch 00007: val_loss did not improve from 0.24192\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2202 - acc: 0.9223 - val_loss: 0.2426 - val_acc: 0.9134\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9235\n",
      "Epoch 00008: val_loss improved from 0.24192 to 0.24107, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2174 - acc: 0.9236 - val_loss: 0.2411 - val_acc: 0.9144\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2162 - acc: 0.9247\n",
      "Epoch 00009: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2161 - acc: 0.9248 - val_loss: 0.2414 - val_acc: 0.9153\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9224- ETA: 0s - loss: 0.2136\n",
      "Epoch 00010: val_loss improved from 0.24107 to 0.24043, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2140 - acc: 0.9225 - val_loss: 0.2404 - val_acc: 0.9153\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9241\n",
      "Epoch 00011: val_loss did not improve from 0.24043\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2112 - acc: 0.9241 - val_loss: 0.2408 - val_acc: 0.9139\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9253- ETA: 1s - l\n",
      "Epoch 00012: val_loss did not improve from 0.24043\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2108 - acc: 0.9253 - val_loss: 0.2412 - val_acc: 0.9148\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9263\n",
      "Epoch 00013: val_loss did not improve from 0.24043\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2091 - acc: 0.9263 - val_loss: 0.2408 - val_acc: 0.9153\n",
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9278\n",
      "Epoch 00014: val_loss did not improve from 0.24043\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2063 - acc: 0.9279 - val_loss: 0.2405 - val_acc: 0.9158\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9271\n",
      "Epoch 00015: val_loss did not improve from 0.24043\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2066 - acc: 0.9271 - val_loss: 0.2410 - val_acc: 0.9144\n",
      "auc0.8788583383707516, auprc0.5794934281694756, acc0.9124910093502757, F10.4717800289435601 \n",
      "0.8788583383707516 0.5794934281694756 0.9124910093502757 0.4717800289435601\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9340- ETA: 0s - loss: 0.2205 \n",
      "Epoch 00001: val_loss improved from inf to 0.18539, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 31ms/step - loss: 0.2207 - acc: 0.9339 - val_loss: 0.1854 - val_acc: 0.9411\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9415\n",
      "Epoch 00002: val_loss improved from 0.18539 to 0.17859, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1845 - acc: 0.9415 - val_loss: 0.1786 - val_acc: 0.9431\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9437\n",
      "Epoch 00003: val_loss improved from 0.17859 to 0.17684, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.1731 - acc: 0.9437 - val_loss: 0.1768 - val_acc: 0.9450\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9448\n",
      "Epoch 00004: val_loss improved from 0.17684 to 0.17587, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1676 - acc: 0.9447 - val_loss: 0.1759 - val_acc: 0.9445\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9463\n",
      "Epoch 00005: val_loss did not improve from 0.17587\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1621 - acc: 0.9463 - val_loss: 0.1759 - val_acc: 0.9431\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1582 - acc: 0.9477- ETA: 1s - loss: 0\n",
      "Epoch 00006: val_loss improved from 0.17587 to 0.17498, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.1581 - acc: 0.9477 - val_loss: 0.1750 - val_acc: 0.9435\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9486- ETA: 1s - loss: 0.\n",
      "Epoch 00007: val_loss did not improve from 0.17498\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.1546 - acc: 0.9486 - val_loss: 0.1750 - val_acc: 0.9431\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9487\n",
      "Epoch 00008: val_loss improved from 0.17498 to 0.17481, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1526 - acc: 0.9487 - val_loss: 0.1748 - val_acc: 0.9426\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9498\n",
      "Epoch 00009: val_loss improved from 0.17481 to 0.17457, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1516 - acc: 0.9496 - val_loss: 0.1746 - val_acc: 0.9421\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9495\n",
      "Epoch 00010: val_loss did not improve from 0.17457\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1499 - acc: 0.9493 - val_loss: 0.1749 - val_acc: 0.9421\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9495\n",
      "Epoch 00011: val_loss did not improve from 0.17457\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1484 - acc: 0.9495 - val_loss: 0.1746 - val_acc: 0.9421\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9509\n",
      "Epoch 00012: val_loss did not improve from 0.17457\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1467 - acc: 0.9509 - val_loss: 0.1748 - val_acc: 0.9426\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9502\n",
      "Epoch 00013: val_loss did not improve from 0.17457\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1457 - acc: 0.9504 - val_loss: 0.1747 - val_acc: 0.9431\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9509\n",
      "Epoch 00014: val_loss did not improve from 0.17457\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1439 - acc: 0.9509 - val_loss: 0.1753 - val_acc: 0.9411\n",
      "auc0.8884268658462205, auprc0.516579460553444, acc0.9393430831934788, F10.44880174291939 \n",
      "0.8884268658462205 0.516579460553444 0.9393430831934788 0.44880174291939\n",
      "Iteration number:  2\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2998 - acc: 0.8982\n",
      "Epoch 00001: val_loss improved from inf to 0.24810, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 32ms/step - loss: 0.2992 - acc: 0.8985 - val_loss: 0.2481 - val_acc: 0.9148\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2550 - acc: 0.9106\n",
      "Epoch 00002: val_loss improved from 0.24810 to 0.24517, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2548 - acc: 0.9108 - val_loss: 0.2452 - val_acc: 0.9153\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2432 - acc: 0.9149\n",
      "Epoch 00003: val_loss improved from 0.24517 to 0.24303, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2431 - acc: 0.9150 - val_loss: 0.2430 - val_acc: 0.9163\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9174\n",
      "Epoch 00004: val_loss improved from 0.24303 to 0.24286, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2325 - acc: 0.9176 - val_loss: 0.2429 - val_acc: 0.9139\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2274 - acc: 0.9182\n",
      "Epoch 00005: val_loss did not improve from 0.24286\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2274 - acc: 0.9184 - val_loss: 0.2430 - val_acc: 0.9158\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2238 - acc: 0.9201\n",
      "Epoch 00006: val_loss improved from 0.24286 to 0.24252, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2247 - acc: 0.9197 - val_loss: 0.2425 - val_acc: 0.9139\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9222- ETA: 1s - los\n",
      "Epoch 00007: val_loss did not improve from 0.24252\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2208 - acc: 0.9223 - val_loss: 0.2427 - val_acc: 0.9158\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9219\n",
      "Epoch 00008: val_loss improved from 0.24252 to 0.24217, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2163 - acc: 0.9219 - val_loss: 0.2422 - val_acc: 0.9177\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9229\n",
      "Epoch 00009: val_loss did not improve from 0.24217\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2160 - acc: 0.9229 - val_loss: 0.2425 - val_acc: 0.9163\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9240\n",
      "Epoch 00010: val_loss did not improve from 0.24217\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2132 - acc: 0.9241 - val_loss: 0.2423 - val_acc: 0.9163\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9251\n",
      "Epoch 00011: val_loss did not improve from 0.24217\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2109 - acc: 0.9250 - val_loss: 0.2427 - val_acc: 0.9167\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2096 - acc: 0.9258\n",
      "Epoch 00012: val_loss did not improve from 0.24217\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2095 - acc: 0.9259 - val_loss: 0.2426 - val_acc: 0.9182\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.2072 - acc: 0.9279- ETA: 1s - los\n",
      "Epoch 00013: val_loss improved from 0.24217 to 0.24198, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 8s 35ms/step - loss: 0.2073 - acc: 0.9279 - val_loss: 0.2420 - val_acc: 0.9158\n",
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9270\n",
      "Epoch 00014: val_loss did not improve from 0.24198\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.2061 - acc: 0.9268 - val_loss: 0.2429 - val_acc: 0.9163\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9279\n",
      "Epoch 00015: val_loss did not improve from 0.24198\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2047 - acc: 0.9279 - val_loss: 0.2434 - val_acc: 0.9158\n",
      "Epoch 16/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9279\n",
      "Epoch 00016: val_loss did not improve from 0.24198\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2035 - acc: 0.9279 - val_loss: 0.2429 - val_acc: 0.9163\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9268\n",
      "Epoch 00017: val_loss did not improve from 0.24198\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2039 - acc: 0.9268 - val_loss: 0.2431 - val_acc: 0.9148\n",
      "Epoch 18/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9277\n",
      "Epoch 00018: val_loss did not improve from 0.24198\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2011 - acc: 0.9277 - val_loss: 0.2434 - val_acc: 0.9158\n",
      "auc0.877821690710765, auprc0.5789395106516068, acc0.9151282666027332, F10.48843930635838156 \n",
      "0.877821690710765 0.5789395106516068 0.9151282666027332 0.48843930635838156\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2327 - acc: 0.9311\n",
      "Epoch 00001: val_loss improved from inf to 0.18200, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 28ms/step - loss: 0.2327 - acc: 0.9311 - val_loss: 0.1820 - val_acc: 0.9421\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9400\n",
      "Epoch 00002: val_loss did not improve from 0.18200\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1853 - acc: 0.9399 - val_loss: 0.1856 - val_acc: 0.9411\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9425\n",
      "Epoch 00003: val_loss improved from 0.18200 to 0.17936, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1761 - acc: 0.9425 - val_loss: 0.1794 - val_acc: 0.9416\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9460\n",
      "Epoch 00004: val_loss improved from 0.17936 to 0.17710, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1675 - acc: 0.9460 - val_loss: 0.1771 - val_acc: 0.9402\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9456\n",
      "Epoch 00005: val_loss improved from 0.17710 to 0.17629, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1645 - acc: 0.9457 - val_loss: 0.1763 - val_acc: 0.9402\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9480\n",
      "Epoch 00006: val_loss improved from 0.17629 to 0.17590, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1612 - acc: 0.9479 - val_loss: 0.1759 - val_acc: 0.9397\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9476\n",
      "Epoch 00007: val_loss improved from 0.17590 to 0.17572, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1586 - acc: 0.9476 - val_loss: 0.1757 - val_acc: 0.9402\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9483\n",
      "Epoch 00008: val_loss improved from 0.17572 to 0.17499, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1566 - acc: 0.9484 - val_loss: 0.1750 - val_acc: 0.9416\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9494\n",
      "Epoch 00009: val_loss did not improve from 0.17499\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1535 - acc: 0.9494 - val_loss: 0.1754 - val_acc: 0.9421\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9489\n",
      "Epoch 00010: val_loss did not improve from 0.17499\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1529 - acc: 0.9489 - val_loss: 0.1755 - val_acc: 0.9411\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9503\n",
      "Epoch 00011: val_loss did not improve from 0.17499\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1511 - acc: 0.9503 - val_loss: 0.1753 - val_acc: 0.9416\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9503\n",
      "Epoch 00012: val_loss did not improve from 0.17499\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1497 - acc: 0.9504 - val_loss: 0.1753 - val_acc: 0.9402\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9500\n",
      "Epoch 00013: val_loss did not improve from 0.17499\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1490 - acc: 0.9500 - val_loss: 0.1751 - val_acc: 0.9411\n",
      "auc0.8857867341738309, auprc0.516272115458813, acc0.9391033325341644, F10.4253393665158371 \n",
      "0.8857867341738309 0.516272115458813 0.9391033325341644 0.4253393665158371\n",
      "Iteration number:  3\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2999 - acc: 0.8981\n",
      "Epoch 00001: val_loss improved from inf to 0.24977, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 8s 29ms/step - loss: 0.3000 - acc: 0.8980 - val_loss: 0.2498 - val_acc: 0.9100\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2537 - acc: 0.9108\n",
      "Epoch 00002: val_loss improved from 0.24977 to 0.24244, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2537 - acc: 0.9108 - val_loss: 0.2424 - val_acc: 0.9139\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2432 - acc: 0.9146\n",
      "Epoch 00003: val_loss improved from 0.24244 to 0.24170, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2432 - acc: 0.9146 - val_loss: 0.2417 - val_acc: 0.9153\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9168\n",
      "Epoch 00004: val_loss improved from 0.24170 to 0.24008, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2328 - acc: 0.9168 - val_loss: 0.2401 - val_acc: 0.9167\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2278 - acc: 0.9173\n",
      "Epoch 00005: val_loss did not improve from 0.24008\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2278 - acc: 0.9173 - val_loss: 0.2409 - val_acc: 0.9134\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2226 - acc: 0.9202\n",
      "Epoch 00006: val_loss improved from 0.24008 to 0.23975, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2226 - acc: 0.9202 - val_loss: 0.2398 - val_acc: 0.9134\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9231\n",
      "Epoch 00007: val_loss did not improve from 0.23975\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2192 - acc: 0.9231 - val_loss: 0.2414 - val_acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9221\n",
      "Epoch 00008: val_loss did not improve from 0.23975\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2173 - acc: 0.9221 - val_loss: 0.2402 - val_acc: 0.9144\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9233\n",
      "Epoch 00009: val_loss did not improve from 0.23975\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2148 - acc: 0.9234 - val_loss: 0.2406 - val_acc: 0.9105\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9243\n",
      "Epoch 00010: val_loss did not improve from 0.23975\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2120 - acc: 0.9243 - val_loss: 0.2410 - val_acc: 0.9115\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2104 - acc: 0.9246\n",
      "Epoch 00011: val_loss improved from 0.23975 to 0.23951, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2106 - acc: 0.9246 - val_loss: 0.2395 - val_acc: 0.9134\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2083 - acc: 0.9249\n",
      "Epoch 00012: val_loss did not improve from 0.23951\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2085 - acc: 0.9248 - val_loss: 0.2401 - val_acc: 0.9124\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9258\n",
      "Epoch 00013: val_loss did not improve from 0.23951\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2064 - acc: 0.9258 - val_loss: 0.2404 - val_acc: 0.9124\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9280\n",
      "Epoch 00014: val_loss did not improve from 0.23951\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2062 - acc: 0.9280 - val_loss: 0.2404 - val_acc: 0.9124\n",
      "Epoch 15/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2049 - acc: 0.9261\n",
      "Epoch 00015: val_loss did not improve from 0.23951\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2047 - acc: 0.9261 - val_loss: 0.2404 - val_acc: 0.9144\n",
      "Epoch 16/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2030 - acc: 0.9278\n",
      "Epoch 00016: val_loss did not improve from 0.23951\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2030 - acc: 0.9278 - val_loss: 0.2409 - val_acc: 0.9129\n",
      "auc0.881951195370524, auprc0.5888313535300452, acc0.9144090146247902, F10.4788321167883212 \n",
      "0.881951195370524 0.5888313535300452 0.9144090146247902 0.4788321167883212\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2415 - acc: 0.9274\n",
      "Epoch 00001: val_loss improved from inf to 0.18358, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 28ms/step - loss: 0.2410 - acc: 0.9277 - val_loss: 0.1836 - val_acc: 0.9411\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9384- ETA: \n",
      "Epoch 00002: val_loss improved from 0.18358 to 0.18082, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1897 - acc: 0.9383 - val_loss: 0.1808 - val_acc: 0.9407\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9429\n",
      "Epoch 00003: val_loss improved from 0.18082 to 0.17783, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1783 - acc: 0.9429 - val_loss: 0.1778 - val_acc: 0.9416\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9448\n",
      "Epoch 00004: val_loss did not improve from 0.17783\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1714 - acc: 0.9446 - val_loss: 0.1786 - val_acc: 0.9416\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9452\n",
      "Epoch 00005: val_loss improved from 0.17783 to 0.17580, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1671 - acc: 0.9452 - val_loss: 0.1758 - val_acc: 0.9421\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9465\n",
      "Epoch 00006: val_loss improved from 0.17580 to 0.17552, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.1629 - acc: 0.9465 - val_loss: 0.1755 - val_acc: 0.9440\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9473\n",
      "Epoch 00007: val_loss did not improve from 0.17552\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1604 - acc: 0.9472 - val_loss: 0.1759 - val_acc: 0.9435\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9483\n",
      "Epoch 00008: val_loss did not improve from 0.17552\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1582 - acc: 0.9482 - val_loss: 0.1777 - val_acc: 0.9426\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9484\n",
      "Epoch 00009: val_loss did not improve from 0.17552\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1558 - acc: 0.9483 - val_loss: 0.1755 - val_acc: 0.9440\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9488\n",
      "Epoch 00010: val_loss did not improve from 0.17552\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1548 - acc: 0.9487 - val_loss: 0.1757 - val_acc: 0.9440\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9505\n",
      "Epoch 00011: val_loss did not improve from 0.17552\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1528 - acc: 0.9506 - val_loss: 0.1757 - val_acc: 0.9440\n",
      "auc0.8870324418711516, auprc0.5119549251401174, acc0.9374250779189642, F10.41083521444695253 \n",
      "0.8870324418711516 0.5119549251401174 0.9374250779189642 0.41083521444695253\n",
      "Iteration number:  4\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2948 - acc: 0.8982\n",
      "Epoch 00001: val_loss improved from inf to 0.24936, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 8s 28ms/step - loss: 0.2941 - acc: 0.8983 - val_loss: 0.2494 - val_acc: 0.9139\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2520 - acc: 0.9110\n",
      "Epoch 00002: val_loss improved from 0.24936 to 0.24188, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2521 - acc: 0.9109 - val_loss: 0.2419 - val_acc: 0.9124\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2389 - acc: 0.9159\n",
      "Epoch 00003: val_loss improved from 0.24188 to 0.23950, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2388 - acc: 0.9160 - val_loss: 0.2395 - val_acc: 0.9134\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2313 - acc: 0.9178- ETA: 1s - loss: 0.234 - ETA: 0s - loss: 0.22\n",
      "Epoch 00004: val_loss did not improve from 0.23950\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2312 - acc: 0.9179 - val_loss: 0.2400 - val_acc: 0.9134\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9191- ETA: 0s - loss: 0.2239 -\n",
      "Epoch 00005: val_loss improved from 0.23950 to 0.23889, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2253 - acc: 0.9193 - val_loss: 0.2389 - val_acc: 0.9129\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9214- ETA: 2s - loss: 0.2234 -  - ETA: 1s\n",
      "Epoch 00006: val_loss improved from 0.23889 to 0.23696, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2209 - acc: 0.9213 - val_loss: 0.2370 - val_acc: 0.9163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2195 - acc: 0.9220\n",
      "Epoch 00007: val_loss improved from 0.23696 to 0.23694, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2195 - acc: 0.9220 - val_loss: 0.2369 - val_acc: 0.9148\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2150 - acc: 0.9225- ETA: 1s - loss: 0\n",
      "Epoch 00008: val_loss did not improve from 0.23694\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2150 - acc: 0.9225 - val_loss: 0.2374 - val_acc: 0.9134\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9243\n",
      "Epoch 00009: val_loss did not improve from 0.23694\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2116 - acc: 0.9244 - val_loss: 0.2375 - val_acc: 0.9153\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9246\n",
      "Epoch 00010: val_loss improved from 0.23694 to 0.23692, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2107 - acc: 0.9244 - val_loss: 0.2369 - val_acc: 0.9153\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2075 - acc: 0.9264\n",
      "Epoch 00011: val_loss improved from 0.23692 to 0.23668, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2075 - acc: 0.9264 - val_loss: 0.2367 - val_acc: 0.9158\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9263\n",
      "Epoch 00012: val_loss improved from 0.23668 to 0.23647, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2081 - acc: 0.9262 - val_loss: 0.2365 - val_acc: 0.9148\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2058 - acc: 0.9260\n",
      "Epoch 00013: val_loss did not improve from 0.23647\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2058 - acc: 0.9260 - val_loss: 0.2368 - val_acc: 0.9153\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9275\n",
      "Epoch 00014: val_loss did not improve from 0.23647\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2037 - acc: 0.9274 - val_loss: 0.2375 - val_acc: 0.9124\n",
      "Epoch 15/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9265- ETA: 0s - loss: 0.2032 - acc: \n",
      "Epoch 00015: val_loss did not improve from 0.23647\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2038 - acc: 0.9266 - val_loss: 0.2369 - val_acc: 0.9139\n",
      "Epoch 16/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9277\n",
      "Epoch 00016: val_loss did not improve from 0.23647\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2022 - acc: 0.9276 - val_loss: 0.2376 - val_acc: 0.9134\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9282\n",
      "Epoch 00017: val_loss did not improve from 0.23647\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2006 - acc: 0.9282 - val_loss: 0.2371 - val_acc: 0.9139\n",
      "auc0.8815726525336153, auprc0.5824616365479169, acc0.9120115080316471, F10.4562962962962963 \n",
      "0.8815726525336153 0.5824616365479169 0.9120115080316471 0.4562962962962963\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2347 - acc: 0.9285\n",
      "Epoch 00001: val_loss improved from inf to 0.18387, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 30ms/step - loss: 0.2345 - acc: 0.9285 - val_loss: 0.1839 - val_acc: 0.9421\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1870 - acc: 0.9411- ETA: 0s - loss: 0.1864 - a\n",
      "Epoch 00002: val_loss improved from 0.18387 to 0.17970, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1872 - acc: 0.9410 - val_loss: 0.1797 - val_acc: 0.9431\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9422\n",
      "Epoch 00003: val_loss improved from 0.17970 to 0.17573, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1773 - acc: 0.9422 - val_loss: 0.1757 - val_acc: 0.9464\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9442\n",
      "Epoch 00004: val_loss did not improve from 0.17573\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1704 - acc: 0.9442 - val_loss: 0.1767 - val_acc: 0.9411\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9457\n",
      "Epoch 00005: val_loss improved from 0.17573 to 0.17398, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1644 - acc: 0.9457 - val_loss: 0.1740 - val_acc: 0.9411\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1621 - acc: 0.9468\n",
      "Epoch 00006: val_loss improved from 0.17398 to 0.17377, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1621 - acc: 0.9469 - val_loss: 0.1738 - val_acc: 0.9397\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9475\n",
      "Epoch 00007: val_loss improved from 0.17377 to 0.17368, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1576 - acc: 0.9475 - val_loss: 0.1737 - val_acc: 0.9402\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1553 - acc: 0.9481\n",
      "Epoch 00008: val_loss did not improve from 0.17368\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1551 - acc: 0.9480 - val_loss: 0.1743 - val_acc: 0.9402\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9488\n",
      "Epoch 00009: val_loss improved from 0.17368 to 0.17333, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1529 - acc: 0.9488 - val_loss: 0.1733 - val_acc: 0.9416\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1505 - acc: 0.9502\n",
      "Epoch 00010: val_loss did not improve from 0.17333\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1505 - acc: 0.9502 - val_loss: 0.1735 - val_acc: 0.9402\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9484\n",
      "Epoch 00011: val_loss did not improve from 0.17333\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1500 - acc: 0.9484 - val_loss: 0.1739 - val_acc: 0.9421\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9494\n",
      "Epoch 00012: val_loss did not improve from 0.17333\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1486 - acc: 0.9495 - val_loss: 0.1733 - val_acc: 0.9416\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9487\n",
      "Epoch 00013: val_loss did not improve from 0.17333\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1483 - acc: 0.9489 - val_loss: 0.1733 - val_acc: 0.9402\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1460 - acc: 0.9497\n",
      "Epoch 00014: val_loss did not improve from 0.17333\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1460 - acc: 0.9497 - val_loss: 0.1738 - val_acc: 0.9402\n",
      "auc0.8880993558412913, auprc0.521631357833903, acc0.9395828338527931, F10.4449339207048459 \n",
      "0.8880993558412913 0.521631357833903 0.9395828338527931 0.4449339207048459\n",
      "Iteration number:  5\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2967 - acc: 0.8997\n",
      "Epoch 00001: val_loss improved from inf to 0.25111, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 32ms/step - loss: 0.2966 - acc: 0.8998 - val_loss: 0.2511 - val_acc: 0.9144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2498 - acc: 0.9132\n",
      "Epoch 00002: val_loss improved from 0.25111 to 0.24662, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2496 - acc: 0.9134 - val_loss: 0.2466 - val_acc: 0.9153\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9164\n",
      "Epoch 00003: val_loss improved from 0.24662 to 0.24560, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2384 - acc: 0.9164 - val_loss: 0.2456 - val_acc: 0.9129\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2313 - acc: 0.9185\n",
      "Epoch 00004: val_loss improved from 0.24560 to 0.24377, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2315 - acc: 0.9185 - val_loss: 0.2438 - val_acc: 0.9163\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9210\n",
      "Epoch 00005: val_loss did not improve from 0.24377\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2248 - acc: 0.9210 - val_loss: 0.2443 - val_acc: 0.9148\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9214\n",
      "Epoch 00006: val_loss did not improve from 0.24377\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2198 - acc: 0.9213 - val_loss: 0.2447 - val_acc: 0.9134\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9226\n",
      "Epoch 00007: val_loss did not improve from 0.24377\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2184 - acc: 0.9226 - val_loss: 0.2451 - val_acc: 0.9124\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2142 - acc: 0.9235\n",
      "Epoch 00008: val_loss improved from 0.24377 to 0.24326, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2141 - acc: 0.9236 - val_loss: 0.2433 - val_acc: 0.9153\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9236\n",
      "Epoch 00009: val_loss did not improve from 0.24326\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2131 - acc: 0.9237 - val_loss: 0.2440 - val_acc: 0.9134\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9237\n",
      "Epoch 00010: val_loss improved from 0.24326 to 0.24308, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2106 - acc: 0.9238 - val_loss: 0.2431 - val_acc: 0.9153\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9256\n",
      "Epoch 00011: val_loss did not improve from 0.24308\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2107 - acc: 0.9255 - val_loss: 0.2434 - val_acc: 0.9124\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9254\n",
      "Epoch 00012: val_loss did not improve from 0.24308\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2087 - acc: 0.9253 - val_loss: 0.2445 - val_acc: 0.9148\n",
      "Epoch 13/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2063 - acc: 0.9260\n",
      "Epoch 00013: val_loss did not improve from 0.24308\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2063 - acc: 0.9260 - val_loss: 0.2444 - val_acc: 0.9139\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9269\n",
      "Epoch 00014: val_loss did not improve from 0.24308\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2051 - acc: 0.9269 - val_loss: 0.2440 - val_acc: 0.9139\n",
      "Epoch 15/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9261\n",
      "Epoch 00015: val_loss did not improve from 0.24308\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.2046 - acc: 0.9259 - val_loss: 0.2441 - val_acc: 0.9134\n",
      "auc0.8778941588336284, auprc0.5839428645448527, acc0.9136897626468473, F10.4642857142857143 \n",
      "0.8778941588336284 0.5839428645448527 0.9136897626468473 0.4642857142857143\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2411 - acc: 0.9280\n",
      "Epoch 00001: val_loss improved from inf to 0.18991, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 10s 31ms/step - loss: 0.2410 - acc: 0.9280 - val_loss: 0.1899 - val_acc: 0.9440\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9410\n",
      "Epoch 00002: val_loss improved from 0.18991 to 0.18110, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1905 - acc: 0.9410 - val_loss: 0.1811 - val_acc: 0.9411\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9436\n",
      "Epoch 00003: val_loss improved from 0.18110 to 0.17914, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1781 - acc: 0.9435 - val_loss: 0.1791 - val_acc: 0.9426\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9451- ETA: 1s - lo\n",
      "Epoch 00004: val_loss improved from 0.17914 to 0.17795, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1711 - acc: 0.9451 - val_loss: 0.1779 - val_acc: 0.9421\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1670 - acc: 0.9460\n",
      "Epoch 00005: val_loss improved from 0.17795 to 0.17695, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1673 - acc: 0.9459 - val_loss: 0.1770 - val_acc: 0.9445\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9461- ETA: 0s - loss: 0.1623 - a\n",
      "Epoch 00006: val_loss did not improve from 0.17695\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1627 - acc: 0.9462 - val_loss: 0.1770 - val_acc: 0.9421\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1608 - acc: 0.9477\n",
      "Epoch 00007: val_loss improved from 0.17695 to 0.17619, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1608 - acc: 0.9477 - val_loss: 0.1762 - val_acc: 0.9421\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9485\n",
      "Epoch 00008: val_loss did not improve from 0.17619\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1575 - acc: 0.9485 - val_loss: 0.1763 - val_acc: 0.9426\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9479\n",
      "Epoch 00009: val_loss did not improve from 0.17619\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1563 - acc: 0.9479 - val_loss: 0.1763 - val_acc: 0.9407\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9496\n",
      "Epoch 00010: val_loss improved from 0.17619 to 0.17586, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1532 - acc: 0.9495 - val_loss: 0.1759 - val_acc: 0.9416\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9498\n",
      "Epoch 00011: val_loss did not improve from 0.17586\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1530 - acc: 0.9497 - val_loss: 0.1765 - val_acc: 0.9402\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9506\n",
      "Epoch 00012: val_loss did not improve from 0.17586\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1500 - acc: 0.9508 - val_loss: 0.1762 - val_acc: 0.9402\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9507\n",
      "Epoch 00013: val_loss improved from 0.17586 to 0.17582, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1496 - acc: 0.9507 - val_loss: 0.1758 - val_acc: 0.9407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9506\n",
      "Epoch 00014: val_loss did not improve from 0.17582\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1477 - acc: 0.9508 - val_loss: 0.1759 - val_acc: 0.9407\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9508- ETA: 1s - loss\n",
      "Epoch 00015: val_loss improved from 0.17582 to 0.17582, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1473 - acc: 0.9508 - val_loss: 0.1758 - val_acc: 0.9397\n",
      "Epoch 16/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9515\n",
      "Epoch 00016: val_loss did not improve from 0.17582\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1451 - acc: 0.9514 - val_loss: 0.1761 - val_acc: 0.9397\n",
      "Epoch 17/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9527\n",
      "Epoch 00017: val_loss did not improve from 0.17582\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1447 - acc: 0.9526 - val_loss: 0.1762 - val_acc: 0.9397\n",
      "Epoch 18/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9504- ETA: 0s - loss: 0.1449 - acc: 0\n",
      "Epoch 00018: val_loss did not improve from 0.17582\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1440 - acc: 0.9504 - val_loss: 0.1759 - val_acc: 0.9397\n",
      "Epoch 19/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9506\n",
      "Epoch 00019: val_loss did not improve from 0.17582\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1439 - acc: 0.9506 - val_loss: 0.1758 - val_acc: 0.9397\n",
      "Epoch 20/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9511\n",
      "Epoch 00020: val_loss did not improve from 0.17582\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1434 - acc: 0.9511 - val_loss: 0.1764 - val_acc: 0.9392\n",
      "auc0.8886741693193306, auprc0.5216702312989662, acc0.941021337808679, F10.4675324675324675 \n",
      "0.8886741693193306 0.5216702312989662 0.941021337808679 0.4675324675324675\n",
      "Iteration number:  6\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.8957\n",
      "Epoch 00001: val_loss improved from inf to 0.24629, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 10s 32ms/step - loss: 0.3119 - acc: 0.8957 - val_loss: 0.2463 - val_acc: 0.9158\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.9114\n",
      "Epoch 00002: val_loss improved from 0.24629 to 0.24436, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2546 - acc: 0.9115 - val_loss: 0.2444 - val_acc: 0.9129\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9151\n",
      "Epoch 00003: val_loss improved from 0.24436 to 0.24059, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2441 - acc: 0.9150 - val_loss: 0.2406 - val_acc: 0.9158\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9181\n",
      "Epoch 00004: val_loss improved from 0.24059 to 0.23899, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.2350 - acc: 0.9181 - val_loss: 0.2390 - val_acc: 0.9144\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9202- ETA: 1\n",
      "Epoch 00005: val_loss improved from 0.23899 to 0.23799, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2294 - acc: 0.9202 - val_loss: 0.2380 - val_acc: 0.9148\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9190\n",
      "Epoch 00006: val_loss improved from 0.23799 to 0.23790, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2273 - acc: 0.9191 - val_loss: 0.2379 - val_acc: 0.9153\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2225 - acc: 0.9217\n",
      "Epoch 00007: val_loss improved from 0.23790 to 0.23773, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2225 - acc: 0.9217 - val_loss: 0.2377 - val_acc: 0.9144\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2171 - acc: 0.9224\n",
      "Epoch 00008: val_loss improved from 0.23773 to 0.23703, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2176 - acc: 0.9220 - val_loss: 0.2370 - val_acc: 0.9167\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9230\n",
      "Epoch 00009: val_loss did not improve from 0.23703\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2167 - acc: 0.9229 - val_loss: 0.2378 - val_acc: 0.9172\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2144 - acc: 0.9231\n",
      "Epoch 00010: val_loss did not improve from 0.23703\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2143 - acc: 0.9232 - val_loss: 0.2380 - val_acc: 0.9163\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2131 - acc: 0.9248\n",
      "Epoch 00011: val_loss did not improve from 0.23703\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2129 - acc: 0.9249 - val_loss: 0.2371 - val_acc: 0.9187\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9237\n",
      "Epoch 00012: val_loss improved from 0.23703 to 0.23668, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2109 - acc: 0.9236 - val_loss: 0.2367 - val_acc: 0.9187\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9256\n",
      "Epoch 00013: val_loss did not improve from 0.23668\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2101 - acc: 0.9252 - val_loss: 0.2367 - val_acc: 0.9187\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2098 - acc: 0.9255\n",
      "Epoch 00014: val_loss did not improve from 0.23668\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2098 - acc: 0.9255 - val_loss: 0.2367 - val_acc: 0.9187\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9249\n",
      "Epoch 00015: val_loss did not improve from 0.23668\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2074 - acc: 0.9250 - val_loss: 0.2367 - val_acc: 0.9177\n",
      "Epoch 16/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9256\n",
      "Epoch 00016: val_loss did not improve from 0.23668\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2066 - acc: 0.9256 - val_loss: 0.2370 - val_acc: 0.9172\n",
      "Epoch 17/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2063 - acc: 0.9264\n",
      "Epoch 00017: val_loss improved from 0.23668 to 0.23644, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2063 - acc: 0.9264 - val_loss: 0.2364 - val_acc: 0.9196\n",
      "Epoch 18/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9261\n",
      "Epoch 00018: val_loss did not improve from 0.23644\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2052 - acc: 0.9262 - val_loss: 0.2368 - val_acc: 0.9177\n",
      "Epoch 19/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9280\n",
      "Epoch 00019: val_loss did not improve from 0.23644\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2025 - acc: 0.9278 - val_loss: 0.2365 - val_acc: 0.9191\n",
      "Epoch 20/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9274- ETA\n",
      "Epoch 00020: val_loss did not improve from 0.23644\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2039 - acc: 0.9274 - val_loss: 0.2365 - val_acc: 0.9172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9265\n",
      "Epoch 00021: val_loss did not improve from 0.23644\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2023 - acc: 0.9265 - val_loss: 0.2368 - val_acc: 0.9187\n",
      "Epoch 22/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9284\n",
      "Epoch 00022: val_loss did not improve from 0.23644\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2012 - acc: 0.9284 - val_loss: 0.2369 - val_acc: 0.9196\n",
      "auc0.8798419605749845, auprc0.5874919238344121, acc0.9158475185806761, F10.4964131994261119 \n",
      "0.8798419605749845 0.5874919238344121 0.9158475185806761 0.4964131994261119\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9299\n",
      "Epoch 00001: val_loss improved from inf to 0.18785, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 31ms/step - loss: 0.2343 - acc: 0.9299 - val_loss: 0.1879 - val_acc: 0.9416\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9410\n",
      "Epoch 00002: val_loss improved from 0.18785 to 0.18057, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1881 - acc: 0.9411 - val_loss: 0.1806 - val_acc: 0.9440\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9430\n",
      "Epoch 00003: val_loss improved from 0.18057 to 0.17898, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1779 - acc: 0.9432 - val_loss: 0.1790 - val_acc: 0.9445\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9449\n",
      "Epoch 00004: val_loss improved from 0.17898 to 0.17683, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1714 - acc: 0.9448 - val_loss: 0.1768 - val_acc: 0.9421\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9455\n",
      "Epoch 00005: val_loss improved from 0.17683 to 0.17614, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1681 - acc: 0.9454 - val_loss: 0.1761 - val_acc: 0.9407\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9468\n",
      "Epoch 00006: val_loss improved from 0.17614 to 0.17602, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1625 - acc: 0.9468 - val_loss: 0.1760 - val_acc: 0.9416\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9464\n",
      "Epoch 00007: val_loss improved from 0.17602 to 0.17471, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.1595 - acc: 0.9465 - val_loss: 0.1747 - val_acc: 0.9402\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1581 - acc: 0.9477\n",
      "Epoch 00008: val_loss did not improve from 0.17471\n",
      "230/230 [==============================] - 8s 34ms/step - loss: 0.1581 - acc: 0.9478 - val_loss: 0.1748 - val_acc: 0.9421\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9473\n",
      "Epoch 00009: val_loss improved from 0.17471 to 0.17438, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.1548 - acc: 0.9474 - val_loss: 0.1744 - val_acc: 0.9411\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9505\n",
      "Epoch 00010: val_loss did not improve from 0.17438\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.1549 - acc: 0.9504 - val_loss: 0.1746 - val_acc: 0.9416\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9499\n",
      "Epoch 00011: val_loss improved from 0.17438 to 0.17362, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.1527 - acc: 0.9499 - val_loss: 0.1736 - val_acc: 0.9402\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9504\n",
      "Epoch 00012: val_loss did not improve from 0.17362\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.1500 - acc: 0.9504 - val_loss: 0.1743 - val_acc: 0.9402\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9509\n",
      "Epoch 00013: val_loss did not improve from 0.17362\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1493 - acc: 0.9509 - val_loss: 0.1744 - val_acc: 0.9407\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9503\n",
      "Epoch 00014: val_loss did not improve from 0.17362\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1481 - acc: 0.9504 - val_loss: 0.1739 - val_acc: 0.9407\n",
      "Epoch 15/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9505\n",
      "Epoch 00015: val_loss did not improve from 0.17362\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1473 - acc: 0.9505 - val_loss: 0.1740 - val_acc: 0.9421\n",
      "Epoch 16/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9511\n",
      "Epoch 00016: val_loss did not improve from 0.17362\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1470 - acc: 0.9511 - val_loss: 0.1740 - val_acc: 0.9411\n",
      "auc0.8859588440233601, auprc0.516402720494937, acc0.9383840805562216, F10.44008714596949894 \n",
      "0.8859588440233601 0.516402720494937 0.9383840805562216 0.44008714596949894\n",
      "Iteration number:  7\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.8974\n",
      "Epoch 00001: val_loss improved from inf to 0.25252, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 30ms/step - loss: 0.3030 - acc: 0.8975 - val_loss: 0.2525 - val_acc: 0.9163\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2546 - acc: 0.9129\n",
      "Epoch 00002: val_loss improved from 0.25252 to 0.24653, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2545 - acc: 0.9130 - val_loss: 0.2465 - val_acc: 0.9158\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9160\n",
      "Epoch 00003: val_loss improved from 0.24653 to 0.24424, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2398 - acc: 0.9161 - val_loss: 0.2442 - val_acc: 0.9177\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.9187\n",
      "Epoch 00004: val_loss improved from 0.24424 to 0.24184, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.2320 - acc: 0.9186 - val_loss: 0.2418 - val_acc: 0.9153\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.9189\n",
      "Epoch 00005: val_loss did not improve from 0.24184\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2282 - acc: 0.9188 - val_loss: 0.2430 - val_acc: 0.9129\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9214\n",
      "Epoch 00006: val_loss improved from 0.24184 to 0.24083, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2231 - acc: 0.9214 - val_loss: 0.2408 - val_acc: 0.9158\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9226\n",
      "Epoch 00007: val_loss improved from 0.24083 to 0.24082, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2192 - acc: 0.9225 - val_loss: 0.2408 - val_acc: 0.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9235\n",
      "Epoch 00008: val_loss did not improve from 0.24082\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2149 - acc: 0.9236 - val_loss: 0.2420 - val_acc: 0.9148\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9242\n",
      "Epoch 00009: val_loss improved from 0.24082 to 0.24063, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2151 - acc: 0.9240 - val_loss: 0.2406 - val_acc: 0.9158\n",
      "Epoch 10/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9228\n",
      "Epoch 00010: val_loss did not improve from 0.24063\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2121 - acc: 0.9229 - val_loss: 0.2407 - val_acc: 0.9153\n",
      "Epoch 11/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2097 - acc: 0.9243\n",
      "Epoch 00011: val_loss improved from 0.24063 to 0.24042, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2097 - acc: 0.9243 - val_loss: 0.2404 - val_acc: 0.9144\n",
      "Epoch 12/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9243- ETA:  - ETA: \n",
      "Epoch 00012: val_loss did not improve from 0.24042\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2086 - acc: 0.9243 - val_loss: 0.2409 - val_acc: 0.9134\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9248\n",
      "Epoch 00013: val_loss did not improve from 0.24042\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2084 - acc: 0.9248 - val_loss: 0.2405 - val_acc: 0.9134\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2057 - acc: 0.9255\n",
      "Epoch 00014: val_loss improved from 0.24042 to 0.24032, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2057 - acc: 0.9255 - val_loss: 0.2403 - val_acc: 0.9129\n",
      "Epoch 15/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2042 - acc: 0.9274\n",
      "Epoch 00015: val_loss did not improve from 0.24032\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2042 - acc: 0.9274 - val_loss: 0.2406 - val_acc: 0.9148\n",
      "Epoch 16/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9270\n",
      "Epoch 00016: val_loss did not improve from 0.24032\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2034 - acc: 0.9270 - val_loss: 0.2408 - val_acc: 0.9129\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9259\n",
      "Epoch 00017: val_loss did not improve from 0.24032\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2032 - acc: 0.9259 - val_loss: 0.2412 - val_acc: 0.9124\n",
      "Epoch 18/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9267\n",
      "Epoch 00018: val_loss did not improve from 0.24032\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2003 - acc: 0.9266 - val_loss: 0.2411 - val_acc: 0.9115\n",
      "Epoch 19/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2009 - acc: 0.9287\n",
      "Epoch 00019: val_loss did not improve from 0.24032\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2012 - acc: 0.9287 - val_loss: 0.2407 - val_acc: 0.9144\n",
      "auc0.876901993639302, auprc0.5872169563924768, acc0.9148885159434188, F10.4862518089725037 \n",
      "0.876901993639302 0.5872169563924768 0.9148885159434188 0.4862518089725037\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2325 - acc: 0.9300\n",
      "Epoch 00001: val_loss improved from inf to 0.18713, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 32ms/step - loss: 0.2324 - acc: 0.9300 - val_loss: 0.1871 - val_acc: 0.9440\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9415\n",
      "Epoch 00002: val_loss improved from 0.18713 to 0.17895, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.1863 - acc: 0.9416 - val_loss: 0.1789 - val_acc: 0.9402\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9427\n",
      "Epoch 00003: val_loss improved from 0.17895 to 0.17709, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1785 - acc: 0.9429 - val_loss: 0.1771 - val_acc: 0.9392\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9437\n",
      "Epoch 00004: val_loss improved from 0.17709 to 0.17522, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1697 - acc: 0.9437 - val_loss: 0.1752 - val_acc: 0.9402\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1651 - acc: 0.9465- ETA: 1s - loss: 0.1591 - acc - ETA: 0s - loss: 0.1620\n",
      "Epoch 00005: val_loss improved from 0.17522 to 0.17464, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 33ms/step - loss: 0.1652 - acc: 0.9465 - val_loss: 0.1746 - val_acc: 0.9402\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9473- ETA: 0s - loss: 0.1632 - acc:\n",
      "Epoch 00006: val_loss improved from 0.17464 to 0.17392, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.1625 - acc: 0.9473 - val_loss: 0.1739 - val_acc: 0.9397\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9478- ET - ETA: 1\n",
      "Epoch 00007: val_loss improved from 0.17392 to 0.17378, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1585 - acc: 0.9478 - val_loss: 0.1738 - val_acc: 0.9402\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9464\n",
      "Epoch 00008: val_loss improved from 0.17378 to 0.17347, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1578 - acc: 0.9464 - val_loss: 0.1735 - val_acc: 0.9416\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9481\n",
      "Epoch 00009: val_loss did not improve from 0.17347\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1554 - acc: 0.9482 - val_loss: 0.1735 - val_acc: 0.9421\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9483\n",
      "Epoch 00010: val_loss improved from 0.17347 to 0.17320, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1528 - acc: 0.9484 - val_loss: 0.1732 - val_acc: 0.9411\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9490\n",
      "Epoch 00011: val_loss did not improve from 0.17320\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1520 - acc: 0.9490 - val_loss: 0.1733 - val_acc: 0.9416\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9491\n",
      "Epoch 00012: val_loss did not improve from 0.17320\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1499 - acc: 0.9491 - val_loss: 0.1739 - val_acc: 0.9421\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9507\n",
      "Epoch 00013: val_loss did not improve from 0.17320\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1487 - acc: 0.9508 - val_loss: 0.1737 - val_acc: 0.9426\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9505- ETA: 0s - loss: 0.1462 - acc: 0.95\n",
      "Epoch 00014: val_loss did not improve from 0.17320\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1473 - acc: 0.9504 - val_loss: 0.1741 - val_acc: 0.9421\n",
      "Epoch 15/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9493\n",
      "Epoch 00015: val_loss did not improve from 0.17320\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1481 - acc: 0.9495 - val_loss: 0.1742 - val_acc: 0.9416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc0.8862370604306088, auprc0.5223136544470788, acc0.9395828338527931, F10.4449339207048459 \n",
      "0.8862370604306088 0.5223136544470788 0.9395828338527931 0.4449339207048459\n",
      "Iteration number:  8\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3052 - acc: 0.8984\n",
      "Epoch 00001: val_loss improved from inf to 0.24990, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 31ms/step - loss: 0.3051 - acc: 0.8985 - val_loss: 0.2499 - val_acc: 0.9134\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2559 - acc: 0.9132\n",
      "Epoch 00002: val_loss improved from 0.24990 to 0.24689, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2556 - acc: 0.9135 - val_loss: 0.2469 - val_acc: 0.9129\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.9155\n",
      "Epoch 00003: val_loss improved from 0.24689 to 0.24241, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2434 - acc: 0.9155 - val_loss: 0.2424 - val_acc: 0.9153\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2351 - acc: 0.9184- ETA: 0s - loss: 0.2348 - acc\n",
      "Epoch 00004: val_loss improved from 0.24241 to 0.24201, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2352 - acc: 0.9184 - val_loss: 0.2420 - val_acc: 0.9163\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2279 - acc: 0.9206\n",
      "Epoch 00005: val_loss improved from 0.24201 to 0.24033, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2279 - acc: 0.9206 - val_loss: 0.2403 - val_acc: 0.9172\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9203\n",
      "Epoch 00006: val_loss improved from 0.24033 to 0.24025, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2244 - acc: 0.9202 - val_loss: 0.2402 - val_acc: 0.9167\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9213\n",
      "Epoch 00007: val_loss improved from 0.24025 to 0.23906, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2196 - acc: 0.9212 - val_loss: 0.2391 - val_acc: 0.9163\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2185 - acc: 0.9234\n",
      "Epoch 00008: val_loss did not improve from 0.23906\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2186 - acc: 0.9234 - val_loss: 0.2391 - val_acc: 0.9163\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2157 - acc: 0.9239\n",
      "Epoch 00009: val_loss did not improve from 0.23906\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2157 - acc: 0.9239 - val_loss: 0.2393 - val_acc: 0.9144\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9234\n",
      "Epoch 00010: val_loss improved from 0.23906 to 0.23840, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2133 - acc: 0.9235 - val_loss: 0.2384 - val_acc: 0.9177\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9237- ETA: 1s - loss: 0\n",
      "Epoch 00011: val_loss did not improve from 0.23840\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2122 - acc: 0.9240 - val_loss: 0.2393 - val_acc: 0.9153\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2100 - acc: 0.9259\n",
      "Epoch 00012: val_loss improved from 0.23840 to 0.23799, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2100 - acc: 0.9259 - val_loss: 0.2380 - val_acc: 0.9167\n",
      "Epoch 13/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9251- ETA: 0s - loss: 0.2079 - acc:\n",
      "Epoch 00013: val_loss did not improve from 0.23799\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2086 - acc: 0.9249 - val_loss: 0.2386 - val_acc: 0.9158\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9285\n",
      "Epoch 00014: val_loss did not improve from 0.23799\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2059 - acc: 0.9285 - val_loss: 0.2381 - val_acc: 0.9167\n",
      "Epoch 15/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2046 - acc: 0.9266\n",
      "Epoch 00015: val_loss did not improve from 0.23799\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2046 - acc: 0.9266 - val_loss: 0.2388 - val_acc: 0.9163\n",
      "Epoch 16/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9279- ET\n",
      "Epoch 00016: val_loss improved from 0.23799 to 0.23794, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 39ms/step - loss: 0.2032 - acc: 0.9278 - val_loss: 0.2379 - val_acc: 0.9177\n",
      "Epoch 17/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2017 - acc: 0.9276\n",
      "Epoch 00017: val_loss did not improve from 0.23794\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2016 - acc: 0.9277 - val_loss: 0.2388 - val_acc: 0.9153\n",
      "Epoch 18/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2025 - acc: 0.9284\n",
      "Epoch 00018: val_loss improved from 0.23794 to 0.23781, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2026 - acc: 0.9283 - val_loss: 0.2378 - val_acc: 0.9182\n",
      "Epoch 19/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9274\n",
      "Epoch 00019: val_loss did not improve from 0.23781\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2002 - acc: 0.9275 - val_loss: 0.2383 - val_acc: 0.9167\n",
      "Epoch 20/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9286\n",
      "Epoch 00020: val_loss did not improve from 0.23781\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1989 - acc: 0.9285 - val_loss: 0.2385 - val_acc: 0.9177\n",
      "Epoch 21/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9288\n",
      "Epoch 00021: val_loss did not improve from 0.23781\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.1986 - acc: 0.9288 - val_loss: 0.2379 - val_acc: 0.9187\n",
      "Epoch 22/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9293\n",
      "Epoch 00022: val_loss did not improve from 0.23781\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.1973 - acc: 0.9294 - val_loss: 0.2380 - val_acc: 0.9187\n",
      "Epoch 23/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9286\n",
      "Epoch 00023: val_loss improved from 0.23781 to 0.23780, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 8s 34ms/step - loss: 0.1973 - acc: 0.9287 - val_loss: 0.2378 - val_acc: 0.9182\n",
      "Epoch 24/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9294\n",
      "Epoch 00024: val_loss did not improve from 0.23780\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.1962 - acc: 0.9293 - val_loss: 0.2378 - val_acc: 0.9177\n",
      "Epoch 25/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9299\n",
      "Epoch 00025: val_loss did not improve from 0.23780\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.1956 - acc: 0.9300 - val_loss: 0.2382 - val_acc: 0.9187\n",
      "Epoch 26/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9296\n",
      "Epoch 00026: val_loss did not improve from 0.23780\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1957 - acc: 0.9297 - val_loss: 0.2385 - val_acc: 0.9172\n",
      "Epoch 27/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9305\n",
      "Epoch 00027: val_loss did not improve from 0.23780\n",
      "230/230 [==============================] - 8s 33ms/step - loss: 0.1951 - acc: 0.9306 - val_loss: 0.2383 - val_acc: 0.9191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9314\n",
      "Epoch 00028: val_loss did not improve from 0.23780\n",
      "230/230 [==============================] - 9s 38ms/step - loss: 0.1937 - acc: 0.9313 - val_loss: 0.2392 - val_acc: 0.9172\n",
      "auc0.8795379479619961, auprc0.5777366499443775, acc0.9117717573723327, F10.46511627906976744 \n",
      "0.8795379479619961 0.5777366499443775 0.9117717573723327 0.46511627906976744\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2313 - acc: 0.9305\n",
      "Epoch 00001: val_loss improved from inf to 0.18805, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 33ms/step - loss: 0.2312 - acc: 0.9306 - val_loss: 0.1881 - val_acc: 0.9368\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1873 - acc: 0.9406\n",
      "Epoch 00002: val_loss improved from 0.18805 to 0.18258, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1874 - acc: 0.9405 - val_loss: 0.1826 - val_acc: 0.9378\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1776 - acc: 0.9441\n",
      "Epoch 00003: val_loss improved from 0.18258 to 0.18189, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1774 - acc: 0.9442 - val_loss: 0.1819 - val_acc: 0.9368\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9450\n",
      "Epoch 00004: val_loss improved from 0.18189 to 0.17889, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1704 - acc: 0.9449 - val_loss: 0.1789 - val_acc: 0.9364\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9452\n",
      "Epoch 00005: val_loss improved from 0.17889 to 0.17780, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1660 - acc: 0.9452 - val_loss: 0.1778 - val_acc: 0.9359\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1622 - acc: 0.9465\n",
      "Epoch 00006: val_loss improved from 0.17780 to 0.17736, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1622 - acc: 0.9465 - val_loss: 0.1774 - val_acc: 0.9349\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9487\n",
      "Epoch 00007: val_loss improved from 0.17736 to 0.17722, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.1598 - acc: 0.9486 - val_loss: 0.1772 - val_acc: 0.9368\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9478\n",
      "Epoch 00008: val_loss improved from 0.17722 to 0.17716, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1581 - acc: 0.9478 - val_loss: 0.1772 - val_acc: 0.9383\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9500\n",
      "Epoch 00009: val_loss did not improve from 0.17716\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1535 - acc: 0.9501 - val_loss: 0.1772 - val_acc: 0.9383\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9499\n",
      "Epoch 00010: val_loss did not improve from 0.17716\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1518 - acc: 0.9499 - val_loss: 0.1773 - val_acc: 0.9368\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9507- ETA: 3s - loss: 0.1570 - acc: 0 - ETA: 3s - ETA: 1s - l\n",
      "Epoch 00011: val_loss improved from 0.17716 to 0.17683, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1494 - acc: 0.9508 - val_loss: 0.1768 - val_acc: 0.9378\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9501\n",
      "Epoch 00012: val_loss did not improve from 0.17683\n",
      "230/230 [==============================] - 8s 34ms/step - loss: 0.1496 - acc: 0.9502 - val_loss: 0.1768 - val_acc: 0.9368\n",
      "Epoch 13/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1476 - acc: 0.9507\n",
      "Epoch 00013: val_loss did not improve from 0.17683\n",
      "230/230 [==============================] - 8s 34ms/step - loss: 0.1476 - acc: 0.9507 - val_loss: 0.1769 - val_acc: 0.9368\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9511\n",
      "Epoch 00014: val_loss did not improve from 0.17683\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.1470 - acc: 0.9511 - val_loss: 0.1769 - val_acc: 0.9368\n",
      "Epoch 15/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9516- ETA:\n",
      "Epoch 00015: val_loss did not improve from 0.17683\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1454 - acc: 0.9515 - val_loss: 0.1769 - val_acc: 0.9364\n",
      "Epoch 16/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9521\n",
      "Epoch 00016: val_loss did not improve from 0.17683\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1445 - acc: 0.9519 - val_loss: 0.1770 - val_acc: 0.9373\n",
      "auc0.889256502159728, auprc0.5202100528690277, acc0.9388635818748502, F10.4468546637744036 \n",
      "0.889256502159728 0.5202100528690277 0.9388635818748502 0.4468546637744036\n",
      "Iteration number:  9\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.8988\n",
      "Epoch 00001: val_loss improved from inf to 0.25081, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 29ms/step - loss: 0.3011 - acc: 0.8985 - val_loss: 0.2508 - val_acc: 0.9158\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2521 - acc: 0.9134\n",
      "Epoch 00002: val_loss improved from 0.25081 to 0.24633, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2519 - acc: 0.9133 - val_loss: 0.2463 - val_acc: 0.9153\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2423 - acc: 0.9150\n",
      "Epoch 00003: val_loss improved from 0.24633 to 0.24355, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.2419 - acc: 0.9152 - val_loss: 0.2436 - val_acc: 0.9144\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.918 - ETA: 0s - loss: 0.2325 - acc: 0.9187\n",
      "Epoch 00004: val_loss improved from 0.24355 to 0.24180, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.2324 - acc: 0.9188 - val_loss: 0.2418 - val_acc: 0.9153\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9195\n",
      "Epoch 00005: val_loss improved from 0.24180 to 0.24102, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.2272 - acc: 0.9195 - val_loss: 0.2410 - val_acc: 0.9153\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2229 - acc: 0.9206\n",
      "Epoch 00006: val_loss improved from 0.24102 to 0.24076, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2230 - acc: 0.9206 - val_loss: 0.2408 - val_acc: 0.9134\n",
      "Epoch 7/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9224\n",
      "Epoch 00007: val_loss improved from 0.24076 to 0.23889, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2199 - acc: 0.9225 - val_loss: 0.2389 - val_acc: 0.9153\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - ETA: 0s - loss: 0.2165 - acc: 0.9234\n",
      "Epoch 00008: val_loss did not improve from 0.23889\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2165 - acc: 0.9234 - val_loss: 0.2397 - val_acc: 0.9182\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9239\n",
      "Epoch 00009: val_loss did not improve from 0.23889\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.2141 - acc: 0.9236 - val_loss: 0.2411 - val_acc: 0.9167\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2131 - acc: 0.9238\n",
      "Epoch 00010: val_loss improved from 0.23889 to 0.23845, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2133 - acc: 0.9238 - val_loss: 0.2385 - val_acc: 0.9163\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9253\n",
      "Epoch 00011: val_loss did not improve from 0.23845\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2106 - acc: 0.9253 - val_loss: 0.2390 - val_acc: 0.9163\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2082 - acc: 0.9247\n",
      "Epoch 00012: val_loss did not improve from 0.23845\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2082 - acc: 0.9247 - val_loss: 0.2393 - val_acc: 0.9153\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9271\n",
      "Epoch 00013: val_loss did not improve from 0.23845\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2064 - acc: 0.9271 - val_loss: 0.2393 - val_acc: 0.9182\n",
      "Epoch 14/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9266\n",
      "Epoch 00014: val_loss did not improve from 0.23845\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2066 - acc: 0.9266 - val_loss: 0.2388 - val_acc: 0.9153\n",
      "Epoch 15/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9260\n",
      "Epoch 00015: val_loss did not improve from 0.23845\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2056 - acc: 0.9262 - val_loss: 0.2385 - val_acc: 0.9182\n",
      "auc0.8764577581544314, auprc0.5803871865530958, acc0.9160872692399904, F10.48830409356725146 \n",
      "0.8764577581544314 0.5803871865530958 0.9160872692399904 0.48830409356725146\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9333\n",
      "Epoch 00001: val_loss improved from inf to 0.18649, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 10s 33ms/step - loss: 0.2253 - acc: 0.9334 - val_loss: 0.1865 - val_acc: 0.9431\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9422\n",
      "Epoch 00002: val_loss improved from 0.18649 to 0.18247, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1848 - acc: 0.9422 - val_loss: 0.1825 - val_acc: 0.9431\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9449\n",
      "Epoch 00003: val_loss improved from 0.18247 to 0.17893, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1740 - acc: 0.9448 - val_loss: 0.1789 - val_acc: 0.9411\n",
      "Epoch 4/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9450\n",
      "Epoch 00004: val_loss improved from 0.17893 to 0.17769, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1690 - acc: 0.9451 - val_loss: 0.1777 - val_acc: 0.9416\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9461\n",
      "Epoch 00005: val_loss improved from 0.17769 to 0.17742, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1642 - acc: 0.9460 - val_loss: 0.1774 - val_acc: 0.9411\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9478\n",
      "Epoch 00006: val_loss improved from 0.17742 to 0.17657, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1595 - acc: 0.9478 - val_loss: 0.1766 - val_acc: 0.9397\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1577 - acc: 0.9482\n",
      "Epoch 00007: val_loss improved from 0.17657 to 0.17617, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1577 - acc: 0.9482 - val_loss: 0.1762 - val_acc: 0.9431\n",
      "Epoch 8/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9484- ETA: 1s - loss\n",
      "Epoch 00008: val_loss improved from 0.17617 to 0.17541, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1558 - acc: 0.9483 - val_loss: 0.1754 - val_acc: 0.9431\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1542 - acc: 0.9477\n",
      "Epoch 00009: val_loss improved from 0.17541 to 0.17509, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1541 - acc: 0.9478 - val_loss: 0.1751 - val_acc: 0.9431\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9500\n",
      "Epoch 00010: val_loss did not improve from 0.17509\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1519 - acc: 0.9500 - val_loss: 0.1756 - val_acc: 0.9411\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9494\n",
      "Epoch 00011: val_loss did not improve from 0.17509\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1495 - acc: 0.9494 - val_loss: 0.1759 - val_acc: 0.9421\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1495 - acc: 0.9499\n",
      "Epoch 00012: val_loss did not improve from 0.17509\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1495 - acc: 0.9499 - val_loss: 0.1761 - val_acc: 0.9407\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9509\n",
      "Epoch 00013: val_loss did not improve from 0.17509\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1479 - acc: 0.9509 - val_loss: 0.1767 - val_acc: 0.9402\n",
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9510\n",
      "Epoch 00014: val_loss did not improve from 0.17509\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1463 - acc: 0.9511 - val_loss: 0.1754 - val_acc: 0.9416\n",
      "auc0.8853890434535595, auprc0.5127475001223119, acc0.9383840805562216, F10.42505592841163314 \n",
      "0.8853890434535595 0.5127475001223119 0.9383840805562216 0.42505592841163314\n",
      "Iteration number:  10\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.3017 - acc: 0.8975\n",
      "Epoch 00001: val_loss improved from inf to 0.25212, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 9s 31ms/step - loss: 0.3017 - acc: 0.8975 - val_loss: 0.2521 - val_acc: 0.9096\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2523 - acc: 0.9129\n",
      "Epoch 00002: val_loss improved from 0.25212 to 0.24517, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2522 - acc: 0.9129 - val_loss: 0.2452 - val_acc: 0.9129\n",
      "Epoch 3/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9180\n",
      "Epoch 00003: val_loss improved from 0.24517 to 0.24257, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2393 - acc: 0.9176 - val_loss: 0.2426 - val_acc: 0.9134\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9187\n",
      "Epoch 00004: val_loss improved from 0.24257 to 0.24159, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2322 - acc: 0.9187 - val_loss: 0.2416 - val_acc: 0.9124\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9194\n",
      "Epoch 00005: val_loss did not improve from 0.24159\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2276 - acc: 0.9194 - val_loss: 0.2419 - val_acc: 0.9105\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2228 - acc: 0.9201\n",
      "Epoch 00006: val_loss improved from 0.24159 to 0.23993, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.2231 - acc: 0.9201 - val_loss: 0.2399 - val_acc: 0.9115\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9217\n",
      "Epoch 00007: val_loss did not improve from 0.23993\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.2211 - acc: 0.9218 - val_loss: 0.2406 - val_acc: 0.9120\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2172 - acc: 0.9221\n",
      "Epoch 00008: val_loss did not improve from 0.23993\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.2172 - acc: 0.9221 - val_loss: 0.2411 - val_acc: 0.9115\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2142 - acc: 0.9241\n",
      "Epoch 00009: val_loss did not improve from 0.23993\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.2141 - acc: 0.9242 - val_loss: 0.2412 - val_acc: 0.9124\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2136 - acc: 0.9232\n",
      "Epoch 00010: val_loss did not improve from 0.23993\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2136 - acc: 0.9232 - val_loss: 0.2400 - val_acc: 0.9124\n",
      "Epoch 11/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9263\n",
      "Epoch 00011: val_loss did not improve from 0.23993\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.2112 - acc: 0.9261 - val_loss: 0.2408 - val_acc: 0.9129\n",
      "auc0.8742978545900603, auprc0.5724929235921974, acc0.9129705106689043, F10.4508320726172466 \n",
      "0.8742978545900603 0.5724929235921974 0.9129705106689043 0.4508320726172466\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2353 - acc: 0.9267\n",
      "Epoch 00001: val_loss improved from inf to 0.18685, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 9s 30ms/step - loss: 0.2352 - acc: 0.9268 - val_loss: 0.1868 - val_acc: 0.9416\n",
      "Epoch 2/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9400- ETA: 1s - los\n",
      "Epoch 00002: val_loss improved from 0.18685 to 0.18156, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1873 - acc: 0.9401 - val_loss: 0.1816 - val_acc: 0.9397\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9417\n",
      "Epoch 00003: val_loss improved from 0.18156 to 0.18029, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1778 - acc: 0.9417 - val_loss: 0.1803 - val_acc: 0.9407\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9449\n",
      "Epoch 00004: val_loss improved from 0.18029 to 0.17901, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.1702 - acc: 0.9450 - val_loss: 0.1790 - val_acc: 0.9411\n",
      "Epoch 5/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9457\n",
      "Epoch 00005: val_loss improved from 0.17901 to 0.17688, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1653 - acc: 0.9457 - val_loss: 0.1769 - val_acc: 0.9416\n",
      "Epoch 6/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9474- ETA: 1s - los\n",
      "Epoch 00006: val_loss did not improve from 0.17688\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1618 - acc: 0.9470 - val_loss: 0.1781 - val_acc: 0.9407\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1588 - acc: 0.9478\n",
      "Epoch 00007: val_loss did not improve from 0.17688\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1588 - acc: 0.9478 - val_loss: 0.1784 - val_acc: 0.9397\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1558 - acc: 0.9486\n",
      "Epoch 00008: val_loss improved from 0.17688 to 0.17670, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 26ms/step - loss: 0.1558 - acc: 0.9486 - val_loss: 0.1767 - val_acc: 0.9407\n",
      "Epoch 9/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9484\n",
      "Epoch 00009: val_loss improved from 0.17670 to 0.17638, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 6s 27ms/step - loss: 0.1534 - acc: 0.9484 - val_loss: 0.1764 - val_acc: 0.9416\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9494\n",
      "Epoch 00010: val_loss did not improve from 0.17638\n",
      "230/230 [==============================] - 6s 28ms/step - loss: 0.1523 - acc: 0.9494 - val_loss: 0.1769 - val_acc: 0.9416\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9495\n",
      "Epoch 00011: val_loss did not improve from 0.17638\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1514 - acc: 0.9495 - val_loss: 0.1768 - val_acc: 0.9416\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9505\n",
      "Epoch 00012: val_loss did not improve from 0.17638\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.1480 - acc: 0.9506 - val_loss: 0.1769 - val_acc: 0.9416\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9514\n",
      "Epoch 00013: val_loss did not improve from 0.17638\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.1484 - acc: 0.9513 - val_loss: 0.1770 - val_acc: 0.9407\n",
      "Epoch 14/100\n",
      "228/230 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9509\n",
      "Epoch 00014: val_loss did not improve from 0.17638\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.1465 - acc: 0.9508 - val_loss: 0.1772 - val_acc: 0.9411\n",
      "auc0.8897486026518284, auprc0.5172991275180429, acc0.941021337808679, F10.46052631578947373 \n",
      "0.8897486026518284 0.5172991275180429 0.941021337808679 0.46052631578947373\n",
      "Hidden unit:  256\n",
      "Embedding:  word2vec\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.9012- ETA: 0s - loss: 0.2916 - acc: \n",
      "Epoch 00001: val_loss improved from inf to 0.24924, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 50ms/step - loss: 0.2890 - acc: 0.9011 - val_loss: 0.2492 - val_acc: 0.9139\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2444 - acc: 0.9137- ETA: 0s - loss: 0.2447 - acc: 0.914 - ETA: 0s - loss: 0.2443 - a\n",
      "Epoch 00002: val_loss improved from 0.24924 to 0.24404, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2444 - acc: 0.9137 - val_loss: 0.2440 - val_acc: 0.9153\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2304 - acc: 0.9182\n",
      "Epoch 00003: val_loss improved from 0.24404 to 0.24090, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.2304 - acc: 0.9182 - val_loss: 0.2409 - val_acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2220 - acc: 0.9210\n",
      "Epoch 00004: val_loss improved from 0.24090 to 0.23972, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2220 - acc: 0.9210 - val_loss: 0.2397 - val_acc: 0.9134\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2142 - acc: 0.9234\n",
      "Epoch 00005: val_loss did not improve from 0.23972\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2142 - acc: 0.9234 - val_loss: 0.2462 - val_acc: 0.9124\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2105 - acc: 0.9239- ETA: 5s - loss: 0.2129 - acc: 0 - ETA: 5s - loss: 0.2132 - acc:  - ETA - ETA: 1s - loss: 0.\n",
      "Epoch 00006: val_loss improved from 0.23972 to 0.23925, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 0.2105 - acc: 0.9239 - val_loss: 0.2392 - val_acc: 0.9167\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2071 - acc: 0.9253- ETA: 1s \n",
      "Epoch 00007: val_loss did not improve from 0.23925\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2071 - acc: 0.9253 - val_loss: 0.2407 - val_acc: 0.9139\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9265-\n",
      "Epoch 00008: val_loss did not improve from 0.23925\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 0.2019 - acc: 0.9265 - val_loss: 0.2429 - val_acc: 0.9139\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2004 - acc: 0.9269- ETA: 1s - loss: 0.1\n",
      "Epoch 00009: val_loss did not improve from 0.23925\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2004 - acc: 0.9269 - val_loss: 0.2426 - val_acc: 0.9129\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1990 - acc: 0.9273\n",
      "Epoch 00010: val_loss did not improve from 0.23925\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1990 - acc: 0.9273 - val_loss: 0.2417 - val_acc: 0.9163\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9289- ETA: 2\n",
      "Epoch 00011: val_loss did not improve from 0.23925\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1945 - acc: 0.9289 - val_loss: 0.2408 - val_acc: 0.9139\n",
      "auc0.8797989510386508, auprc0.5885539897626865, acc0.9141692639654759, F10.47507331378299117 \n",
      "0.8797989510386508 0.5885539897626865 0.9141692639654759 0.47507331378299117\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2209 - acc: 0.9335\n",
      "Epoch 00001: val_loss improved from inf to 0.18104, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 50ms/step - loss: 0.2211 - acc: 0.9335 - val_loss: 0.1810 - val_acc: 0.9450\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9419\n",
      "Epoch 00002: val_loss improved from 0.18104 to 0.17846, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1809 - acc: 0.9420 - val_loss: 0.1785 - val_acc: 0.9416\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1671 - acc: 0.9464\n",
      "Epoch 00003: val_loss improved from 0.17846 to 0.17758, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1671 - acc: 0.9464 - val_loss: 0.1776 - val_acc: 0.9440\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1623 - acc: 0.9476- ETA: 2s\n",
      "Epoch 00004: val_loss improved from 0.17758 to 0.17490, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1623 - acc: 0.9476 - val_loss: 0.1749 - val_acc: 0.9416\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9488\n",
      "Epoch 00005: val_loss did not improve from 0.17490\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1578 - acc: 0.9488 - val_loss: 0.1752 - val_acc: 0.9411\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1530 - acc: 0.9495\n",
      "Epoch 00006: val_loss improved from 0.17490 to 0.17474, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1530 - acc: 0.9495 - val_loss: 0.1747 - val_acc: 0.9407\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9505\n",
      "Epoch 00007: val_loss improved from 0.17474 to 0.17473, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1491 - acc: 0.9506 - val_loss: 0.1747 - val_acc: 0.9421\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9509\n",
      "Epoch 00008: val_loss did not improve from 0.17473\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1467 - acc: 0.9509 - val_loss: 0.1754 - val_acc: 0.9416\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9509\n",
      "Epoch 00009: val_loss did not improve from 0.17473\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1441 - acc: 0.9509 - val_loss: 0.1755 - val_acc: 0.9397\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9536\n",
      "Epoch 00010: val_loss did not improve from 0.17473\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1409 - acc: 0.9536 - val_loss: 0.1760 - val_acc: 0.9407\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9535\n",
      "Epoch 00011: val_loss did not improve from 0.17473\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1387 - acc: 0.9535 - val_loss: 0.1756 - val_acc: 0.9416\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1381 - acc: 0.9530\n",
      "Epoch 00012: val_loss did not improve from 0.17473\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1381 - acc: 0.9530 - val_loss: 0.1761 - val_acc: 0.9421\n",
      "auc0.8845426974459233, auprc0.5278623485276518, acc0.941021337808679, F10.4652173913043478 \n",
      "0.8845426974459233 0.5278623485276518 0.941021337808679 0.4652173913043478\n",
      "Iteration number:  2\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2912 - acc: 0.9045\n",
      "Epoch 00001: val_loss improved from inf to 0.24702, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 57ms/step - loss: 0.2914 - acc: 0.9044 - val_loss: 0.2470 - val_acc: 0.9163\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2433 - acc: 0.9159\n",
      "Epoch 00002: val_loss did not improve from 0.24702\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2434 - acc: 0.9159 - val_loss: 0.2480 - val_acc: 0.9153\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9196\n",
      "Epoch 00003: val_loss improved from 0.24702 to 0.24397, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2299 - acc: 0.9195 - val_loss: 0.2440 - val_acc: 0.9177\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2200 - acc: 0.9217- ETA: 2s - loss - ETA: 0s - loss: 0.2179 - a\n",
      "Epoch 00004: val_loss did not improve from 0.24397\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2200 - acc: 0.9217 - val_loss: 0.2443 - val_acc: 0.9172\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9234- ET\n",
      "Epoch 00005: val_loss improved from 0.24397 to 0.24369, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 61ms/step - loss: 0.2153 - acc: 0.9234 - val_loss: 0.2437 - val_acc: 0.9167\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9259\n",
      "Epoch 00006: val_loss improved from 0.24369 to 0.24224, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2110 - acc: 0.9259 - val_loss: 0.2422 - val_acc: 0.9201\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9258\n",
      "Epoch 00007: val_loss did not improve from 0.24224\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2058 - acc: 0.9258 - val_loss: 0.2451 - val_acc: 0.9129\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2015 - acc: 0.9280\n",
      "Epoch 00008: val_loss did not improve from 0.24224\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2014 - acc: 0.9280 - val_loss: 0.2453 - val_acc: 0.9172\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1993 - acc: 0.9286\n",
      "Epoch 00009: val_loss did not improve from 0.24224\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1993 - acc: 0.9286 - val_loss: 0.2451 - val_acc: 0.9163\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9299\n",
      "Epoch 00010: val_loss did not improve from 0.24224\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1982 - acc: 0.9300 - val_loss: 0.2452 - val_acc: 0.9172\n",
      "Epoch 11/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1935 - acc: 0.9313\n",
      "Epoch 00011: val_loss did not improve from 0.24224\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1935 - acc: 0.9313 - val_loss: 0.2454 - val_acc: 0.9163\n",
      "auc0.8758677026662378, auprc0.5736584341986948, acc0.9100935027571326, F10.4460856720827179 \n",
      "0.8758677026662378 0.5736584341986948 0.9100935027571326 0.4460856720827179\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9304\n",
      "Epoch 00001: val_loss improved from inf to 0.18161, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 60ms/step - loss: 0.2286 - acc: 0.9304 - val_loss: 0.1816 - val_acc: 0.9407\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9428\n",
      "Epoch 00002: val_loss did not improve from 0.18161\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1805 - acc: 0.9428 - val_loss: 0.1824 - val_acc: 0.9407\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9447- ETA: 0s - loss: 0.16\n",
      "Epoch 00003: val_loss improved from 0.18161 to 0.17505, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 59ms/step - loss: 0.1676 - acc: 0.9447 - val_loss: 0.1750 - val_acc: 0.9397\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9464\n",
      "Epoch 00004: val_loss improved from 0.17505 to 0.17366, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 61ms/step - loss: 0.1611 - acc: 0.9464 - val_loss: 0.1737 - val_acc: 0.9397\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9494- ETA\n",
      "Epoch 00005: val_loss did not improve from 0.17366\n",
      "230/230 [==============================] - 14s 59ms/step - loss: 0.1558 - acc: 0.9494 - val_loss: 0.1744 - val_acc: 0.9416\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9494\n",
      "Epoch 00006: val_loss did not improve from 0.17366\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1498 - acc: 0.9493 - val_loss: 0.1762 - val_acc: 0.9421\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9510\n",
      "Epoch 00007: val_loss did not improve from 0.17366\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1473 - acc: 0.9510 - val_loss: 0.1746 - val_acc: 0.9392\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9516\n",
      "Epoch 00008: val_loss did not improve from 0.17366\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 0.1441 - acc: 0.9517 - val_loss: 0.1764 - val_acc: 0.9402\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9530\n",
      "Epoch 00009: val_loss did not improve from 0.17366\n",
      "230/230 [==============================] - 14s 62ms/step - loss: 0.1414 - acc: 0.9529 - val_loss: 0.1757 - val_acc: 0.9388\n",
      "auc0.883236834849738, auprc0.5129407066202317, acc0.9381443298969072, F10.4366812227074236 \n",
      "0.883236834849738 0.5129407066202317 0.9381443298969072 0.4366812227074236\n",
      "Iteration number:  3\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.8998\n",
      "Epoch 00001: val_loss improved from inf to 0.24538, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 57ms/step - loss: 0.3006 - acc: 0.8998 - val_loss: 0.2454 - val_acc: 0.9158\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2458 - acc: 0.9156\n",
      "Epoch 00002: val_loss did not improve from 0.24538\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.2459 - acc: 0.9155 - val_loss: 0.2472 - val_acc: 0.9158\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2333 - acc: 0.9178\n",
      "Epoch 00003: val_loss improved from 0.24538 to 0.24390, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.2332 - acc: 0.9178 - val_loss: 0.2439 - val_acc: 0.9139\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2229 - acc: 0.9202\n",
      "Epoch 00004: val_loss improved from 0.24390 to 0.24212, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.2228 - acc: 0.9203 - val_loss: 0.2421 - val_acc: 0.9163\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9224\n",
      "Epoch 00005: val_loss did not improve from 0.24212\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.2179 - acc: 0.9224 - val_loss: 0.2427 - val_acc: 0.9124\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9252\n",
      "Epoch 00006: val_loss improved from 0.24212 to 0.24209, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 54ms/step - loss: 0.2136 - acc: 0.9252 - val_loss: 0.2421 - val_acc: 0.9153\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9253\n",
      "Epoch 00007: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2099 - acc: 0.9253 - val_loss: 0.2430 - val_acc: 0.9139\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9275\n",
      "Epoch 00008: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.2057 - acc: 0.9274 - val_loss: 0.2437 - val_acc: 0.9158\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9271\n",
      "Epoch 00009: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2034 - acc: 0.9271 - val_loss: 0.2425 - val_acc: 0.9187\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2008 - acc: 0.9290\n",
      "Epoch 00010: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2007 - acc: 0.9290 - val_loss: 0.2441 - val_acc: 0.9148\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9298\n",
      "Epoch 00011: val_loss did not improve from 0.24209\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1966 - acc: 0.9298 - val_loss: 0.2444 - val_acc: 0.9148\n",
      "auc0.8750425676575356, auprc0.5750538603058505, acc0.9124910093502757, F10.4687045123726346 \n",
      "0.8750425676575356 0.5750538603058505 0.9124910093502757 0.4687045123726346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.9275\n",
      "Epoch 00001: val_loss improved from inf to 0.19064, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 57ms/step - loss: 0.2409 - acc: 0.9275 - val_loss: 0.1906 - val_acc: 0.9411\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1841 - acc: 0.9439\n",
      "Epoch 00002: val_loss improved from 0.19064 to 0.18400, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1841 - acc: 0.9439 - val_loss: 0.1840 - val_acc: 0.9435\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9438\n",
      "Epoch 00003: val_loss improved from 0.18400 to 0.17986, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1719 - acc: 0.9438 - val_loss: 0.1799 - val_acc: 0.9416\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9468\n",
      "Epoch 00004: val_loss did not improve from 0.17986\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1651 - acc: 0.9467 - val_loss: 0.1808 - val_acc: 0.9378\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1590 - acc: 0.9494\n",
      "Epoch 00005: val_loss improved from 0.17986 to 0.17908, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1590 - acc: 0.9494 - val_loss: 0.1791 - val_acc: 0.9402\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9503\n",
      "Epoch 00006: val_loss improved from 0.17908 to 0.17813, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1551 - acc: 0.9502 - val_loss: 0.1781 - val_acc: 0.9392\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9515\n",
      "Epoch 00007: val_loss did not improve from 0.17813\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1509 - acc: 0.9515 - val_loss: 0.1791 - val_acc: 0.9407\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1483 - acc: 0.9520- ETA: 5s \n",
      "Epoch 00008: val_loss did not improve from 0.17813\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1483 - acc: 0.9520 - val_loss: 0.1789 - val_acc: 0.9402\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9522\n",
      "Epoch 00009: val_loss did not improve from 0.17813\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1459 - acc: 0.9521 - val_loss: 0.1787 - val_acc: 0.9388\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9521\n",
      "Epoch 00010: val_loss did not improve from 0.17813\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1440 - acc: 0.9520 - val_loss: 0.1788 - val_acc: 0.9388\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9534\n",
      "Epoch 00011: val_loss did not improve from 0.17813\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1415 - acc: 0.9534 - val_loss: 0.1801 - val_acc: 0.9392\n",
      "auc0.8835584964617222, auprc0.521024574582518, acc0.9395828338527931, F10.46153846153846156 \n",
      "0.8835584964617222 0.521024574582518 0.9395828338527931 0.46153846153846156\n",
      "Iteration number:  4\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.9034\n",
      "Epoch 00001: val_loss improved from inf to 0.24752, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 56ms/step - loss: 0.2891 - acc: 0.9034 - val_loss: 0.2475 - val_acc: 0.9187\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.9164\n",
      "Epoch 00002: val_loss improved from 0.24752 to 0.24048, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2429 - acc: 0.9164 - val_loss: 0.2405 - val_acc: 0.9172\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9191- E\n",
      "Epoch 00003: val_loss did not improve from 0.24048\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2289 - acc: 0.9191 - val_loss: 0.2426 - val_acc: 0.9139\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9236\n",
      "Epoch 00004: val_loss did not improve from 0.24048\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2202 - acc: 0.9234 - val_loss: 0.2416 - val_acc: 0.9158\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2142 - acc: 0.9251\n",
      "Epoch 00005: val_loss improved from 0.24048 to 0.23928, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2141 - acc: 0.9251 - val_loss: 0.2393 - val_acc: 0.9187\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9264\n",
      "Epoch 00006: val_loss did not improve from 0.23928\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2094 - acc: 0.9264 - val_loss: 0.2420 - val_acc: 0.9148\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9277\n",
      "Epoch 00007: val_loss did not improve from 0.23928\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2049 - acc: 0.9277 - val_loss: 0.2406 - val_acc: 0.9177\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2012 - acc: 0.9297\n",
      "Epoch 00008: val_loss did not improve from 0.23928\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2013 - acc: 0.9297 - val_loss: 0.2422 - val_acc: 0.9124\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9301\n",
      "Epoch 00009: val_loss did not improve from 0.23928\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1999 - acc: 0.9301 - val_loss: 0.2419 - val_acc: 0.9167\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1961 - acc: 0.9304\n",
      "Epoch 00010: val_loss did not improve from 0.23928\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1961 - acc: 0.9304 - val_loss: 0.2405 - val_acc: 0.9158\n",
      "auc0.8740539374935928, auprc0.5813201384795856, acc0.9148885159434188, F10.44617784711388453 \n",
      "0.8740539374935928 0.5813201384795856 0.9148885159434188 0.44617784711388453\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2309 - acc: 0.9303- ETA: 1s - loss: 0\n",
      "Epoch 00001: val_loss improved from inf to 0.18810, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 58ms/step - loss: 0.2309 - acc: 0.9303 - val_loss: 0.1881 - val_acc: 0.9431\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9436\n",
      "Epoch 00002: val_loss improved from 0.18810 to 0.17809, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1818 - acc: 0.9436 - val_loss: 0.1781 - val_acc: 0.9426\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9459- ETA: 3s \n",
      "Epoch 00003: val_loss improved from 0.17809 to 0.17557, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 59ms/step - loss: 0.1700 - acc: 0.9459 - val_loss: 0.1756 - val_acc: 0.9421\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9473\n",
      "Epoch 00004: val_loss did not improve from 0.17557\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1620 - acc: 0.9473 - val_loss: 0.1774 - val_acc: 0.9392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1580 - acc: 0.9467\n",
      "Epoch 00005: val_loss improved from 0.17557 to 0.17547, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1580 - acc: 0.9467 - val_loss: 0.1755 - val_acc: 0.9440\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9488\n",
      "Epoch 00006: val_loss did not improve from 0.17547\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1540 - acc: 0.9488 - val_loss: 0.1756 - val_acc: 0.9431\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9518\n",
      "Epoch 00007: val_loss did not improve from 0.17547\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1492 - acc: 0.9517 - val_loss: 0.1768 - val_acc: 0.9431\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9499- ETA: 0s - loss: 0.1477 -\n",
      "Epoch 00008: val_loss did not improve from 0.17547\n",
      "230/230 [==============================] - 14s 59ms/step - loss: 0.1471 - acc: 0.9499 - val_loss: 0.1764 - val_acc: 0.9431\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9514\n",
      "Epoch 00009: val_loss improved from 0.17547 to 0.17514, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1457 - acc: 0.9514 - val_loss: 0.1751 - val_acc: 0.9416\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9539- ETA: 0s - loss: 0.1416 - acc: 0.953\n",
      "Epoch 00010: val_loss did not improve from 0.17514\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1419 - acc: 0.9538 - val_loss: 0.1772 - val_acc: 0.9407\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9529- ETA\n",
      "Epoch 00011: val_loss did not improve from 0.17514\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1399 - acc: 0.9529 - val_loss: 0.1793 - val_acc: 0.9402\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1400 - acc: 0.9519\n",
      "Epoch 00012: val_loss did not improve from 0.17514\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1400 - acc: 0.9519 - val_loss: 0.1781 - val_acc: 0.9407\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9540\n",
      "Epoch 00013: val_loss did not improve from 0.17514\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1370 - acc: 0.9540 - val_loss: 0.1768 - val_acc: 0.9411\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1365 - acc: 0.9539\n",
      "Epoch 00014: val_loss did not improve from 0.17514\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1365 - acc: 0.9539 - val_loss: 0.1790 - val_acc: 0.9411\n",
      "auc0.8862896959671153, auprc0.521921653139038, acc0.9407815871493647, F10.47109207708779444 \n",
      "0.8862896959671153 0.521921653139038 0.9407815871493647 0.47109207708779444\n",
      "Iteration number:  5\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2852 - acc: 0.9043\n",
      "Epoch 00001: val_loss improved from inf to 0.24498, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 54ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2450 - val_acc: 0.9153\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9169\n",
      "Epoch 00002: val_loss improved from 0.24498 to 0.24147, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2392 - acc: 0.9169 - val_loss: 0.2415 - val_acc: 0.9120\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9200\n",
      "Epoch 00003: val_loss improved from 0.24147 to 0.24007, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2265 - acc: 0.9200 - val_loss: 0.2401 - val_acc: 0.9167\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2187 - acc: 0.9202\n",
      "Epoch 00004: val_loss improved from 0.24007 to 0.23883, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2187 - acc: 0.9203 - val_loss: 0.2388 - val_acc: 0.9177\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9246\n",
      "Epoch 00005: val_loss did not improve from 0.23883\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2119 - acc: 0.9247 - val_loss: 0.2412 - val_acc: 0.9167\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9264\n",
      "Epoch 00006: val_loss did not improve from 0.23883\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2073 - acc: 0.9265 - val_loss: 0.2395 - val_acc: 0.9153\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9262\n",
      "Epoch 00007: val_loss did not improve from 0.23883\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2046 - acc: 0.9262 - val_loss: 0.2392 - val_acc: 0.9144\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9268\n",
      "Epoch 00008: val_loss did not improve from 0.23883\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2008 - acc: 0.9267 - val_loss: 0.2406 - val_acc: 0.9163\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1978 - acc: 0.9285-\n",
      "Epoch 00009: val_loss did not improve from 0.23883\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1978 - acc: 0.9285 - val_loss: 0.2391 - val_acc: 0.9124\n",
      "auc0.8725615654999888, auprc0.5810569247143508, acc0.913450011987533, F10.4619970193740685 \n",
      "0.8725615654999888 0.5810569247143508 0.913450011987533 0.4619970193740685\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9347\n",
      "Epoch 00001: val_loss improved from inf to 0.18067, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 60ms/step - loss: 0.2188 - acc: 0.9347 - val_loss: 0.1807 - val_acc: 0.9445\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9430- ETA: \n",
      "Epoch 00002: val_loss improved from 0.18067 to 0.17430, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.1779 - acc: 0.9431 - val_loss: 0.1743 - val_acc: 0.9445\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9467-  - ETA: 3s - los - ETA: 2s - loss: 0.1663 - acc: 0.946 - ETA: 2s - los - ETA: 0s - loss: 0.1662\n",
      "Epoch 00003: val_loss improved from 0.17430 to 0.17396, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 62ms/step - loss: 0.1673 - acc: 0.9467 - val_loss: 0.1740 - val_acc: 0.9431\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9484\n",
      "Epoch 00004: val_loss did not improve from 0.17396\n",
      "230/230 [==============================] - 14s 63ms/step - loss: 0.1593 - acc: 0.9484 - val_loss: 0.1746 - val_acc: 0.9426\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9489\n",
      "Epoch 00005: val_loss improved from 0.17396 to 0.17256, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.1538 - acc: 0.9489 - val_loss: 0.1726 - val_acc: 0.9426\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9507\n",
      "Epoch 00006: val_loss did not improve from 0.17256\n",
      "230/230 [==============================] - 13s 59ms/step - loss: 0.1506 - acc: 0.9507 - val_loss: 0.1738 - val_acc: 0.9421\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9505\n",
      "Epoch 00007: val_loss did not improve from 0.17256\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1480 - acc: 0.9506 - val_loss: 0.1729 - val_acc: 0.9402\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9503\n",
      "Epoch 00008: val_loss did not improve from 0.17256\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1432 - acc: 0.9504 - val_loss: 0.1733 - val_acc: 0.9426\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9519\n",
      "Epoch 00009: val_loss did not improve from 0.17256\n",
      "230/230 [==============================] - 13s 59ms/step - loss: 0.1422 - acc: 0.9519 - val_loss: 0.1753 - val_acc: 0.9421\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9527\n",
      "Epoch 00010: val_loss did not improve from 0.17256\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1409 - acc: 0.9527 - val_loss: 0.1739 - val_acc: 0.9421\n",
      "auc0.8846630072436523, auprc0.520144497915537, acc0.9398225845121074, F10.4434589800443459 \n",
      "0.8846630072436523 0.520144497915537 0.9398225845121074 0.4434589800443459\n",
      "Iteration number:  6\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2901 - acc: 0.9023\n",
      "Epoch 00001: val_loss improved from inf to 0.25035, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 60ms/step - loss: 0.2900 - acc: 0.9023 - val_loss: 0.2504 - val_acc: 0.9167\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9146\n",
      "Epoch 00002: val_loss improved from 0.25035 to 0.24468, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.2430 - acc: 0.9146 - val_loss: 0.2447 - val_acc: 0.9163\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2274 - acc: 0.9202\n",
      "Epoch 00003: val_loss did not improve from 0.24468\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2275 - acc: 0.9202 - val_loss: 0.2468 - val_acc: 0.9148\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9232\n",
      "Epoch 00004: val_loss improved from 0.24468 to 0.24075, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2194 - acc: 0.9233 - val_loss: 0.2408 - val_acc: 0.9139\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2136 - acc: 0.9242\n",
      "Epoch 00005: val_loss did not improve from 0.24075\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2136 - acc: 0.9242 - val_loss: 0.2424 - val_acc: 0.9191\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2083 - acc: 0.9259\n",
      "Epoch 00006: val_loss did not improve from 0.24075\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2082 - acc: 0.9259 - val_loss: 0.2429 - val_acc: 0.9129\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9275\n",
      "Epoch 00007: val_loss improved from 0.24075 to 0.24052, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2059 - acc: 0.9276 - val_loss: 0.2405 - val_acc: 0.9148\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2024 - acc: 0.9283- ETA\n",
      "Epoch 00008: val_loss did not improve from 0.24052\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2024 - acc: 0.9283 - val_loss: 0.2412 - val_acc: 0.9134\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1993 - acc: 0.9289\n",
      "Epoch 00009: val_loss did not improve from 0.24052\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1993 - acc: 0.9289 - val_loss: 0.2431 - val_acc: 0.9139\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9301\n",
      "Epoch 00010: val_loss did not improve from 0.24052\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1955 - acc: 0.9301 - val_loss: 0.2426 - val_acc: 0.9144\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9299\n",
      "Epoch 00011: val_loss did not improve from 0.24052\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1934 - acc: 0.9299 - val_loss: 0.2427 - val_acc: 0.9139\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9316\n",
      "Epoch 00012: val_loss did not improve from 0.24052\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1915 - acc: 0.9316 - val_loss: 0.2429 - val_acc: 0.9163\n",
      "auc0.876127232813566, auprc0.5857612520282606, acc0.9127307600095901, F10.47851002865329506 \n",
      "0.876127232813566 0.5857612520282606 0.9127307600095901 0.47851002865329506\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2343 - acc: 0.9272\n",
      "Epoch 00001: val_loss improved from inf to 0.18620, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 57ms/step - loss: 0.2343 - acc: 0.9272 - val_loss: 0.1862 - val_acc: 0.9431\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1859 - acc: 0.9423\n",
      "Epoch 00002: val_loss improved from 0.18620 to 0.17925, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1859 - acc: 0.9423 - val_loss: 0.1792 - val_acc: 0.9421\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9443\n",
      "Epoch 00003: val_loss improved from 0.17925 to 0.17885, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1722 - acc: 0.9444 - val_loss: 0.1788 - val_acc: 0.9402\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1637 - acc: 0.9460\n",
      "Epoch 00004: val_loss did not improve from 0.17885\n",
      "230/230 [==============================] - 13s 54ms/step - loss: 0.1637 - acc: 0.9460 - val_loss: 0.1793 - val_acc: 0.9402\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9487\n",
      "Epoch 00005: val_loss improved from 0.17885 to 0.17780, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1590 - acc: 0.9487 - val_loss: 0.1778 - val_acc: 0.9435\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1536 - acc: 0.9503\n",
      "Epoch 00006: val_loss improved from 0.17780 to 0.17765, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1536 - acc: 0.9503 - val_loss: 0.1777 - val_acc: 0.9421\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9505\n",
      "Epoch 00007: val_loss did not improve from 0.17765\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1495 - acc: 0.9505 - val_loss: 0.1780 - val_acc: 0.9421\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9518\n",
      "Epoch 00008: val_loss did not improve from 0.17765\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1473 - acc: 0.9518 - val_loss: 0.1793 - val_acc: 0.9426\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9513\n",
      "Epoch 00009: val_loss did not improve from 0.17765\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1432 - acc: 0.9512 - val_loss: 0.1788 - val_acc: 0.9426\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9530\n",
      "Epoch 00010: val_loss did not improve from 0.17765\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1415 - acc: 0.9530 - val_loss: 0.1794 - val_acc: 0.9426\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9528\n",
      "Epoch 00011: val_loss did not improve from 0.17765\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1388 - acc: 0.9528 - val_loss: 0.1787 - val_acc: 0.9431\n",
      "auc0.8839035516454872, auprc0.5195280266542648, acc0.9415008391273076, F10.46017699115044247 \n",
      "0.8839035516454872 0.5195280266542648 0.9415008391273076 0.46017699115044247\n",
      "Iteration number:  7\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2976 - acc: 0.8977\n",
      "Epoch 00001: val_loss improved from inf to 0.24582, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 59ms/step - loss: 0.2975 - acc: 0.8978 - val_loss: 0.2458 - val_acc: 0.9139\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2423 - acc: 0.9131\n",
      "Epoch 00002: val_loss improved from 0.24582 to 0.24176, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2423 - acc: 0.9131 - val_loss: 0.2418 - val_acc: 0.9144\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9217\n",
      "Epoch 00003: val_loss improved from 0.24176 to 0.23882, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2295 - acc: 0.9217 - val_loss: 0.2388 - val_acc: 0.9139\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2209 - acc: 0.9216\n",
      "Epoch 00004: val_loss did not improve from 0.23882\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2208 - acc: 0.9217 - val_loss: 0.2413 - val_acc: 0.9153\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2155 - acc: 0.9242\n",
      "Epoch 00005: val_loss did not improve from 0.23882\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 0.2155 - acc: 0.9242 - val_loss: 0.2411 - val_acc: 0.9129\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9252\n",
      "Epoch 00006: val_loss did not improve from 0.23882\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2100 - acc: 0.9253 - val_loss: 0.2427 - val_acc: 0.9163\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9260\n",
      "Epoch 00007: val_loss did not improve from 0.23882\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2055 - acc: 0.9260 - val_loss: 0.2405 - val_acc: 0.9153\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.928 - ETA: 0s - loss: 0.2039 - acc: 0.9284\n",
      "Epoch 00008: val_loss did not improve from 0.23882\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2039 - acc: 0.9284 - val_loss: 0.2420 - val_acc: 0.9148\n",
      "auc0.8740922336560817, auprc0.5745144269230011, acc0.9141692639654759, F10.47507331378299117 \n",
      "0.8740922336560817 0.5745144269230011 0.9141692639654759 0.47507331378299117\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2246 - acc: 0.9326\n",
      "Epoch 00001: val_loss improved from inf to 0.18502, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 51ms/step - loss: 0.2246 - acc: 0.9326 - val_loss: 0.1850 - val_acc: 0.9431\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1795 - acc: 0.9432\n",
      "Epoch 00002: val_loss improved from 0.18502 to 0.17738, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1795 - acc: 0.9432 - val_loss: 0.1774 - val_acc: 0.9445\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9454\n",
      "Epoch 00003: val_loss improved from 0.17738 to 0.17675, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1684 - acc: 0.9453 - val_loss: 0.1767 - val_acc: 0.9445\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1619 - acc: 0.9473\n",
      "Epoch 00004: val_loss improved from 0.17675 to 0.17666, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1619 - acc: 0.9473 - val_loss: 0.1767 - val_acc: 0.9435\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1569 - acc: 0.9474\n",
      "Epoch 00005: val_loss improved from 0.17666 to 0.17443, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1569 - acc: 0.9474 - val_loss: 0.1744 - val_acc: 0.9440\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9490- ETA: 0s - loss: 0.1511 - acc: 0.\n",
      "Epoch 00006: val_loss did not improve from 0.17443\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1514 - acc: 0.9489 - val_loss: 0.1769 - val_acc: 0.9435\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9508\n",
      "Epoch 00007: val_loss did not improve from 0.17443\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1490 - acc: 0.9508 - val_loss: 0.1769 - val_acc: 0.9426\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9514\n",
      "Epoch 00008: val_loss did not improve from 0.17443\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1447 - acc: 0.9514 - val_loss: 0.1773 - val_acc: 0.9440\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9518\n",
      "Epoch 00009: val_loss did not improve from 0.17443\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1423 - acc: 0.9519 - val_loss: 0.1779 - val_acc: 0.9431\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9527- ETA:\n",
      "Epoch 00010: val_loss did not improve from 0.17443\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1401 - acc: 0.9527 - val_loss: 0.1778 - val_acc: 0.9416\n",
      "auc0.8854989096924581, auprc0.5255509024311901, acc0.9400623351714217, F10.4343891402714932 \n",
      "0.8854989096924581 0.5255509024311901 0.9400623351714217 0.4343891402714932\n",
      "Iteration number:  8\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.8994\n",
      "Epoch 00001: val_loss improved from inf to 0.24997, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 53ms/step - loss: 0.2984 - acc: 0.8994 - val_loss: 0.2500 - val_acc: 0.9134\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2454 - acc: 0.9151\n",
      "Epoch 00002: val_loss improved from 0.24997 to 0.24110, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2454 - acc: 0.9150 - val_loss: 0.2411 - val_acc: 0.9172\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2308 - acc: 0.9199\n",
      "Epoch 00003: val_loss did not improve from 0.24110\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2308 - acc: 0.9199 - val_loss: 0.2418 - val_acc: 0.9196\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.9215\n",
      "Epoch 00004: val_loss did not improve from 0.24110\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.2216 - acc: 0.9214 - val_loss: 0.2438 - val_acc: 0.9158\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9232\n",
      "Epoch 00005: val_loss did not improve from 0.24110\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2167 - acc: 0.9233 - val_loss: 0.2421 - val_acc: 0.9158\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9249\n",
      "Epoch 00006: val_loss improved from 0.24110 to 0.24107, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 11s 47ms/step - loss: 0.2105 - acc: 0.9249 - val_loss: 0.2411 - val_acc: 0.9144\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9267\n",
      "Epoch 00007: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2074 - acc: 0.9268 - val_loss: 0.2426 - val_acc: 0.9153\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9279\n",
      "Epoch 00008: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2039 - acc: 0.9279 - val_loss: 0.2416 - val_acc: 0.9148\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2009 - acc: 0.9286\n",
      "Epoch 00009: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2009 - acc: 0.9286 - val_loss: 0.2425 - val_acc: 0.9148\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1987 - acc: 0.9292\n",
      "Epoch 00010: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1987 - acc: 0.9292 - val_loss: 0.2423 - val_acc: 0.9144\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9302\n",
      "Epoch 00011: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1955 - acc: 0.9302 - val_loss: 0.2435 - val_acc: 0.9139\n",
      "auc0.8792604480768845, auprc0.5822405616812281, acc0.9127307600095901, F10.47246376811594204 \n",
      "0.8792604480768845 0.5822405616812281 0.9127307600095901 0.47246376811594204\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2185 - acc: 0.9341- ETA: 1s - loss\n",
      "Epoch 00001: val_loss improved from inf to 0.18341, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 51ms/step - loss: 0.2186 - acc: 0.9341 - val_loss: 0.1834 - val_acc: 0.9445\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9417- ETA: 2s - \n",
      "Epoch 00002: val_loss improved from 0.18341 to 0.17691, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1808 - acc: 0.9418 - val_loss: 0.1769 - val_acc: 0.9440\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9455\n",
      "Epoch 00003: val_loss did not improve from 0.17691\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1684 - acc: 0.9455 - val_loss: 0.1779 - val_acc: 0.9426\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9468\n",
      "Epoch 00004: val_loss improved from 0.17691 to 0.17356, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1615 - acc: 0.9469 - val_loss: 0.1736 - val_acc: 0.9440\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1556 - acc: 0.9498- ETA: 0s - loss: 0.1556 - \n",
      "Epoch 00005: val_loss did not improve from 0.17356\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1556 - acc: 0.9498 - val_loss: 0.1745 - val_acc: 0.9435\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9506\n",
      "Epoch 00006: val_loss did not improve from 0.17356\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1510 - acc: 0.9506 - val_loss: 0.1747 - val_acc: 0.9435\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9505\n",
      "Epoch 00007: val_loss did not improve from 0.17356\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1482 - acc: 0.9505 - val_loss: 0.1757 - val_acc: 0.9416\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1442 - acc: 0.9532\n",
      "Epoch 00008: val_loss did not improve from 0.17356\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1442 - acc: 0.9532 - val_loss: 0.1744 - val_acc: 0.9445\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9528\n",
      "Epoch 00009: val_loss did not improve from 0.17356\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1434 - acc: 0.9527 - val_loss: 0.1748 - val_acc: 0.9431\n",
      "auc0.8819150980441304, auprc0.5200451035532021, acc0.9393430831934788, F10.4236902050113895 \n",
      "0.8819150980441304 0.5200451035532021 0.9393430831934788 0.4236902050113895\n",
      "Iteration number:  9\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.9050\n",
      "Epoch 00001: val_loss improved from inf to 0.24709, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 54ms/step - loss: 0.2888 - acc: 0.9051 - val_loss: 0.2471 - val_acc: 0.9163\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9179\n",
      "Epoch 00002: val_loss improved from 0.24709 to 0.24010, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.2425 - acc: 0.9180 - val_loss: 0.2401 - val_acc: 0.9158\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9212\n",
      "Epoch 00003: val_loss did not improve from 0.24010\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2290 - acc: 0.9211 - val_loss: 0.2433 - val_acc: 0.9144\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9223\n",
      "Epoch 00004: val_loss improved from 0.24010 to 0.23852, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2191 - acc: 0.9222 - val_loss: 0.2385 - val_acc: 0.9158\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2141 - acc: 0.9236\n",
      "Epoch 00005: val_loss did not improve from 0.23852\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2141 - acc: 0.9236 - val_loss: 0.2386 - val_acc: 0.9134\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9261\n",
      "Epoch 00006: val_loss did not improve from 0.23852\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2097 - acc: 0.9262 - val_loss: 0.2387 - val_acc: 0.9153\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9266\n",
      "Epoch 00007: val_loss did not improve from 0.23852\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2054 - acc: 0.9266 - val_loss: 0.2394 - val_acc: 0.9120\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9288\n",
      "Epoch 00008: val_loss did not improve from 0.23852\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2025 - acc: 0.9288 - val_loss: 0.2392 - val_acc: 0.9167\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1982 - acc: 0.9289\n",
      "Epoch 00009: val_loss did not improve from 0.23852\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1982 - acc: 0.9289 - val_loss: 0.2392 - val_acc: 0.9129\n",
      "auc0.8762403537858408, auprc0.5746480039402522, acc0.9127307600095901, F10.4434250764525993 \n",
      "0.8762403537858408 0.5746480039402522 0.9127307600095901 0.4434250764525993\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9319- ETA: 3s  - ETA: 1s - loss\n",
      "Epoch 00001: val_loss improved from inf to 0.18120, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 18s 69ms/step - loss: 0.2257 - acc: 0.9319 - val_loss: 0.1812 - val_acc: 0.9440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9427\n",
      "Epoch 00002: val_loss improved from 0.18120 to 0.17459, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1809 - acc: 0.9427 - val_loss: 0.1746 - val_acc: 0.9450\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9460\n",
      "Epoch 00003: val_loss improved from 0.17459 to 0.17424, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1678 - acc: 0.9460 - val_loss: 0.1742 - val_acc: 0.9383\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9473\n",
      "Epoch 00004: val_loss improved from 0.17424 to 0.17266, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1615 - acc: 0.9473 - val_loss: 0.1727 - val_acc: 0.9416\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1554 - acc: 0.9495\n",
      "Epoch 00005: val_loss did not improve from 0.17266\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1554 - acc: 0.9495 - val_loss: 0.1727 - val_acc: 0.9440\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9487\n",
      "Epoch 00006: val_loss improved from 0.17266 to 0.17252, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1524 - acc: 0.9487 - val_loss: 0.1725 - val_acc: 0.9407\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9503\n",
      "Epoch 00007: val_loss did not improve from 0.17252\n",
      "230/230 [==============================] - 14s 59ms/step - loss: 0.1495 - acc: 0.9503 - val_loss: 0.1735 - val_acc: 0.9450\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9514\n",
      "Epoch 00008: val_loss did not improve from 0.17252\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1455 - acc: 0.9514 - val_loss: 0.1739 - val_acc: 0.9407\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9514\n",
      "Epoch 00009: val_loss did not improve from 0.17252\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1443 - acc: 0.9513 - val_loss: 0.1743 - val_acc: 0.9431\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9525\n",
      "Epoch 00010: val_loss did not improve from 0.17252\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1411 - acc: 0.9525 - val_loss: 0.1745 - val_acc: 0.9431\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9539\n",
      "Epoch 00011: val_loss did not improve from 0.17252\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1386 - acc: 0.9538 - val_loss: 0.1747 - val_acc: 0.9426\n",
      "auc0.8858067858067858, auprc0.5303013283266627, acc0.9424598417645649, F10.4642857142857143 \n",
      "0.8858067858067858 0.5303013283266627 0.9424598417645649 0.4642857142857143\n",
      "Iteration number:  10\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2925 - acc: 0.9021\n",
      "Epoch 00001: val_loss improved from inf to 0.24438, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 52ms/step - loss: 0.2925 - acc: 0.9021 - val_loss: 0.2444 - val_acc: 0.9153\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2436 - acc: 0.9141- ETA: \n",
      "Epoch 00002: val_loss improved from 0.24438 to 0.24121, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2436 - acc: 0.9141 - val_loss: 0.2412 - val_acc: 0.9120\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2322 - acc: 0.9186\n",
      "Epoch 00003: val_loss did not improve from 0.24121\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2322 - acc: 0.9186 - val_loss: 0.2418 - val_acc: 0.9100\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2246 - acc: 0.9201\n",
      "Epoch 00004: val_loss improved from 0.24121 to 0.23632, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2246 - acc: 0.9201 - val_loss: 0.2363 - val_acc: 0.9163\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2168 - acc: 0.9225\n",
      "Epoch 00005: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2168 - acc: 0.9225 - val_loss: 0.2397 - val_acc: 0.9167\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9248- \n",
      "Epoch 00006: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2114 - acc: 0.9247 - val_loss: 0.2372 - val_acc: 0.9158\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9272\n",
      "Epoch 00007: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2068 - acc: 0.9272 - val_loss: 0.2376 - val_acc: 0.9163\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2051 - acc: 0.9267- ETA: 0s - loss: 0.2044 - acc\n",
      "Epoch 00008: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2051 - acc: 0.9267 - val_loss: 0.2382 - val_acc: 0.9144\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2014 - acc: 0.9266\n",
      "Epoch 00009: val_loss did not improve from 0.23632\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.2014 - acc: 0.9266 - val_loss: 0.2395 - val_acc: 0.9139\n",
      "auc0.8764430288611664, auprc0.5781206743605876, acc0.9168065212179334, F10.48744460856720834 \n",
      "0.8764430288611664 0.5781206743605876 0.9168065212179334 0.48744460856720834\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9367\n",
      "Epoch 00001: val_loss improved from inf to 0.17923, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 16s 59ms/step - loss: 0.2154 - acc: 0.9368 - val_loss: 0.1792 - val_acc: 0.9421\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9425\n",
      "Epoch 00002: val_loss improved from 0.17923 to 0.17585, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1778 - acc: 0.9424 - val_loss: 0.1758 - val_acc: 0.9421\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1660 - acc: 0.9464\n",
      "Epoch 00003: val_loss improved from 0.17585 to 0.17324, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1661 - acc: 0.9463 - val_loss: 0.1732 - val_acc: 0.9455\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1581 - acc: 0.9475\n",
      "Epoch 00004: val_loss improved from 0.17324 to 0.17296, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1581 - acc: 0.9475 - val_loss: 0.1730 - val_acc: 0.9435\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9493\n",
      "Epoch 00005: val_loss did not improve from 0.17296\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.1528 - acc: 0.9493 - val_loss: 0.1752 - val_acc: 0.9402\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9505\n",
      "Epoch 00006: val_loss did not improve from 0.17296\n",
      "230/230 [==============================] - 14s 62ms/step - loss: 0.1497 - acc: 0.9504 - val_loss: 0.1752 - val_acc: 0.9407\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9506\n",
      "Epoch 00007: val_loss did not improve from 0.17296\n",
      "230/230 [==============================] - 14s 59ms/step - loss: 0.1470 - acc: 0.9506 - val_loss: 0.1747 - val_acc: 0.9407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9529\n",
      "Epoch 00008: val_loss did not improve from 0.17296\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1438 - acc: 0.9529 - val_loss: 0.1748 - val_acc: 0.9416\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9522\n",
      "Epoch 00009: val_loss did not improve from 0.17296\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1411 - acc: 0.9523 - val_loss: 0.1748 - val_acc: 0.9411\n",
      "auc0.8867792900050965, auprc0.5236537783635045, acc0.9386238312155358, F10.4410480349344979 \n",
      "0.8867792900050965 0.5236537783635045 0.9386238312155358 0.4410480349344979\n",
      "Embedding:  fasttext\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3057 - acc: 0.8974\n",
      "Epoch 00001: val_loss improved from inf to 0.25184, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 52ms/step - loss: 0.3055 - acc: 0.8975 - val_loss: 0.2518 - val_acc: 0.9096\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2484 - acc: 0.9150\n",
      "Epoch 00002: val_loss improved from 0.25184 to 0.24141, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2483 - acc: 0.9150 - val_loss: 0.2414 - val_acc: 0.9163\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2326 - acc: 0.9181\n",
      "Epoch 00003: val_loss did not improve from 0.24141\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2327 - acc: 0.9181 - val_loss: 0.2447 - val_acc: 0.9144\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2225 - acc: 0.9211\n",
      "Epoch 00004: val_loss improved from 0.24141 to 0.24114, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2224 - acc: 0.9211 - val_loss: 0.2411 - val_acc: 0.9201\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9234\n",
      "Epoch 00005: val_loss did not improve from 0.24114\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2166 - acc: 0.9234 - val_loss: 0.2415 - val_acc: 0.9182\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2122 - acc: 0.9258\n",
      "Epoch 00006: val_loss did not improve from 0.24114\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2122 - acc: 0.9259 - val_loss: 0.2435 - val_acc: 0.9153\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9260\n",
      "Epoch 00007: val_loss did not improve from 0.24114\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2079 - acc: 0.9261 - val_loss: 0.2424 - val_acc: 0.9163\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2050 - acc: 0.9272\n",
      "Epoch 00008: val_loss did not improve from 0.24114\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2050 - acc: 0.9272 - val_loss: 0.2445 - val_acc: 0.9134\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2029 - acc: 0.9274\n",
      "Epoch 00009: val_loss did not improve from 0.24114\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2029 - acc: 0.9274 - val_loss: 0.2436 - val_acc: 0.9144\n",
      "auc0.872895920457103, auprc0.5706784965463418, acc0.9124910093502757, F10.4427480916030534 \n",
      "0.872895920457103 0.5706784965463418 0.9124910093502757 0.4427480916030534\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2170 - acc: 0.9346\n",
      "Epoch 00001: val_loss improved from inf to 0.17835, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 55ms/step - loss: 0.2171 - acc: 0.9345 - val_loss: 0.1784 - val_acc: 0.9450\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9432- ETA: 0s - loss: 0.1792 - acc: 0.943\n",
      "Epoch 00002: val_loss improved from 0.17835 to 0.17825, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1789 - acc: 0.9432 - val_loss: 0.1782 - val_acc: 0.9435\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1652 - acc: 0.9465\n",
      "Epoch 00003: val_loss improved from 0.17825 to 0.17561, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1652 - acc: 0.9465 - val_loss: 0.1756 - val_acc: 0.9416\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9490\n",
      "Epoch 00004: val_loss improved from 0.17561 to 0.17295, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1596 - acc: 0.9490 - val_loss: 0.1730 - val_acc: 0.9440\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9490\n",
      "Epoch 00005: val_loss improved from 0.17295 to 0.17245, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1547 - acc: 0.9489 - val_loss: 0.1724 - val_acc: 0.9426\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9518\n",
      "Epoch 00006: val_loss did not improve from 0.17245\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1505 - acc: 0.9517 - val_loss: 0.1728 - val_acc: 0.9445\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9505- ETA: 1s - l\n",
      "Epoch 00007: val_loss did not improve from 0.17245\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1478 - acc: 0.9506 - val_loss: 0.1734 - val_acc: 0.9426\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9515\n",
      "Epoch 00008: val_loss did not improve from 0.17245\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1453 - acc: 0.9515 - val_loss: 0.1734 - val_acc: 0.9440\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9519\n",
      "Epoch 00009: val_loss did not improve from 0.17245\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1431 - acc: 0.9519 - val_loss: 0.1752 - val_acc: 0.9407\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9520\n",
      "Epoch 00010: val_loss did not improve from 0.17245\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1402 - acc: 0.9521 - val_loss: 0.1744 - val_acc: 0.9407\n",
      "auc0.885537341988955, auprc0.5253375533006456, acc0.9407815871493647, F10.46187363834422657 \n",
      "0.885537341988955 0.5253375533006456 0.9407815871493647 0.46187363834422657\n",
      "Iteration number:  2\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.3002 - acc: 0.8966\n",
      "Epoch 00001: val_loss improved from inf to 0.25232, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 54ms/step - loss: 0.3002 - acc: 0.8966 - val_loss: 0.2523 - val_acc: 0.9153\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2454 - acc: 0.9139\n",
      "Epoch 00002: val_loss improved from 0.25232 to 0.24525, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2455 - acc: 0.9138 - val_loss: 0.2452 - val_acc: 0.9091\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9187\n",
      "Epoch 00003: val_loss improved from 0.24525 to 0.24275, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2313 - acc: 0.9188 - val_loss: 0.2428 - val_acc: 0.9096\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.2219 - acc: 0.9225\n",
      "Epoch 00004: val_loss improved from 0.24275 to 0.24061, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2218 - acc: 0.9225 - val_loss: 0.2406 - val_acc: 0.9115\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9229- ETA: 1s -\n",
      "Epoch 00005: val_loss improved from 0.24061 to 0.23921, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2168 - acc: 0.9229 - val_loss: 0.2392 - val_acc: 0.9163\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9239\n",
      "Epoch 00006: val_loss did not improve from 0.23921\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2118 - acc: 0.9238 - val_loss: 0.2416 - val_acc: 0.9144\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9257\n",
      "Epoch 00007: val_loss did not improve from 0.23921\n",
      "230/230 [==============================] - 13s 54ms/step - loss: 0.2070 - acc: 0.9257 - val_loss: 0.2407 - val_acc: 0.9129\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9277\n",
      "Epoch 00008: val_loss did not improve from 0.23921\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2039 - acc: 0.9277 - val_loss: 0.2393 - val_acc: 0.9124\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9288- ETA: 4s - lo - ETA: 1s - loss: \n",
      "Epoch 00009: val_loss did not improve from 0.23921\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2023 - acc: 0.9287 - val_loss: 0.2410 - val_acc: 0.9105\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9296\n",
      "Epoch 00010: val_loss did not improve from 0.23921\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1982 - acc: 0.9296 - val_loss: 0.2414 - val_acc: 0.9134\n",
      "auc0.8777945888111575, auprc0.5770011748416244, acc0.9122512586909614, F10.4351851851851851 \n",
      "0.8777945888111575 0.5770011748416244 0.9122512586909614 0.4351851851851851\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9273\n",
      "Epoch 00001: val_loss improved from inf to 0.18436, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 52ms/step - loss: 0.2355 - acc: 0.9273 - val_loss: 0.1844 - val_acc: 0.9411\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1845 - acc: 0.9431\n",
      "Epoch 00002: val_loss improved from 0.18436 to 0.17932, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1845 - acc: 0.9431 - val_loss: 0.1793 - val_acc: 0.9411\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9453\n",
      "Epoch 00003: val_loss improved from 0.17932 to 0.17628, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1721 - acc: 0.9452 - val_loss: 0.1763 - val_acc: 0.9445\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1627 - acc: 0.9477\n",
      "Epoch 00004: val_loss did not improve from 0.17628\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1627 - acc: 0.9477 - val_loss: 0.1768 - val_acc: 0.9445\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1587 - acc: 0.9485\n",
      "Epoch 00005: val_loss did not improve from 0.17628\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1587 - acc: 0.9485 - val_loss: 0.1765 - val_acc: 0.9435\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1542 - acc: 0.9490\n",
      "Epoch 00006: val_loss improved from 0.17628 to 0.17614, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1541 - acc: 0.9491 - val_loss: 0.1761 - val_acc: 0.9411\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9501\n",
      "Epoch 00007: val_loss did not improve from 0.17614\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1501 - acc: 0.9501 - val_loss: 0.1763 - val_acc: 0.9431\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9518\n",
      "Epoch 00008: val_loss improved from 0.17614 to 0.17601, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1471 - acc: 0.9518 - val_loss: 0.1760 - val_acc: 0.9426\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9518\n",
      "Epoch 00009: val_loss did not improve from 0.17601\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1448 - acc: 0.9518 - val_loss: 0.1788 - val_acc: 0.9402\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1431 - acc: 0.9507\n",
      "Epoch 00010: val_loss did not improve from 0.17601\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1431 - acc: 0.9507 - val_loss: 0.1770 - val_acc: 0.9426\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9522\n",
      "Epoch 00011: val_loss did not improve from 0.17601\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1403 - acc: 0.9521 - val_loss: 0.1785 - val_acc: 0.9416\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9533- ETA:\n",
      "Epoch 00012: val_loss did not improve from 0.17601\n",
      "230/230 [==============================] - 14s 59ms/step - loss: 0.1391 - acc: 0.9532 - val_loss: 0.1784 - val_acc: 0.9426\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9534\n",
      "Epoch 00013: val_loss did not improve from 0.17601\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1368 - acc: 0.9534 - val_loss: 0.1781 - val_acc: 0.9431\n",
      "auc0.8887121838734743, auprc0.5319782077208225, acc0.9405418364900503, F10.46086956521739125 \n",
      "0.8887121838734743 0.5319782077208225 0.9405418364900503 0.46086956521739125\n",
      "Iteration number:  3\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2927 - acc: 0.9023\n",
      "Epoch 00001: val_loss improved from inf to 0.24937, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 58ms/step - loss: 0.2927 - acc: 0.9024 - val_loss: 0.2494 - val_acc: 0.9139\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9151\n",
      "Epoch 00002: val_loss improved from 0.24937 to 0.24470, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2455 - acc: 0.9150 - val_loss: 0.2447 - val_acc: 0.9172\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9190\n",
      "Epoch 00003: val_loss improved from 0.24470 to 0.23883, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2308 - acc: 0.9191 - val_loss: 0.2388 - val_acc: 0.9144\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9245\n",
      "Epoch 00004: val_loss did not improve from 0.23883\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2183 - acc: 0.9244 - val_loss: 0.2437 - val_acc: 0.9134\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9242\n",
      "Epoch 00005: val_loss did not improve from 0.23883\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.2145 - acc: 0.9242 - val_loss: 0.2393 - val_acc: 0.9167\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9244- ETA: 0s - loss: 0.2081 - acc\n",
      "Epoch 00006: val_loss improved from 0.23883 to 0.23867, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.2100 - acc: 0.9244 - val_loss: 0.2387 - val_acc: 0.9163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2055 - acc: 0.9272\n",
      "Epoch 00007: val_loss improved from 0.23867 to 0.23854, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2055 - acc: 0.9272 - val_loss: 0.2385 - val_acc: 0.9110\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9286\n",
      "Epoch 00008: val_loss did not improve from 0.23854\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2026 - acc: 0.9285 - val_loss: 0.2403 - val_acc: 0.9110\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2000 - acc: 0.9298\n",
      "Epoch 00009: val_loss did not improve from 0.23854\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.2000 - acc: 0.9298 - val_loss: 0.2401 - val_acc: 0.9110\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1981 - acc: 0.9295\n",
      "Epoch 00010: val_loss did not improve from 0.23854\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 0.1981 - acc: 0.9295 - val_loss: 0.2390 - val_acc: 0.9148\n",
      "Epoch 11/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1949 - acc: 0.9298\n",
      "Epoch 00011: val_loss did not improve from 0.23854\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1949 - acc: 0.9298 - val_loss: 0.2420 - val_acc: 0.9124\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9307\n",
      "Epoch 00012: val_loss did not improve from 0.23854\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1932 - acc: 0.9308 - val_loss: 0.2395 - val_acc: 0.9129\n",
      "auc0.8783165949644671, auprc0.5902143209158961, acc0.9141692639654759, F10.49147727272727276 \n",
      "0.8783165949644671 0.5902143209158961 0.9141692639654759 0.49147727272727276\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2300 - acc: 0.9321\n",
      "Epoch 00001: val_loss improved from inf to 0.17952, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 54ms/step - loss: 0.2300 - acc: 0.9321 - val_loss: 0.1795 - val_acc: 0.9411\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9434\n",
      "Epoch 00002: val_loss did not improve from 0.17952\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1816 - acc: 0.9434 - val_loss: 0.1806 - val_acc: 0.9421\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9462\n",
      "Epoch 00003: val_loss improved from 0.17952 to 0.17881, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1697 - acc: 0.9462 - val_loss: 0.1788 - val_acc: 0.9421\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9481\n",
      "Epoch 00004: val_loss improved from 0.17881 to 0.17504, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1617 - acc: 0.9480 - val_loss: 0.1750 - val_acc: 0.9421\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9486\n",
      "Epoch 00005: val_loss did not improve from 0.17504\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1572 - acc: 0.9485 - val_loss: 0.1759 - val_acc: 0.9402\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9497\n",
      "Epoch 00006: val_loss did not improve from 0.17504\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1526 - acc: 0.9497 - val_loss: 0.1751 - val_acc: 0.9421\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9514\n",
      "Epoch 00007: val_loss did not improve from 0.17504\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1484 - acc: 0.9514 - val_loss: 0.1768 - val_acc: 0.9440\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9507\n",
      "Epoch 00008: val_loss did not improve from 0.17504\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1461 - acc: 0.9507 - val_loss: 0.1772 - val_acc: 0.9426\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9524\n",
      "Epoch 00009: val_loss did not improve from 0.17504\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1427 - acc: 0.9524 - val_loss: 0.1774 - val_acc: 0.9435\n",
      "auc0.8827906860164924, auprc0.5160630352131571, acc0.9407815871493647, F10.42691415313225056 \n",
      "0.8827906860164924 0.5160630352131571 0.9407815871493647 0.42691415313225056\n",
      "Iteration number:  4\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2879 - acc: 0.9031\n",
      "Epoch 00001: val_loss improved from inf to 0.25665, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 56ms/step - loss: 0.2879 - acc: 0.9031 - val_loss: 0.2567 - val_acc: 0.9115\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2451 - acc: 0.9133\n",
      "Epoch 00002: val_loss improved from 0.25665 to 0.24513, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2451 - acc: 0.9133 - val_loss: 0.2451 - val_acc: 0.9177\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2298 - acc: 0.9189- ETA: 0s - loss: 0.2291 - acc: 0.\n",
      "Epoch 00003: val_loss improved from 0.24513 to 0.24185, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2298 - acc: 0.9189 - val_loss: 0.2418 - val_acc: 0.9163\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2227 - acc: 0.9217- ETA: 5s - loss: 0.2\n",
      "Epoch 00004: val_loss did not improve from 0.24185\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2227 - acc: 0.9217 - val_loss: 0.2445 - val_acc: 0.9124\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2161 - acc: 0.9233- ETA: 2s - \n",
      "Epoch 00005: val_loss did not improve from 0.24185\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 0.2161 - acc: 0.9233 - val_loss: 0.2421 - val_acc: 0.9167\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2106 - acc: 0.9257\n",
      "Epoch 00006: val_loss did not improve from 0.24185\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 0.2106 - acc: 0.9257 - val_loss: 0.2422 - val_acc: 0.9148\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2082 - acc: 0.9261\n",
      "Epoch 00007: val_loss improved from 0.24185 to 0.24048, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2081 - acc: 0.9262 - val_loss: 0.2405 - val_acc: 0.9182\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2035 - acc: 0.9273\n",
      "Epoch 00008: val_loss did not improve from 0.24048\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2035 - acc: 0.9273 - val_loss: 0.2422 - val_acc: 0.9163\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2011 - acc: 0.9286\n",
      "Epoch 00009: val_loss did not improve from 0.24048\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.2011 - acc: 0.9286 - val_loss: 0.2427 - val_acc: 0.9120\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9285\n",
      "Epoch 00010: val_loss did not improve from 0.24048\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1994 - acc: 0.9285 - val_loss: 0.2433 - val_acc: 0.9144\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1953 - acc: 0.9303\n",
      "Epoch 00011: val_loss did not improve from 0.24048\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1952 - acc: 0.9304 - val_loss: 0.2432 - val_acc: 0.9086\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1939 - acc: 0.9307\n",
      "Epoch 00012: val_loss did not improve from 0.24048\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1939 - acc: 0.9308 - val_loss: 0.2420 - val_acc: 0.9129\n",
      "auc0.8745081888978836, auprc0.572269994954177, acc0.913450011987533, F10.4619970193740685 \n",
      "0.8745081888978836 0.572269994954177 0.913450011987533 0.4619970193740685\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9318- ETA: 0s - loss: 0.2150 - acc: \n",
      "Epoch 00001: val_loss improved from inf to 0.18304, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 50ms/step - loss: 0.2155 - acc: 0.9318 - val_loss: 0.1830 - val_acc: 0.9359\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1792 - acc: 0.9426\n",
      "Epoch 00002: val_loss improved from 0.18304 to 0.17640, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1792 - acc: 0.9426 - val_loss: 0.1764 - val_acc: 0.9421\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9457\n",
      "Epoch 00003: val_loss did not improve from 0.17640\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1672 - acc: 0.9457 - val_loss: 0.1770 - val_acc: 0.9435\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9476- ETA: 3s - loss: 0.1 - ETA: 1s - loss: 0.\n",
      "Epoch 00004: val_loss did not improve from 0.17640\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 0.1593 - acc: 0.9476 - val_loss: 0.1767 - val_acc: 0.9421\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9486- ETA: 5s - loss: - ETA: 0s - loss: 0.1546 - a\n",
      "Epoch 00005: val_loss improved from 0.17640 to 0.17583, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 0.1535 - acc: 0.9485 - val_loss: 0.1758 - val_acc: 0.9402\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9504\n",
      "Epoch 00006: val_loss did not improve from 0.17583\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1505 - acc: 0.9503 - val_loss: 0.1777 - val_acc: 0.9392\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1471 - acc: 0.9507\n",
      "Epoch 00007: val_loss did not improve from 0.17583\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1473 - acc: 0.9506 - val_loss: 0.1763 - val_acc: 0.9402\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9518\n",
      "Epoch 00008: val_loss did not improve from 0.17583\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1439 - acc: 0.9517 - val_loss: 0.1782 - val_acc: 0.9378\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9518\n",
      "Epoch 00009: val_loss did not improve from 0.17583\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1415 - acc: 0.9519 - val_loss: 0.1782 - val_acc: 0.9402\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9540\n",
      "Epoch 00010: val_loss did not improve from 0.17583\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1388 - acc: 0.9540 - val_loss: 0.1778 - val_acc: 0.9402\n",
      "auc0.8867483770709578, auprc0.527544673499965, acc0.9407815871493647, F10.4547461368653422 \n",
      "0.8867483770709578 0.527544673499965 0.9407815871493647 0.4547461368653422\n",
      "Iteration number:  5\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2954 - acc: 0.8983\n",
      "Epoch 00001: val_loss improved from inf to 0.25005, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 53ms/step - loss: 0.2953 - acc: 0.8983 - val_loss: 0.2500 - val_acc: 0.9129\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2452 - acc: 0.9157- ETA: 0s - loss: 0.2457 - acc: 0\n",
      "Epoch 00002: val_loss improved from 0.25005 to 0.24255, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2452 - acc: 0.9157 - val_loss: 0.2425 - val_acc: 0.9148\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2315 - acc: 0.9187- ETA: 1s - loss: 0.2300 \n",
      "Epoch 00003: val_loss did not improve from 0.24255\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2314 - acc: 0.9188 - val_loss: 0.2437 - val_acc: 0.9158\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9215\n",
      "Epoch 00004: val_loss improved from 0.24255 to 0.23931, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2244 - acc: 0.9216 - val_loss: 0.2393 - val_acc: 0.9167\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2181 - acc: 0.9219\n",
      "Epoch 00005: val_loss did not improve from 0.23931\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2181 - acc: 0.9219 - val_loss: 0.2397 - val_acc: 0.9144\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2131 - acc: 0.9237\n",
      "Epoch 00006: val_loss did not improve from 0.23931\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.2131 - acc: 0.9237 - val_loss: 0.2398 - val_acc: 0.9163\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9243\n",
      "Epoch 00007: val_loss did not improve from 0.23931\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2089 - acc: 0.9244 - val_loss: 0.2395 - val_acc: 0.9144\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2058 - acc: 0.9254\n",
      "Epoch 00008: val_loss did not improve from 0.23931\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2059 - acc: 0.9254 - val_loss: 0.2405 - val_acc: 0.9139\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9279\n",
      "Epoch 00009: val_loss did not improve from 0.23931\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2024 - acc: 0.9279 - val_loss: 0.2401 - val_acc: 0.9115\n",
      "auc0.8782323434069916, auprc0.5777329169547168, acc0.9139295133061616, F10.4601503759398496 \n",
      "0.8782323434069916 0.5777329169547168 0.9139295133061616 0.4601503759398496\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2348 - acc: 0.9268\n",
      "Epoch 00001: val_loss improved from inf to 0.18779, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 54ms/step - loss: 0.2348 - acc: 0.9268 - val_loss: 0.1878 - val_acc: 0.9388\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9416\n",
      "Epoch 00002: val_loss improved from 0.18779 to 0.18038, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1834 - acc: 0.9416 - val_loss: 0.1804 - val_acc: 0.9421\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9457\n",
      "Epoch 00003: val_loss improved from 0.18038 to 0.17665, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1714 - acc: 0.9457 - val_loss: 0.1767 - val_acc: 0.9440\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9476\n",
      "Epoch 00004: val_loss did not improve from 0.17665\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1646 - acc: 0.9476 - val_loss: 0.1768 - val_acc: 0.9416\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/230 [============================>.] - ETA: 0s - loss: 0.1581 - acc: 0.9496\n",
      "Epoch 00005: val_loss improved from 0.17665 to 0.17593, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1584 - acc: 0.9495 - val_loss: 0.1759 - val_acc: 0.9416\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9502- ETA: 4s - loss: 0.1536\n",
      "Epoch 00006: val_loss did not improve from 0.17593\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1532 - acc: 0.9502 - val_loss: 0.1760 - val_acc: 0.9421\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1503 - acc: 0.9508\n",
      "Epoch 00007: val_loss did not improve from 0.17593\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1503 - acc: 0.9508 - val_loss: 0.1762 - val_acc: 0.9426\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9513\n",
      "Epoch 00008: val_loss improved from 0.17593 to 0.17513, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1483 - acc: 0.9512 - val_loss: 0.1751 - val_acc: 0.9411\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9516\n",
      "Epoch 00009: val_loss did not improve from 0.17513\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1450 - acc: 0.9517 - val_loss: 0.1753 - val_acc: 0.9411\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9525\n",
      "Epoch 00010: val_loss did not improve from 0.17513\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1413 - acc: 0.9524 - val_loss: 0.1763 - val_acc: 0.9426\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9539\n",
      "Epoch 00011: val_loss did not improve from 0.17513\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1407 - acc: 0.9539 - val_loss: 0.1764 - val_acc: 0.9421\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9533\n",
      "Epoch 00012: val_loss did not improve from 0.17513\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1388 - acc: 0.9532 - val_loss: 0.1764 - val_acc: 0.9421\n",
      "Epoch 13/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1370 - acc: 0.9550\n",
      "Epoch 00013: val_loss did not improve from 0.17513\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1370 - acc: 0.9550 - val_loss: 0.1766 - val_acc: 0.9421\n",
      "auc0.8866263963038156, auprc0.5210552055314406, acc0.9386238312155358, F10.4410480349344979 \n",
      "0.8866263963038156 0.5210552055314406 0.9386238312155358 0.4410480349344979\n",
      "Iteration number:  6\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.8993\n",
      "Epoch 00001: val_loss improved from inf to 0.24887, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 53ms/step - loss: 0.2976 - acc: 0.8993 - val_loss: 0.2489 - val_acc: 0.9134\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2463 - acc: 0.9149\n",
      "Epoch 00002: val_loss improved from 0.24887 to 0.24352, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2463 - acc: 0.9149 - val_loss: 0.2435 - val_acc: 0.9139\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2325 - acc: 0.9182\n",
      "Epoch 00003: val_loss did not improve from 0.24352\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2325 - acc: 0.9182 - val_loss: 0.2448 - val_acc: 0.9120\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2229 - acc: 0.9217\n",
      "Epoch 00004: val_loss improved from 0.24352 to 0.24301, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2228 - acc: 0.9218 - val_loss: 0.2430 - val_acc: 0.9144\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2186 - acc: 0.9221\n",
      "Epoch 00005: val_loss improved from 0.24301 to 0.24107, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2185 - acc: 0.9221 - val_loss: 0.2411 - val_acc: 0.9124\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2145 - acc: 0.9232\n",
      "Epoch 00006: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2144 - acc: 0.9233 - val_loss: 0.2426 - val_acc: 0.9120\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2103 - acc: 0.9249\n",
      "Epoch 00007: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2103 - acc: 0.9249 - val_loss: 0.2420 - val_acc: 0.9129\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2071 - acc: 0.9267\n",
      "Epoch 00008: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2071 - acc: 0.9267 - val_loss: 0.2417 - val_acc: 0.9129\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2036 - acc: 0.9283\n",
      "Epoch 00009: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2036 - acc: 0.9283 - val_loss: 0.2431 - val_acc: 0.9120\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2011 - acc: 0.9277\n",
      "Epoch 00010: val_loss did not improve from 0.24107\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.2011 - acc: 0.9277 - val_loss: 0.2437 - val_acc: 0.9115\n",
      "auc0.8753177108557249, auprc0.5805085663856817, acc0.9146487652841045, F10.48405797101449266 \n",
      "0.8753177108557249 0.5805085663856817 0.9146487652841045 0.48405797101449266\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9345\n",
      "Epoch 00001: val_loss improved from inf to 0.17970, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 58ms/step - loss: 0.2152 - acc: 0.9344 - val_loss: 0.1797 - val_acc: 0.9450\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9430\n",
      "Epoch 00002: val_loss improved from 0.17970 to 0.17520, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 54ms/step - loss: 0.1794 - acc: 0.9429 - val_loss: 0.1752 - val_acc: 0.9469\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9456\n",
      "Epoch 00003: val_loss improved from 0.17520 to 0.17372, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1658 - acc: 0.9456 - val_loss: 0.1737 - val_acc: 0.9440\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9474\n",
      "Epoch 00004: val_loss did not improve from 0.17372\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1607 - acc: 0.9474 - val_loss: 0.1740 - val_acc: 0.9426\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9484\n",
      "Epoch 00005: val_loss did not improve from 0.17372\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1548 - acc: 0.9484 - val_loss: 0.1747 - val_acc: 0.9407\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9486\n",
      "Epoch 00006: val_loss did not improve from 0.17372\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1504 - acc: 0.9486 - val_loss: 0.1755 - val_acc: 0.9426\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1469 - acc: 0.9497\n",
      "Epoch 00007: val_loss improved from 0.17372 to 0.17332, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1469 - acc: 0.9497 - val_loss: 0.1733 - val_acc: 0.9421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9509\n",
      "Epoch 00008: val_loss did not improve from 0.17332\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1445 - acc: 0.9509 - val_loss: 0.1749 - val_acc: 0.9426\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9519\n",
      "Epoch 00009: val_loss did not improve from 0.17332\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1424 - acc: 0.9519 - val_loss: 0.1748 - val_acc: 0.9421\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9520- ETA: 1s - los\n",
      "Epoch 00010: val_loss did not improve from 0.17332\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1396 - acc: 0.9520 - val_loss: 0.1763 - val_acc: 0.9416\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9517\n",
      "Epoch 00011: val_loss did not improve from 0.17332\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1395 - acc: 0.9517 - val_loss: 0.1751 - val_acc: 0.9431\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9537\n",
      "Epoch 00012: val_loss did not improve from 0.17332\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1369 - acc: 0.9537 - val_loss: 0.1748 - val_acc: 0.9421\n",
      "auc0.8839119064925516, auprc0.51735619587962, acc0.940302085830736, F10.4551422319474836 \n",
      "0.8839119064925516 0.51735619587962 0.940302085830736 0.4551422319474836\n",
      "Iteration number:  7\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.3066 - acc: 0.8953\n",
      "Epoch 00001: val_loss improved from inf to 0.24990, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 59ms/step - loss: 0.3065 - acc: 0.8953 - val_loss: 0.2499 - val_acc: 0.9153\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.9153\n",
      "Epoch 00002: val_loss improved from 0.24990 to 0.24774, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2473 - acc: 0.9153 - val_loss: 0.2477 - val_acc: 0.9134\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2327 - acc: 0.9178\n",
      "Epoch 00003: val_loss improved from 0.24774 to 0.24413, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2327 - acc: 0.9178 - val_loss: 0.2441 - val_acc: 0.9163\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2231 - acc: 0.9227\n",
      "Epoch 00004: val_loss did not improve from 0.24413\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2231 - acc: 0.9227 - val_loss: 0.2445 - val_acc: 0.9124\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9229\n",
      "Epoch 00005: val_loss improved from 0.24413 to 0.24184, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2180 - acc: 0.9229 - val_loss: 0.2418 - val_acc: 0.9100\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9258\n",
      "Epoch 00006: val_loss did not improve from 0.24184\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2136 - acc: 0.9257 - val_loss: 0.2420 - val_acc: 0.9163\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2110 - acc: 0.9254\n",
      "Epoch 00007: val_loss improved from 0.24184 to 0.24054, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.2110 - acc: 0.9254 - val_loss: 0.2405 - val_acc: 0.9144\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9269\n",
      "Epoch 00008: val_loss improved from 0.24054 to 0.24051, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2050 - acc: 0.9270 - val_loss: 0.2405 - val_acc: 0.9100\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9275\n",
      "Epoch 00009: val_loss did not improve from 0.24051\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2036 - acc: 0.9274 - val_loss: 0.2409 - val_acc: 0.9129\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9288\n",
      "Epoch 00010: val_loss did not improve from 0.24051\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2003 - acc: 0.9288 - val_loss: 0.2421 - val_acc: 0.9129\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9311\n",
      "Epoch 00011: val_loss did not improve from 0.24051\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1973 - acc: 0.9311 - val_loss: 0.2418 - val_acc: 0.9120\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9303\n",
      "Epoch 00012: val_loss did not improve from 0.24051\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1945 - acc: 0.9302 - val_loss: 0.2434 - val_acc: 0.9124\n",
      "Epoch 13/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1924 - acc: 0.9311\n",
      "Epoch 00013: val_loss did not improve from 0.24051\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1924 - acc: 0.9311 - val_loss: 0.2437 - val_acc: 0.9134\n",
      "auc0.8804228839013538, auprc0.5777248640828042, acc0.9129705106689043, F10.47769784172661867 \n",
      "0.8804228839013538 0.5777248640828042 0.9129705106689043 0.47769784172661867\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2232 - acc: 0.9333\n",
      "Epoch 00001: val_loss improved from inf to 0.18311, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 55ms/step - loss: 0.2231 - acc: 0.9334 - val_loss: 0.1831 - val_acc: 0.9431\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1789 - acc: 0.9428\n",
      "Epoch 00002: val_loss improved from 0.18311 to 0.17604, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1789 - acc: 0.9428 - val_loss: 0.1760 - val_acc: 0.9397\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9458\n",
      "Epoch 00003: val_loss did not improve from 0.17604\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1673 - acc: 0.9457 - val_loss: 0.1769 - val_acc: 0.9431\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9484\n",
      "Epoch 00004: val_loss did not improve from 0.17604\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1595 - acc: 0.9484 - val_loss: 0.1766 - val_acc: 0.9421\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9485\n",
      "Epoch 00005: val_loss did not improve from 0.17604\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1547 - acc: 0.9485 - val_loss: 0.1761 - val_acc: 0.9440\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1504 - acc: 0.9499\n",
      "Epoch 00006: val_loss improved from 0.17604 to 0.17453, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1504 - acc: 0.9499 - val_loss: 0.1745 - val_acc: 0.9421\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9507\n",
      "Epoch 00007: val_loss improved from 0.17453 to 0.17378, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1474 - acc: 0.9507 - val_loss: 0.1738 - val_acc: 0.9407\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9511\n",
      "Epoch 00008: val_loss did not improve from 0.17378\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1444 - acc: 0.9512 - val_loss: 0.1745 - val_acc: 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9518\n",
      "Epoch 00009: val_loss did not improve from 0.17378\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1424 - acc: 0.9519 - val_loss: 0.1752 - val_acc: 0.9416\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9535\n",
      "Epoch 00010: val_loss did not improve from 0.17378\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1387 - acc: 0.9535 - val_loss: 0.1759 - val_acc: 0.9416\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9531\n",
      "Epoch 00011: val_loss did not improve from 0.17378\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1370 - acc: 0.9530 - val_loss: 0.1757 - val_acc: 0.9421\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1356 - acc: 0.9527- ETA: 5s - ETA: 2s - loss: 0.1359 - acc: 0.9 - ETA: 2s -\n",
      "Epoch 00012: val_loss did not improve from 0.17378\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 0.1356 - acc: 0.9527 - val_loss: 0.1761 - val_acc: 0.9426\n",
      "auc0.8853096724064466, auprc0.5213578091762197, acc0.9391033325341644, F10.4454148471615721 \n",
      "0.8853096724064466 0.5213578091762197 0.9391033325341644 0.4454148471615721\n",
      "Iteration number:  8\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2959 - acc: 0.8989\n",
      "Epoch 00001: val_loss improved from inf to 0.24561, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 55ms/step - loss: 0.2958 - acc: 0.8989 - val_loss: 0.2456 - val_acc: 0.9163\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9143\n",
      "Epoch 00002: val_loss improved from 0.24561 to 0.24149, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2443 - acc: 0.9144 - val_loss: 0.2415 - val_acc: 0.9153\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9198\n",
      "Epoch 00003: val_loss improved from 0.24149 to 0.23959, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2291 - acc: 0.9199 - val_loss: 0.2396 - val_acc: 0.9148\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.9232\n",
      "Epoch 00004: val_loss did not improve from 0.23959\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2196 - acc: 0.9232 - val_loss: 0.2411 - val_acc: 0.9134\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9249\n",
      "Epoch 00005: val_loss improved from 0.23959 to 0.23823, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2154 - acc: 0.9249 - val_loss: 0.2382 - val_acc: 0.9153\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9235\n",
      "Epoch 00006: val_loss improved from 0.23823 to 0.23735, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2097 - acc: 0.9235 - val_loss: 0.2374 - val_acc: 0.9134\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9255\n",
      "Epoch 00007: val_loss did not improve from 0.23735\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2055 - acc: 0.9255 - val_loss: 0.2384 - val_acc: 0.9105\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9264\n",
      "Epoch 00008: val_loss did not improve from 0.23735\n",
      "230/230 [==============================] - 13s 54ms/step - loss: 0.2033 - acc: 0.9264 - val_loss: 0.2383 - val_acc: 0.9115\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9277\n",
      "Epoch 00009: val_loss did not improve from 0.23735\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1999 - acc: 0.9278 - val_loss: 0.2380 - val_acc: 0.9115\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1974 - acc: 0.9285- ETA: 2s - lo\n",
      "Epoch 00010: val_loss did not improve from 0.23735\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1974 - acc: 0.9285 - val_loss: 0.2384 - val_acc: 0.9110\n",
      "Epoch 11/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1949 - acc: 0.9300\n",
      "Epoch 00011: val_loss did not improve from 0.23735\n",
      "230/230 [==============================] - 11s 50ms/step - loss: 0.1949 - acc: 0.9300 - val_loss: 0.2385 - val_acc: 0.9115\n",
      "auc0.8774988246023975, auprc0.5799441196850649, acc0.9115320067130185, F10.4751066856330014 \n",
      "0.8774988246023975 0.5799441196850649 0.9115320067130185 0.4751066856330014\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9346\n",
      "Epoch 00001: val_loss improved from inf to 0.18129, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 55ms/step - loss: 0.2168 - acc: 0.9345 - val_loss: 0.1813 - val_acc: 0.9402\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1786 - acc: 0.9430\n",
      "Epoch 00002: val_loss improved from 0.18129 to 0.17389, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1786 - acc: 0.9430 - val_loss: 0.1739 - val_acc: 0.9431\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9456\n",
      "Epoch 00003: val_loss improved from 0.17389 to 0.17210, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1656 - acc: 0.9455 - val_loss: 0.1721 - val_acc: 0.9421\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9477\n",
      "Epoch 00004: val_loss did not improve from 0.17210\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1580 - acc: 0.9476 - val_loss: 0.1723 - val_acc: 0.9431\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9486\n",
      "Epoch 00005: val_loss did not improve from 0.17210\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1536 - acc: 0.9487 - val_loss: 0.1736 - val_acc: 0.9426\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9494\n",
      "Epoch 00006: val_loss did not improve from 0.17210\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.1489 - acc: 0.9495 - val_loss: 0.1731 - val_acc: 0.9411\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1470 - acc: 0.9508\n",
      "Epoch 00007: val_loss did not improve from 0.17210\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1470 - acc: 0.9508 - val_loss: 0.1737 - val_acc: 0.9407\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9511\n",
      "Epoch 00008: val_loss did not improve from 0.17210\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1443 - acc: 0.9511 - val_loss: 0.1734 - val_acc: 0.9402\n",
      "auc0.8833170413815576, auprc0.5179924924072946, acc0.9415008391273076, F10.4504504504504504 \n",
      "0.8833170413815576 0.5179924924072946 0.9415008391273076 0.4504504504504504\n",
      "Iteration number:  9\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2945 - acc: 0.9011\n",
      "Epoch 00001: val_loss improved from inf to 0.24559, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 15s 55ms/step - loss: 0.2947 - acc: 0.9011 - val_loss: 0.2456 - val_acc: 0.9124\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2441 - acc: 0.9162\n",
      "Epoch 00002: val_loss improved from 0.24559 to 0.24100, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.2441 - acc: 0.9162 - val_loss: 0.2410 - val_acc: 0.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2301 - acc: 0.9194\n",
      "Epoch 00003: val_loss improved from 0.24100 to 0.23816, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.2300 - acc: 0.9193 - val_loss: 0.2382 - val_acc: 0.9172\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2209 - acc: 0.9202\n",
      "Epoch 00004: val_loss did not improve from 0.23816\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2210 - acc: 0.9202 - val_loss: 0.2408 - val_acc: 0.9124\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2144 - acc: 0.9219\n",
      "Epoch 00005: val_loss did not improve from 0.23816\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2143 - acc: 0.9219 - val_loss: 0.2436 - val_acc: 0.9120\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9246- ETA: 0s - loss: 0.2103 - acc: 0.924\n",
      "Epoch 00006: val_loss did not improve from 0.23816\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2101 - acc: 0.9247 - val_loss: 0.2391 - val_acc: 0.9139\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9258\n",
      "Epoch 00007: val_loss did not improve from 0.23816\n",
      "230/230 [==============================] - 12s 53ms/step - loss: 0.2059 - acc: 0.9259 - val_loss: 0.2411 - val_acc: 0.9144\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2025 - acc: 0.9274\n",
      "Epoch 00008: val_loss did not improve from 0.23816\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.2025 - acc: 0.9274 - val_loss: 0.2405 - val_acc: 0.9120\n",
      "auc0.8760182360434055, auprc0.5788745815258235, acc0.9168065212179334, F10.4813153961136023 \n",
      "0.8760182360434055 0.5788745815258235 0.9168065212179334 0.4813153961136023\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.2298 - acc: 0.9317\n",
      "Epoch 00001: val_loss improved from inf to 0.18863, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 54ms/step - loss: 0.2298 - acc: 0.9317 - val_loss: 0.1886 - val_acc: 0.9349\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9428\n",
      "Epoch 00002: val_loss improved from 0.18863 to 0.17813, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1833 - acc: 0.9428 - val_loss: 0.1781 - val_acc: 0.9416\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9449\n",
      "Epoch 00003: val_loss did not improve from 0.17813\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.1704 - acc: 0.9450 - val_loss: 0.1786 - val_acc: 0.9378\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1626 - acc: 0.9479\n",
      "Epoch 00004: val_loss did not improve from 0.17813\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 0.1626 - acc: 0.9479 - val_loss: 0.1797 - val_acc: 0.9397\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1586 - acc: 0.9485\n",
      "Epoch 00005: val_loss improved from 0.17813 to 0.17644, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1586 - acc: 0.9485 - val_loss: 0.1764 - val_acc: 0.9416\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1523 - acc: 0.9498\n",
      "Epoch 00006: val_loss improved from 0.17644 to 0.17577, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1522 - acc: 0.9498 - val_loss: 0.1758 - val_acc: 0.9407\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9505\n",
      "Epoch 00007: val_loss did not improve from 0.17577\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1501 - acc: 0.9505 - val_loss: 0.1768 - val_acc: 0.9411\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9507\n",
      "Epoch 00008: val_loss did not improve from 0.17577\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1468 - acc: 0.9508 - val_loss: 0.1763 - val_acc: 0.9407\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.1439 - acc: 0.9530\n",
      "Epoch 00009: val_loss did not improve from 0.17577\n",
      "230/230 [==============================] - 12s 54ms/step - loss: 0.1439 - acc: 0.9530 - val_loss: 0.1767 - val_acc: 0.9407\n",
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9522\n",
      "Epoch 00010: val_loss did not improve from 0.17577\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.1429 - acc: 0.9523 - val_loss: 0.1787 - val_acc: 0.9411\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9529\n",
      "Epoch 00011: val_loss did not improve from 0.17577\n",
      "230/230 [==============================] - 12s 50ms/step - loss: 0.1399 - acc: 0.9529 - val_loss: 0.1792 - val_acc: 0.9388\n",
      "auc0.8882806560225915, auprc0.5294266289394585, acc0.9415008391273076, F10.4695652173913043 \n",
      "0.8882806560225915 0.5294266289394585 0.9415008391273076 0.4695652173913043\n",
      "Iteration number:  10\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2920 - acc: 0.9027\n",
      "Epoch 00001: val_loss improved from inf to 0.24599, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 16s 60ms/step - loss: 0.2919 - acc: 0.9027 - val_loss: 0.2460 - val_acc: 0.9129\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2442 - acc: 0.9145\n",
      "Epoch 00002: val_loss did not improve from 0.24599\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2441 - acc: 0.9145 - val_loss: 0.2478 - val_acc: 0.9115\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9187\n",
      "Epoch 00003: val_loss improved from 0.24599 to 0.24375, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2310 - acc: 0.9188 - val_loss: 0.2438 - val_acc: 0.9139\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9209\n",
      "Epoch 00004: val_loss improved from 0.24375 to 0.24184, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.2218 - acc: 0.9209 - val_loss: 0.2418 - val_acc: 0.9144\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2175 - acc: 0.9221\n",
      "Epoch 00005: val_loss improved from 0.24184 to 0.24121, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.2174 - acc: 0.9221 - val_loss: 0.2412 - val_acc: 0.9148\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9249\n",
      "Epoch 00006: val_loss did not improve from 0.24121\n",
      "230/230 [==============================] - 14s 59ms/step - loss: 0.2132 - acc: 0.9249 - val_loss: 0.2417 - val_acc: 0.9153\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9258\n",
      "Epoch 00007: val_loss improved from 0.24121 to 0.24037, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.2080 - acc: 0.9259 - val_loss: 0.2404 - val_acc: 0.9158\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9276\n",
      "Epoch 00008: val_loss did not improve from 0.24037\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.2053 - acc: 0.9275 - val_loss: 0.2427 - val_acc: 0.9139\n",
      "Epoch 9/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9269\n",
      "Epoch 00009: val_loss did not improve from 0.24037\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 0.2028 - acc: 0.9268 - val_loss: 0.2422 - val_acc: 0.9115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9290\n",
      "Epoch 00010: val_loss did not improve from 0.24037\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.1992 - acc: 0.9291 - val_loss: 0.2421 - val_acc: 0.9124\n",
      "Epoch 11/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9286\n",
      "Epoch 00011: val_loss did not improve from 0.24037\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1977 - acc: 0.9286 - val_loss: 0.2407 - val_acc: 0.9134\n",
      "Epoch 12/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9294\n",
      "Epoch 00012: val_loss did not improve from 0.24037\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1961 - acc: 0.9294 - val_loss: 0.2441 - val_acc: 0.9134\n",
      "auc0.8757330769257963, auprc0.5779211931411866, acc0.9160872692399904, F10.4712990936555891 \n",
      "0.8757330769257963 0.5779211931411866 0.9160872692399904 0.4712990936555891\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9334\n",
      "Epoch 00001: val_loss improved from inf to 0.18269, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 18s 67ms/step - loss: 0.2181 - acc: 0.9333 - val_loss: 0.1827 - val_acc: 0.9445\n",
      "Epoch 2/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9414\n",
      "Epoch 00002: val_loss improved from 0.18269 to 0.17662, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 15s 65ms/step - loss: 0.1803 - acc: 0.9414 - val_loss: 0.1766 - val_acc: 0.9440\n",
      "Epoch 3/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9468- ET\n",
      "Epoch 00003: val_loss improved from 0.17662 to 0.17541, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "230/230 [==============================] - 14s 60ms/step - loss: 0.1657 - acc: 0.9468 - val_loss: 0.1754 - val_acc: 0.9440\n",
      "Epoch 4/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9474\n",
      "Epoch 00004: val_loss did not improve from 0.17541\n",
      "230/230 [==============================] - 14s 61ms/step - loss: 0.1591 - acc: 0.9474 - val_loss: 0.1784 - val_acc: 0.9431\n",
      "Epoch 5/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9484- ETA: 1\n",
      "Epoch 00005: val_loss did not improve from 0.17541\n",
      "230/230 [==============================] - 13s 58ms/step - loss: 0.1545 - acc: 0.9484 - val_loss: 0.1766 - val_acc: 0.9431\n",
      "Epoch 6/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9503\n",
      "Epoch 00006: val_loss did not improve from 0.17541\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 0.1497 - acc: 0.9503 - val_loss: 0.1758 - val_acc: 0.9426\n",
      "Epoch 7/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9516\n",
      "Epoch 00007: val_loss did not improve from 0.17541\n",
      "230/230 [==============================] - 13s 59ms/step - loss: 0.1462 - acc: 0.9516 - val_loss: 0.1771 - val_acc: 0.9421\n",
      "Epoch 8/100\n",
      "229/230 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9514- ETA: 0s - loss: 0.1425 - \n",
      "Epoch 00008: val_loss did not improve from 0.17541\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 0.1433 - acc: 0.9514 - val_loss: 0.1777 - val_acc: 0.9421\n",
      "auc0.8808799324928357, auprc0.5134243007831252, acc0.9398225845121074, F10.4229885057471265 \n",
      "0.8808799324928357 0.5134243007831252 0.9398225845121074 0.4229885057471265\n"
     ]
    }
   ],
   "source": [
    "embedding_types = ['word2vec', 'fasttext']#, 'concat']\n",
    "embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
    "target_problems = ['mort_hosp', 'mort_icu']#, 'los_3', 'los_7']\n",
    "\n",
    "\n",
    "num_epoch = 100\n",
    "model_patience = 5\n",
    "monitor_criteria = 'val_loss'\n",
    "batch_size = 64\n",
    "iter_num = 11\n",
    "unit_sizes = [128, 256]\n",
    "\n",
    "#layers = [\"LSTM\", \"GRU\"]\n",
    "layers = [\"GRU\"]\n",
    "for each_layer in layers:\n",
    "    print (\"Layer: \", each_layer)\n",
    "    for each_unit_size in unit_sizes:\n",
    "        print (\"Hidden unit: \", each_unit_size)\n",
    "\n",
    "        for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n",
    "            print (\"Embedding: \", embed_name)\n",
    "            print(\"=============================\")\n",
    "            \n",
    "            temp_train_ner = dict((k, ner_word2vec[k]) for k in train_ids)\n",
    "            temp_dev_ner = dict((k, ner_word2vec[k]) for k in dev_ids)\n",
    "            temp_test_ner = dict((k, ner_word2vec[k]) for k in test_ids)\n",
    "\n",
    "            x_train_ner = create_dataset(temp_train_ner)\n",
    "            x_dev_ner = create_dataset(temp_dev_ner)\n",
    "            x_test_ner = create_dataset(temp_test_ner)\n",
    "\n",
    "\n",
    "            for iteration in range(1, iter_num):\n",
    "                print (\"Iteration number: \", iteration)\n",
    "\n",
    "                for each_problem in target_problems:\n",
    "                    print (\"Problem type: \", each_problem)\n",
    "                    print (\"__________________\")\n",
    "\n",
    "                    early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "                    best_model_name = \"avg-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "                    checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1,\n",
    "                        save_best_only=True, mode='min', period=1)\n",
    "\n",
    "\n",
    "                    callbacks = [early_stopping_monitor, checkpoint]\n",
    "\n",
    "                    model = avg_ner_model(each_layer, each_unit_size, embed_name)\n",
    "                    \n",
    "                    model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n",
    "                              validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, \n",
    "                              batch_size=batch_size )\n",
    "\n",
    "                    model.load_weights(best_model_name)\n",
    "\n",
    "                    probs, predictions = make_prediction_multi_avg(model, [x_test_lstm, x_test_ner])\n",
    "                    \n",
    "                    # nitin uncomment the code\n",
    "                    save_scores_multi_avg(predictions, probs, y_test[each_problem], \n",
    "                               embed_name, each_problem, iteration, each_unit_size, \n",
    "                               each_layer, type_of_ner)\n",
    "                    \n",
    "                    #reset_keras(model) nitin commented as its not defined\n",
    "                    #del model\n",
    "                    sess = get_session()\n",
    "                    clear_session()\n",
    "                    sess.close()\n",
    "                    #clear_session() nitin originally its only clear session but added abve three line\n",
    "                    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
